{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Particle_identification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "W2vIhf5-CVa4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# About\n",
        "\n",
        "In this programming assignment you will train a classifier to identify type of a particle. There are six particle types: electron, proton, muon, kaon, pion and ghost. Ghost is a particle with other type than the first five or a detector noise. \n",
        "\n",
        "Different particle types remain different responses in the detector systems or subdetectors. Thre are five systems: tracking system, ring imaging Cherenkov detector (RICH), electromagnetic and hadron calorimeters, and muon system.\n",
        "\n",
        "![pid](pic/pid.jpg)\n",
        "\n",
        "You task is to identify a particle type using the responses in the detector systems. \n",
        "\n",
        "# Attention\n",
        "\n",
        "Data files you should download from https://github.com/hse-aml/hadron-collider-machine-learning/releases/tag/Week_2"
      ]
    },
    {
      "metadata": {
        "id": "xyzhC-2eM0AZ",
        "colab_type": "code",
        "outputId": "1f3fad8c-2032-46e8-8844-7ab523528d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oCxmBJdLn8sW",
        "colab_type": "code",
        "outputId": "12df8dd2-7d39-4f3e-d068-55edfde4fcff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks/hadron-collider-machine-learning-master/week2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/hadron-collider-machine-learning-master/week2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "elFaMM6TCVa8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STlkR4rwCVbJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download data\n",
        "\n",
        "Download data used to train classifiers."
      ]
    },
    {
      "metadata": {
        "id": "jCEfAxBlCVbN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Read training file"
      ]
    },
    {
      "metadata": {
        "id": "nYaAYpOsCVbQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataorigin = pandas.read_csv('training.csv.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eTdx-1UiCVbY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataorigin.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdCl9zNtndTw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = dataorigin.loc[0:240000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37zpJigNNutM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(data.Label)\n",
        "le.classes_\n",
        "labels = le.transform(data.Label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TmDlfZbfIwf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labelspd = pandas.DataFrame(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qH7d6eIxL8Xm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labelspd.columns = ['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivdw14gNQKH3",
        "colab_type": "code",
        "outputId": "db4163d3-96cd-4644-b193-31ef441b4c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "data.drop(['Label'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "W_MewDzmQ_GB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pandas.concat([data,labelspd],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4TZMn2JbSArk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GPgiF3gpCVbj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### List of columns in the samples"
      ]
    },
    {
      "metadata": {
        "id": "gTrxelRJCVbl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, **Spd** stands for Scintillating Pad Detector, **Prs** - Preshower, **Ecal** - electromagnetic calorimeter, **Hcal** - hadronic calorimeter, **Brem** denotes traces of the particles that were deflected by detector."
      ]
    },
    {
      "metadata": {
        "id": "ip1GXSvGCVbn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- ID - id value for tracks (presents only in the test file for the submitting purposes)\n",
        "- Label - string valued observable denoting particle types. Can take values \"Electron\", \"Muon\", \"Kaon\", \"Proton\", \"Pion\" and \"Ghost\". This column is absent in the test file.\n",
        "- FlagSpd - flag (0 or 1), if reconstructed track passes through Spd\n",
        "- FlagPrs - flag (0 or 1), if reconstructed track passes through Prs\n",
        "- FlagBrem - flag (0 or 1), if reconstructed track passes through Brem\n",
        "- FlagEcal - flag (0 or 1), if reconstructed track passes through Ecal\n",
        "- FlagHcal - flag (0 or 1), if reconstructed track passes through Hcal\n",
        "- FlagRICH1 - flag (0 or 1), if reconstructed track passes through the first RICH detector\n",
        "- FlagRICH2 - flag (0 or 1), if reconstructed track passes through the second RICH detector\n",
        "- FlagMuon - flag (0 or 1), if reconstructed track passes through muon stations (Muon)\n",
        "- SpdE - energy deposit associated to the track in the Spd\n",
        "- PrsE - energy deposit associated to the track in the Prs\n",
        "- EcalE - energy deposit associated to the track in the Hcal\n",
        "- HcalE - energy deposit associated to the track in the Hcal\n",
        "- PrsDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Prs\n",
        "- BremDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Brem\n",
        "- TrackP - particle momentum\n",
        "- TrackPt - particle transverse momentum\n",
        "- TrackNDoFSubdetector1  - number of degrees of freedom for track fit using hits in the tracking sub-detector1\n",
        "- TrackQualitySubdetector1 - chi2 quality of the track fit using hits in the tracking sub-detector1\n",
        "- TrackNDoFSubdetector2 - number of degrees of freedom for track fit using hits in the tracking sub-detector2\n",
        "- TrackQualitySubdetector2 - chi2 quality of the track fit using hits in the  tracking sub-detector2\n",
        "- TrackNDoF - number of degrees of freedom for track fit using hits in all tracking sub-detectors\n",
        "- TrackQualityPerNDoF - chi2 quality of the track fit per degree of freedom\n",
        "- TrackDistanceToZ - distance between track and z-axis (beam axis)\n",
        "- Calo2dFitQuality - quality of the 2d fit of the clusters in the calorimeter \n",
        "- Calo3dFitQuality - quality of the 3d fit in the calorimeter with assumption that particle was electron\n",
        "- EcalDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Ecal\n",
        "- EcalDLLbeMuon - delta log-likelihood for a particle candidate to be muon using information from Ecal\n",
        "- EcalShowerLongitudinalParameter - longitudinal parameter of Ecal shower\n",
        "- HcalDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Hcal\n",
        "- HcalDLLbeMuon - delta log-likelihood for a particle candidate to be using information from Hcal\n",
        "- RICHpFlagElectron - flag (0 or 1) if momentum is greater than threshold for electrons to produce Cherenkov light\n",
        "- RICHpFlagProton - flag (0 or 1) if momentum is greater than threshold for protons to produce Cherenkov light\n",
        "- RICHpFlagPion - flag (0 or 1) if momentum is greater than threshold for pions to produce Cherenkov light\n",
        "- RICHpFlagKaon - flag (0 or 1) if momentum is greater than threshold for kaons to produce Cherenkov light\n",
        "- RICHpFlagMuon - flag (0 or 1) if momentum is greater than threshold for muons to produce Cherenkov light\n",
        "- RICH_DLLbeBCK  - delta log-likelihood for a particle candidate to be background using information from RICH\n",
        "- RICH_DLLbeKaon - delta log-likelihood for a particle candidate to be kaon using information from RICH\n",
        "- RICH_DLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from RICH\n",
        "- RICH_DLLbeMuon - delta log-likelihood for a particle candidate to be muon using information from RICH\n",
        "- RICH_DLLbeProton - delta log-likelihood for a particle candidate to be proton using information from RICH\n",
        "- MuonFlag - muon flag (is this track muon) which is determined from muon stations\n",
        "- MuonLooseFlag muon flag (is this track muon) which is determined from muon stations using looser criteria\n",
        "- MuonLLbeBCK - log-likelihood for a particle candidate to be not muon using information from muon stations\n",
        "- MuonLLbeMuon - log-likelihood for a particle candidate to be muon using information from muon stations\n",
        "- DLLelectron - delta log-likelihood for a particle candidate to be electron using information from all subdetectors\n",
        "- DLLmuon - delta log-likelihood for a particle candidate to be muon using information from all subdetectors\n",
        "- DLLkaon - delta log-likelihood for a particle candidate to be kaon using information from all subdetectors\n",
        "- DLLproton - delta log-likelihood for a particle candidate to be proton using information from all subdetectors\n",
        "- GhostProbability - probability for a particle candidate to be ghost track. This variable is an output of classification model used in the tracking algorithm."
      ]
    },
    {
      "metadata": {
        "id": "GZi0eT6NCVbp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Delta log-likelihood in the features descriptions means the difference between log-likelihood for the mass hypothesis that a given track is left by some particle (for example, electron) and log-likelihood for the mass hypothesis that a given track is left by a pion (so, DLLpion = 0 and thus we don't have these columns). This is done since most tracks (~80%) are left by pions and in practice we actually need to discriminate other particles from pions. In other words, the null hypothesis is that particle is a pion."
      ]
    },
    {
      "metadata": {
        "id": "QPOx7TqKCVbw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Look at the labels set\n",
        "\n",
        "The training data contains six classes. Each class corresponds to a particle type. Your task is to predict type of a particle."
      ]
    },
    {
      "metadata": {
        "id": "zTCkeGVaCVcW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Divide training data into 2 parts"
      ]
    },
    {
      "metadata": {
        "id": "LVBLU012Sgh-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QLbZNwzDNgIt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.drop('Label',axis=1), \n",
        "                                                    data['Label'],\n",
        "                                                    test_size=0.40, \n",
        "                                                    random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fgRzfScrQ_Hp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_val, X_test, y_val, y_test = train_test_split(X_test, \n",
        "                                                y_test,\n",
        "                                                test_size=0.50, \n",
        "                                                random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "29Q5UB0xCVce",
        "colab_type": "code",
        "outputId": "c1cae7c6-29d0-403b-8883-b61a9d7b5cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(X_train), len(X_val), len(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144000, 48000, 48001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "8OUIyBsaCVco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sklearn classifier\n",
        "\n",
        "On this step your task is to train **Sklearn** classifier to provide lower **log loss** value.\n",
        "\n",
        "\n",
        "TASK: your task is to tune the classifier parameters to achieve the lowest **log loss** value on the validation sample you can."
      ]
    },
    {
      "metadata": {
        "id": "M6D897bUCVcp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier # Import Gradient Boost Classifier (GBC)\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc # Import metrics as Confusio Matrix, Classification Report..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7se7JCh0MliL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_x = StandardScaler()\n",
        "X_train_sc = sc_x.fit_transform(X_train)\n",
        "X_val_sc = sc_x.fit_transform(X_val)\n",
        "X_test_sc = sc_x.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zuHdi81vCVcu",
        "colab_type": "code",
        "outputId": "5357c7f1-5234-441f-8519-edad81e21d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier(loss='deviance', # Create the object GBC and yours hyperparameters\n",
        "                                learning_rate=0.04, # learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
        "                                verbose = 1, # Enable verbose output. If 1 then it prints progress and performance once in a while (the more trees the lower the frequency). If greater than 1 then it prints progress and performance for every tree.\n",
        "                                n_estimators=10, # The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
        "                                max_depth=8, # maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
        "                                min_samples_split=1200, # The minimum number of samples required to split an internal node\n",
        "                                min_samples_leaf=100, # The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
        "                                subsample=0.85, # The fraction of samples to be used for fitting the individual base learners. If smaller than 1.0 this results in Stochastic Gradient Boosting. subsample interacts with the parameter n_estimators. \n",
        "                                random_state=1231, # Random_state is the seed used by the random number generator\n",
        "                                max_features=18, #The number of features to consider when looking for the best split\n",
        "                                min_impurity_decrease=0.001,\n",
        "                                warm_start=True) # When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution.\n",
        "                                \n",
        "\n",
        "gb.fit(X_train_sc, y_train) # Fit the gradient boosting model.\n",
        "proba_gb = gb.predict_proba(X_val_sc) # Predict class probabilities for validation_data.\n",
        "logloss = log_loss(y_val, proba_gb) # Log loss, aka logistic loss or cross-entropy loss. This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier’s predictions. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is-log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))\n",
        "print (logloss) # Print the log loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1      207132.9861        2142.0872           55.18s\n",
            "         2      196570.7303        1857.3213           49.48s\n",
            "         3      187302.4408        1606.6515           42.92s\n",
            "         4      179014.4574        1448.8513           36.43s\n",
            "         5      171626.5612        1304.2276           30.31s\n",
            "         6      164899.6608        1162.9217           24.28s\n",
            "         7      158924.7881        1052.4660           18.16s\n",
            "         8      153328.8233         961.0270           12.11s\n",
            "         9      148344.5724         890.7574            6.06s\n",
            "        10      143668.6748         797.0885            0.00s\n",
            "1.2041598809389948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R4g6OJd1TMwK",
        "colab_type": "code",
        "outputId": "a4830486-499b-4d92-fb31-04a4933e1992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train_sc, y_train))) # Returns the mean accuracy on the given TRAINING DATA and labels. In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.\n",
        "print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_val_sc, y_val))) # Returns the mean accuracy on the given VALIDATION DATA and labels. In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.\n",
        "print(\"Accuracy score (testing): {0:.3f}\".format(gb.score(X_test_sc, y_test))) # Returns the mean accuracy on the given TESTING DATA and labels. In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.\n",
        "\n",
        "print ('----------------------------TRAINING DATA-------------------------------\\n\\n')\n",
        "\n",
        "print ('Matriz de Confusão training_data :\\n ')\n",
        "predictions1 = gb.predict(X_train_sc) # Predictions of training data\n",
        "print (confusion_matrix(y_train, predictions1)) # Confusion Matrix of training data\n",
        "\n",
        "print(\"\\n\\nReports (Precision - Recall - F1 Score)\\n\")\n",
        "print (classification_report(y_train, predictions1)) # Reports of training data\n",
        "\n",
        "print ('----------------------------VALIDATION DATA-------------------------------\\n\\n')\n",
        "\n",
        "print ('Matriz de Confusão validation_data :\\n ')\n",
        "predictions2 = gb.predict(X_val_sc) # Predictions of validation data\n",
        "print (confusion_matrix(y_val, predictions2)) # Confusion Matrix of validation data\n",
        "\n",
        "print(\"\\n\\nReports (Precision - Recall - F1 Score)\\n\")\n",
        "print (classification_report(y_val, predictions2)) # Reports of validation data\n",
        "\n",
        "print ('----------------------------TESTING DATA-------------------------------\\n\\n')\n",
        "\n",
        "print ('Matriz de Confusão testing_data : \\n')\n",
        "predictions3 = gb.predict(X_test_sc) # Predictions of testing data\n",
        "print (confusion_matrix(y_test, predictions3)) # Confusion matrix of testing data\n",
        "\n",
        "print(\"\\n\\nReports (Precision - Recall - F1 Score)\\n\")\n",
        "print (classification_report(y_test, predictions3)) # Reports of testing data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (training): 0.737\n",
            "Accuracy score (validation): 0.721\n",
            "Accuracy score (testing): 0.720\n",
            "----------------------------TRAINING DATA-------------------------------\n",
            "\n",
            "\n",
            "Matriz de Confusão training_data :\n",
            " \n",
            "[[21014  2020   199   147   713   232]\n",
            " [ 1905 18689   440   394  1804   690]\n",
            " [  378  1209 14145   424  2930  4914]\n",
            " [  144  1155   216 20707  1408   213]\n",
            " [  485  1843   938   718 19088   936]\n",
            " [  436  1306  6297   318  3006 12539]]\n",
            "\n",
            "\n",
            "Reports (Precision - Recall - F1 Score)\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.86      0.86      0.86     24325\n",
            "          1       0.71      0.78      0.75     23922\n",
            "          2       0.64      0.59      0.61     24000\n",
            "          3       0.91      0.87      0.89     23843\n",
            "          4       0.66      0.80      0.72     24008\n",
            "          5       0.64      0.52      0.58     23902\n",
            "\n",
            "avg / total       0.74      0.74      0.73    144000\n",
            "\n",
            "----------------------------VALIDATION DATA-------------------------------\n",
            "\n",
            "\n",
            "Matriz de Confusão validation_data :\n",
            " \n",
            "[[6678  881   73   71  179   74]\n",
            " [ 527 6455  143  202  533  206]\n",
            " [ 175  535 4521  232  860 1679]\n",
            " [  44  483   67 6994  355   82]\n",
            " [ 188  822  311  407 6018  290]\n",
            " [ 143  581 2199  171  864 3957]]\n",
            "\n",
            "\n",
            "Reports (Precision - Recall - F1 Score)\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.86      0.84      0.85      7956\n",
            "          1       0.66      0.80      0.72      8066\n",
            "          2       0.62      0.56      0.59      8002\n",
            "          3       0.87      0.87      0.87      8025\n",
            "          4       0.68      0.75      0.71      8036\n",
            "          5       0.63      0.50      0.56      7915\n",
            "\n",
            "avg / total       0.72      0.72      0.72     48000\n",
            "\n",
            "----------------------------TESTING DATA-------------------------------\n",
            "\n",
            "\n",
            "Matriz de Confusão testing_data : \n",
            "\n",
            "[[6598  908   65   83  187   75]\n",
            " [ 528 6418  135  187  492  213]\n",
            " [ 162  519 4537  201  859 1787]\n",
            " [  52  465   67 6950  348   74]\n",
            " [ 196  819  330  410 5955  324]\n",
            " [ 150  645 2193  150  811 4108]]\n",
            "\n",
            "\n",
            "Reports (Precision - Recall - F1 Score)\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.86      0.83      0.85      7916\n",
            "          1       0.66      0.80      0.72      7973\n",
            "          2       0.62      0.56      0.59      8065\n",
            "          3       0.87      0.87      0.87      7956\n",
            "          4       0.69      0.74      0.71      8034\n",
            "          5       0.62      0.51      0.56      8057\n",
            "\n",
            "avg / total       0.72      0.72      0.72     48001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zlNZDhSECVdG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Log loss on the cross validation sample"
      ]
    },
    {
      "metadata": {
        "id": "bIO7vK0CCVdk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras neural network\n",
        "\n",
        "On this step your task is to train **Keras** NN classifier to provide lower **log loss** value.\n",
        "\n",
        "\n",
        "TASK: your task is to tune the classifier parameters to achieve the lowest **log loss** value on the validation sample you can. Data preprocessing may help you to improve your score."
      ]
    },
    {
      "metadata": {
        "id": "8hQhZJS7CVdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers, regularizers\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.layers import BatchNormalization\n",
        "from keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from keras.metrics import categorical_accuracy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2PZezDAdTYmu",
        "colab_type": "code",
        "outputId": "d008b7ef-81ce-4f6c-e5ff-29cb0cdb9c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46481
        }
      },
      "cell_type": "code",
      "source": [
        "numpy.random.seed(7)\n",
        "v = 8\n",
        "i = 49\n",
        "#init = ['Zeros', 'Ones', 'Constant', 'RandomNormal', 'RandomUniform', 'TruncatedNormal', 'VarianceScaling', 'Orthogonal', 'Identity', 'lecun_uniform', 'glorot_normal', 'glorot_uniform', 'he_normal', 'lecun_normal', 'he_uniform']\n",
        "#for it in init:\n",
        "#for i in ivar:\n",
        "#    for v in var:\n",
        "input_dim = i\n",
        "hidden = int(108000/(v*(i+6)))\n",
        "\n",
        "\n",
        "def nn_model(input_dim):\n",
        "    model = Sequential() \n",
        "    \n",
        "    model.add(Dense(hidden, kernel_regularizer=regularizers.l2(0.001), input_dim=input_dim))\n",
        "    model.add(layers.BatchNormalization(axis=1))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    \n",
        "    model.add(Dense(hidden ))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(layers.BatchNormalization(axis=1))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(6))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=False)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "nn = nn_model(49)\n",
        "nn.fit(X_train_sc, np_utils.to_categorical(y_train), verbose=1, nb_epoch=1300, batch_size=512)\n",
        "proba_nn = nn.predict_proba(X_val_sc)\n",
        "logloss = log_loss(y_val, proba_nn)\n",
        "acc = categorical_accuracy(y_val, proba_nn)\n",
        "\n",
        "print (acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1300\n",
            "144000/144000 [==============================] - 6s 43us/step - loss: 1.4290 - acc: 0.4637\n",
            "Epoch 2/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 1.2384 - acc: 0.5447\n",
            "Epoch 3/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 1.1621 - acc: 0.5765\n",
            "Epoch 4/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 1.1019 - acc: 0.5989\n",
            "Epoch 5/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 1.0485 - acc: 0.6168\n",
            "Epoch 6/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 1.0004 - acc: 0.6334\n",
            "Epoch 7/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.9705 - acc: 0.6425\n",
            "Epoch 8/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.9443 - acc: 0.6547\n",
            "Epoch 9/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.9249 - acc: 0.6601\n",
            "Epoch 10/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.9009 - acc: 0.6696\n",
            "Epoch 11/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8810 - acc: 0.6764\n",
            "Epoch 12/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8629 - acc: 0.6826\n",
            "Epoch 13/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8495 - acc: 0.6893\n",
            "Epoch 14/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8404 - acc: 0.6924\n",
            "Epoch 15/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8286 - acc: 0.6965\n",
            "Epoch 16/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8219 - acc: 0.6988\n",
            "Epoch 17/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8147 - acc: 0.7028\n",
            "Epoch 18/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8067 - acc: 0.7038\n",
            "Epoch 19/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.8011 - acc: 0.7064\n",
            "Epoch 20/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7945 - acc: 0.7086\n",
            "Epoch 21/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7905 - acc: 0.7102\n",
            "Epoch 22/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7857 - acc: 0.7116\n",
            "Epoch 23/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7791 - acc: 0.7144\n",
            "Epoch 24/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7755 - acc: 0.7148\n",
            "Epoch 25/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7726 - acc: 0.7153\n",
            "Epoch 26/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7698 - acc: 0.7161\n",
            "Epoch 27/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7657 - acc: 0.7180\n",
            "Epoch 28/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7627 - acc: 0.7173\n",
            "Epoch 29/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7578 - acc: 0.7201\n",
            "Epoch 30/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7561 - acc: 0.7212\n",
            "Epoch 31/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7533 - acc: 0.7215\n",
            "Epoch 32/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7504 - acc: 0.7220\n",
            "Epoch 33/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7485 - acc: 0.7224\n",
            "Epoch 34/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7447 - acc: 0.7234\n",
            "Epoch 35/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7441 - acc: 0.7239\n",
            "Epoch 36/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7413 - acc: 0.7239\n",
            "Epoch 37/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7390 - acc: 0.7248\n",
            "Epoch 38/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7363 - acc: 0.7255\n",
            "Epoch 39/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7346 - acc: 0.7266\n",
            "Epoch 40/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7327 - acc: 0.7261\n",
            "Epoch 41/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7287 - acc: 0.7270\n",
            "Epoch 42/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7274 - acc: 0.7277\n",
            "Epoch 43/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7255 - acc: 0.7277\n",
            "Epoch 44/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7242 - acc: 0.7290\n",
            "Epoch 45/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7226 - acc: 0.7286\n",
            "Epoch 46/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7209 - acc: 0.7300\n",
            "Epoch 47/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7194 - acc: 0.7304\n",
            "Epoch 48/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7165 - acc: 0.7301\n",
            "Epoch 49/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7168 - acc: 0.7309\n",
            "Epoch 50/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7150 - acc: 0.7316\n",
            "Epoch 51/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7115 - acc: 0.7316\n",
            "Epoch 52/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7114 - acc: 0.7307\n",
            "Epoch 53/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7097 - acc: 0.7326\n",
            "Epoch 54/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7094 - acc: 0.7316\n",
            "Epoch 55/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7073 - acc: 0.7335\n",
            "Epoch 56/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7051 - acc: 0.7329\n",
            "Epoch 57/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7038 - acc: 0.7337\n",
            "Epoch 58/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.7039 - acc: 0.7338\n",
            "Epoch 59/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7023 - acc: 0.7336\n",
            "Epoch 60/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.7009 - acc: 0.7346\n",
            "Epoch 61/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6991 - acc: 0.7342\n",
            "Epoch 62/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6978 - acc: 0.7340\n",
            "Epoch 63/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6972 - acc: 0.7348\n",
            "Epoch 64/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6962 - acc: 0.7352\n",
            "Epoch 65/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6949 - acc: 0.7353\n",
            "Epoch 66/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6938 - acc: 0.7351\n",
            "Epoch 67/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6921 - acc: 0.7358\n",
            "Epoch 68/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6912 - acc: 0.7359\n",
            "Epoch 69/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6892 - acc: 0.7367\n",
            "Epoch 70/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6889 - acc: 0.7363\n",
            "Epoch 71/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6883 - acc: 0.7375\n",
            "Epoch 72/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6864 - acc: 0.7381\n",
            "Epoch 73/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6854 - acc: 0.7386\n",
            "Epoch 74/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6843 - acc: 0.7384\n",
            "Epoch 75/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6840 - acc: 0.7389\n",
            "Epoch 76/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6847 - acc: 0.7377\n",
            "Epoch 77/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6828 - acc: 0.7385\n",
            "Epoch 78/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6799 - acc: 0.7391\n",
            "Epoch 79/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6818 - acc: 0.7377\n",
            "Epoch 80/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6799 - acc: 0.7379\n",
            "Epoch 81/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6770 - acc: 0.7403\n",
            "Epoch 82/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6783 - acc: 0.7390\n",
            "Epoch 83/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6786 - acc: 0.7399\n",
            "Epoch 84/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6763 - acc: 0.7394\n",
            "Epoch 85/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6764 - acc: 0.7397\n",
            "Epoch 86/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6756 - acc: 0.7395\n",
            "Epoch 87/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6752 - acc: 0.7399\n",
            "Epoch 88/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6748 - acc: 0.7392\n",
            "Epoch 89/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6728 - acc: 0.7407\n",
            "Epoch 90/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6737 - acc: 0.7399\n",
            "Epoch 91/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6720 - acc: 0.7405\n",
            "Epoch 92/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6701 - acc: 0.7409\n",
            "Epoch 93/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6692 - acc: 0.7408\n",
            "Epoch 94/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6712 - acc: 0.7395\n",
            "Epoch 95/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6679 - acc: 0.7409\n",
            "Epoch 96/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6676 - acc: 0.7410\n",
            "Epoch 97/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6677 - acc: 0.7410\n",
            "Epoch 98/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6662 - acc: 0.7417\n",
            "Epoch 99/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6651 - acc: 0.7424\n",
            "Epoch 100/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6644 - acc: 0.7423\n",
            "Epoch 101/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6647 - acc: 0.7425\n",
            "Epoch 102/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6648 - acc: 0.7417\n",
            "Epoch 103/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6627 - acc: 0.7428\n",
            "Epoch 104/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6632 - acc: 0.7423\n",
            "Epoch 105/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6621 - acc: 0.7427\n",
            "Epoch 106/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6623 - acc: 0.7432\n",
            "Epoch 107/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6612 - acc: 0.7436\n",
            "Epoch 108/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6620 - acc: 0.7418\n",
            "Epoch 109/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6601 - acc: 0.7423\n",
            "Epoch 110/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6607 - acc: 0.7425\n",
            "Epoch 111/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6593 - acc: 0.7442\n",
            "Epoch 112/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6591 - acc: 0.7427\n",
            "Epoch 113/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6570 - acc: 0.7429\n",
            "Epoch 114/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6576 - acc: 0.7434\n",
            "Epoch 115/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6575 - acc: 0.7434\n",
            "Epoch 116/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6554 - acc: 0.7441\n",
            "Epoch 117/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6538 - acc: 0.7437\n",
            "Epoch 118/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6544 - acc: 0.7441\n",
            "Epoch 119/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6554 - acc: 0.7434\n",
            "Epoch 120/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6545 - acc: 0.7439\n",
            "Epoch 121/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6532 - acc: 0.7451\n",
            "Epoch 122/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6536 - acc: 0.7435\n",
            "Epoch 123/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6536 - acc: 0.7436\n",
            "Epoch 124/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6526 - acc: 0.7444\n",
            "Epoch 125/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6513 - acc: 0.7450\n",
            "Epoch 126/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6527 - acc: 0.7442\n",
            "Epoch 127/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6509 - acc: 0.7442\n",
            "Epoch 128/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6499 - acc: 0.7443\n",
            "Epoch 129/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6510 - acc: 0.7445\n",
            "Epoch 130/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6484 - acc: 0.7451\n",
            "Epoch 131/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6489 - acc: 0.7453\n",
            "Epoch 132/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6482 - acc: 0.7454\n",
            "Epoch 133/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6496 - acc: 0.7448\n",
            "Epoch 134/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6488 - acc: 0.7453\n",
            "Epoch 135/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6486 - acc: 0.7446\n",
            "Epoch 136/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6462 - acc: 0.7452\n",
            "Epoch 137/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6459 - acc: 0.7456\n",
            "Epoch 138/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6469 - acc: 0.7449\n",
            "Epoch 139/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6460 - acc: 0.7465\n",
            "Epoch 140/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6458 - acc: 0.7465\n",
            "Epoch 141/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6447 - acc: 0.7459\n",
            "Epoch 142/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6443 - acc: 0.7457\n",
            "Epoch 143/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6472 - acc: 0.7452\n",
            "Epoch 144/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6448 - acc: 0.7460\n",
            "Epoch 145/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6447 - acc: 0.7461\n",
            "Epoch 146/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6430 - acc: 0.7449\n",
            "Epoch 147/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6429 - acc: 0.7460\n",
            "Epoch 148/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6428 - acc: 0.7460\n",
            "Epoch 149/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6416 - acc: 0.7465\n",
            "Epoch 150/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6422 - acc: 0.7475\n",
            "Epoch 151/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6398 - acc: 0.7466\n",
            "Epoch 152/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6400 - acc: 0.7480\n",
            "Epoch 153/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6405 - acc: 0.7474\n",
            "Epoch 154/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6405 - acc: 0.7468\n",
            "Epoch 155/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6402 - acc: 0.7461\n",
            "Epoch 156/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6406 - acc: 0.7472\n",
            "Epoch 157/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6391 - acc: 0.7465\n",
            "Epoch 158/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6391 - acc: 0.7468\n",
            "Epoch 159/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6387 - acc: 0.7483\n",
            "Epoch 160/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6394 - acc: 0.7456\n",
            "Epoch 161/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.6386 - acc: 0.7472\n",
            "Epoch 162/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6379 - acc: 0.7473\n",
            "Epoch 163/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6371 - acc: 0.7478\n",
            "Epoch 164/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6365 - acc: 0.7480\n",
            "Epoch 165/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6375 - acc: 0.7481\n",
            "Epoch 166/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6367 - acc: 0.7471\n",
            "Epoch 167/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6360 - acc: 0.7481\n",
            "Epoch 168/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6367 - acc: 0.7472\n",
            "Epoch 169/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6357 - acc: 0.7472\n",
            "Epoch 170/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6355 - acc: 0.7482\n",
            "Epoch 171/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6346 - acc: 0.7480\n",
            "Epoch 172/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6350 - acc: 0.7479\n",
            "Epoch 173/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6348 - acc: 0.7487\n",
            "Epoch 174/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6348 - acc: 0.7485\n",
            "Epoch 175/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6347 - acc: 0.7480\n",
            "Epoch 176/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6348 - acc: 0.7469\n",
            "Epoch 177/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6337 - acc: 0.7499\n",
            "Epoch 178/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6324 - acc: 0.7486\n",
            "Epoch 179/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6335 - acc: 0.7472\n",
            "Epoch 180/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6333 - acc: 0.7485\n",
            "Epoch 181/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6316 - acc: 0.7491\n",
            "Epoch 182/1300\n",
            "144000/144000 [==============================] - 4s 25us/step - loss: 0.6323 - acc: 0.7495\n",
            "Epoch 183/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.6327 - acc: 0.7489\n",
            "Epoch 184/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6320 - acc: 0.7491\n",
            "Epoch 185/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6320 - acc: 0.7482\n",
            "Epoch 186/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6327 - acc: 0.7486\n",
            "Epoch 187/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6311 - acc: 0.7485\n",
            "Epoch 188/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6322 - acc: 0.7492\n",
            "Epoch 189/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6312 - acc: 0.7491\n",
            "Epoch 190/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6306 - acc: 0.7488\n",
            "Epoch 191/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6302 - acc: 0.7493\n",
            "Epoch 192/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6308 - acc: 0.7495\n",
            "Epoch 193/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6307 - acc: 0.7490\n",
            "Epoch 194/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6291 - acc: 0.7489\n",
            "Epoch 195/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6297 - acc: 0.7493\n",
            "Epoch 196/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6306 - acc: 0.7483\n",
            "Epoch 197/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6293 - acc: 0.7495\n",
            "Epoch 198/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6297 - acc: 0.7481\n",
            "Epoch 199/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6280 - acc: 0.7508\n",
            "Epoch 200/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6294 - acc: 0.7489\n",
            "Epoch 201/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6287 - acc: 0.7495\n",
            "Epoch 202/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6267 - acc: 0.7509\n",
            "Epoch 203/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6289 - acc: 0.7489\n",
            "Epoch 204/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6292 - acc: 0.7486\n",
            "Epoch 205/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6289 - acc: 0.7491\n",
            "Epoch 206/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6278 - acc: 0.7486\n",
            "Epoch 207/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6280 - acc: 0.7503\n",
            "Epoch 208/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6271 - acc: 0.7511\n",
            "Epoch 209/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6282 - acc: 0.7490\n",
            "Epoch 210/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6268 - acc: 0.7498\n",
            "Epoch 211/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6264 - acc: 0.7506\n",
            "Epoch 212/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6253 - acc: 0.7510\n",
            "Epoch 213/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6254 - acc: 0.7502\n",
            "Epoch 214/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6249 - acc: 0.7502\n",
            "Epoch 215/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6257 - acc: 0.7501\n",
            "Epoch 216/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6261 - acc: 0.7491\n",
            "Epoch 217/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6262 - acc: 0.7502\n",
            "Epoch 218/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6252 - acc: 0.7504\n",
            "Epoch 219/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6256 - acc: 0.7503\n",
            "Epoch 220/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6248 - acc: 0.7513\n",
            "Epoch 221/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6250 - acc: 0.7515\n",
            "Epoch 222/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6248 - acc: 0.7502\n",
            "Epoch 223/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6244 - acc: 0.7509\n",
            "Epoch 224/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6237 - acc: 0.7499\n",
            "Epoch 225/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6250 - acc: 0.7509\n",
            "Epoch 226/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6233 - acc: 0.7513\n",
            "Epoch 227/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6241 - acc: 0.7498\n",
            "Epoch 228/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6229 - acc: 0.7505\n",
            "Epoch 229/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6221 - acc: 0.7521\n",
            "Epoch 230/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6238 - acc: 0.7517\n",
            "Epoch 231/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6227 - acc: 0.7524\n",
            "Epoch 232/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6215 - acc: 0.7518\n",
            "Epoch 233/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6227 - acc: 0.7515\n",
            "Epoch 234/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6216 - acc: 0.7529\n",
            "Epoch 235/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6211 - acc: 0.7522\n",
            "Epoch 236/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6233 - acc: 0.7512\n",
            "Epoch 237/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6233 - acc: 0.7504\n",
            "Epoch 238/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6221 - acc: 0.7516\n",
            "Epoch 239/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6215 - acc: 0.7511\n",
            "Epoch 240/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6215 - acc: 0.7516\n",
            "Epoch 241/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6214 - acc: 0.7518\n",
            "Epoch 242/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6217 - acc: 0.7513\n",
            "Epoch 243/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6223 - acc: 0.7506\n",
            "Epoch 244/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6221 - acc: 0.7514\n",
            "Epoch 245/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6189 - acc: 0.7527\n",
            "Epoch 246/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6208 - acc: 0.7519\n",
            "Epoch 247/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6206 - acc: 0.7514\n",
            "Epoch 248/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6200 - acc: 0.7517\n",
            "Epoch 249/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6211 - acc: 0.7515\n",
            "Epoch 250/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6207 - acc: 0.7525\n",
            "Epoch 251/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6207 - acc: 0.7521\n",
            "Epoch 252/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6206 - acc: 0.7512\n",
            "Epoch 253/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6200 - acc: 0.7524\n",
            "Epoch 254/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6196 - acc: 0.7529\n",
            "Epoch 255/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6192 - acc: 0.7529\n",
            "Epoch 256/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6203 - acc: 0.7505\n",
            "Epoch 257/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6187 - acc: 0.7528\n",
            "Epoch 258/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6196 - acc: 0.7518\n",
            "Epoch 259/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6193 - acc: 0.7515\n",
            "Epoch 260/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6187 - acc: 0.7522\n",
            "Epoch 261/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6193 - acc: 0.7507\n",
            "Epoch 262/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6189 - acc: 0.7528\n",
            "Epoch 263/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6190 - acc: 0.7522\n",
            "Epoch 264/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6185 - acc: 0.7517\n",
            "Epoch 265/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6192 - acc: 0.7527\n",
            "Epoch 266/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6194 - acc: 0.7519\n",
            "Epoch 267/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6197 - acc: 0.7525\n",
            "Epoch 268/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6176 - acc: 0.7522\n",
            "Epoch 269/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6172 - acc: 0.7533\n",
            "Epoch 270/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6178 - acc: 0.7531\n",
            "Epoch 271/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6177 - acc: 0.7519\n",
            "Epoch 272/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6186 - acc: 0.7527\n",
            "Epoch 273/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6170 - acc: 0.7531\n",
            "Epoch 274/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6189 - acc: 0.7516\n",
            "Epoch 275/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6179 - acc: 0.7531\n",
            "Epoch 276/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6170 - acc: 0.7531\n",
            "Epoch 277/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6165 - acc: 0.7529\n",
            "Epoch 278/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6167 - acc: 0.7536\n",
            "Epoch 279/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6161 - acc: 0.7536\n",
            "Epoch 280/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6165 - acc: 0.7519\n",
            "Epoch 281/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6171 - acc: 0.7520\n",
            "Epoch 282/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6149 - acc: 0.7529\n",
            "Epoch 283/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6174 - acc: 0.7521\n",
            "Epoch 284/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6155 - acc: 0.7533\n",
            "Epoch 285/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6164 - acc: 0.7523\n",
            "Epoch 286/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6165 - acc: 0.7521\n",
            "Epoch 287/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6149 - acc: 0.7536\n",
            "Epoch 288/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6155 - acc: 0.7529\n",
            "Epoch 289/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6166 - acc: 0.7520\n",
            "Epoch 290/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6166 - acc: 0.7531\n",
            "Epoch 291/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6151 - acc: 0.7535\n",
            "Epoch 292/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6151 - acc: 0.7537\n",
            "Epoch 293/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6155 - acc: 0.7531\n",
            "Epoch 294/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6153 - acc: 0.7543\n",
            "Epoch 295/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6151 - acc: 0.7528\n",
            "Epoch 296/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6155 - acc: 0.7534\n",
            "Epoch 297/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6143 - acc: 0.7531\n",
            "Epoch 298/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6144 - acc: 0.7525\n",
            "Epoch 299/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6155 - acc: 0.7522\n",
            "Epoch 300/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6156 - acc: 0.7533\n",
            "Epoch 301/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6149 - acc: 0.7542\n",
            "Epoch 302/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6141 - acc: 0.7536\n",
            "Epoch 303/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6152 - acc: 0.7541\n",
            "Epoch 304/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6153 - acc: 0.7529\n",
            "Epoch 305/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6151 - acc: 0.7526\n",
            "Epoch 306/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6146 - acc: 0.7538\n",
            "Epoch 307/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6144 - acc: 0.7533\n",
            "Epoch 308/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6134 - acc: 0.7533\n",
            "Epoch 309/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6141 - acc: 0.7531\n",
            "Epoch 310/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6135 - acc: 0.7536\n",
            "Epoch 311/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6135 - acc: 0.7536\n",
            "Epoch 312/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6138 - acc: 0.7541\n",
            "Epoch 313/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6132 - acc: 0.7539\n",
            "Epoch 314/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6122 - acc: 0.7539\n",
            "Epoch 315/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6141 - acc: 0.7539\n",
            "Epoch 316/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6140 - acc: 0.7535\n",
            "Epoch 317/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6120 - acc: 0.7547\n",
            "Epoch 318/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6128 - acc: 0.7531\n",
            "Epoch 319/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6121 - acc: 0.7545\n",
            "Epoch 320/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6131 - acc: 0.7535\n",
            "Epoch 321/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6125 - acc: 0.7544\n",
            "Epoch 322/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6122 - acc: 0.7535\n",
            "Epoch 323/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6120 - acc: 0.7548\n",
            "Epoch 324/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6121 - acc: 0.7553\n",
            "Epoch 325/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6127 - acc: 0.7547\n",
            "Epoch 326/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6122 - acc: 0.7547\n",
            "Epoch 327/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6114 - acc: 0.7550\n",
            "Epoch 328/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6115 - acc: 0.7547\n",
            "Epoch 329/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6118 - acc: 0.7556\n",
            "Epoch 330/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6125 - acc: 0.7532\n",
            "Epoch 331/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6113 - acc: 0.7544\n",
            "Epoch 332/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6113 - acc: 0.7542\n",
            "Epoch 333/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6121 - acc: 0.7542\n",
            "Epoch 334/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6113 - acc: 0.7533\n",
            "Epoch 335/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6115 - acc: 0.7548\n",
            "Epoch 336/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6122 - acc: 0.7548\n",
            "Epoch 337/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6113 - acc: 0.7550\n",
            "Epoch 338/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6113 - acc: 0.7544\n",
            "Epoch 339/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6106 - acc: 0.7547\n",
            "Epoch 340/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6113 - acc: 0.7541\n",
            "Epoch 341/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6101 - acc: 0.7543\n",
            "Epoch 342/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6102 - acc: 0.7546\n",
            "Epoch 343/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6088 - acc: 0.7558\n",
            "Epoch 344/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6103 - acc: 0.7548\n",
            "Epoch 345/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.6106 - acc: 0.7545\n",
            "Epoch 346/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6109 - acc: 0.7550\n",
            "Epoch 347/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6103 - acc: 0.7552\n",
            "Epoch 348/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6104 - acc: 0.7553\n",
            "Epoch 349/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6104 - acc: 0.7548\n",
            "Epoch 350/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6100 - acc: 0.7559\n",
            "Epoch 351/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6092 - acc: 0.7558\n",
            "Epoch 352/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6111 - acc: 0.7549\n",
            "Epoch 353/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6096 - acc: 0.7556\n",
            "Epoch 354/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6106 - acc: 0.7539\n",
            "Epoch 355/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6081 - acc: 0.7566\n",
            "Epoch 356/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6099 - acc: 0.7553\n",
            "Epoch 357/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6088 - acc: 0.7560\n",
            "Epoch 358/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6108 - acc: 0.7548\n",
            "Epoch 359/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6108 - acc: 0.7548\n",
            "Epoch 360/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6090 - acc: 0.7559\n",
            "Epoch 361/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6106 - acc: 0.7549\n",
            "Epoch 362/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6098 - acc: 0.7551\n",
            "Epoch 363/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6105 - acc: 0.7555\n",
            "Epoch 364/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6092 - acc: 0.7555\n",
            "Epoch 365/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6085 - acc: 0.7553\n",
            "Epoch 366/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6092 - acc: 0.7550\n",
            "Epoch 367/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6093 - acc: 0.7552\n",
            "Epoch 368/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6091 - acc: 0.7554\n",
            "Epoch 369/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6089 - acc: 0.7552\n",
            "Epoch 370/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6096 - acc: 0.7549\n",
            "Epoch 371/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6080 - acc: 0.7558\n",
            "Epoch 372/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6075 - acc: 0.7561\n",
            "Epoch 373/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6082 - acc: 0.7551\n",
            "Epoch 374/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6082 - acc: 0.7553\n",
            "Epoch 375/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6068 - acc: 0.7556\n",
            "Epoch 376/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6075 - acc: 0.7559\n",
            "Epoch 377/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6078 - acc: 0.7554\n",
            "Epoch 378/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6082 - acc: 0.7545\n",
            "Epoch 379/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6077 - acc: 0.7560\n",
            "Epoch 380/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6072 - acc: 0.7561\n",
            "Epoch 381/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6082 - acc: 0.7557\n",
            "Epoch 382/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6074 - acc: 0.7563\n",
            "Epoch 383/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6076 - acc: 0.7557\n",
            "Epoch 384/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6081 - acc: 0.7550\n",
            "Epoch 385/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6080 - acc: 0.7555\n",
            "Epoch 386/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6078 - acc: 0.7560\n",
            "Epoch 387/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6078 - acc: 0.7559\n",
            "Epoch 388/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6062 - acc: 0.7561\n",
            "Epoch 389/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6067 - acc: 0.7563\n",
            "Epoch 390/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6065 - acc: 0.7555\n",
            "Epoch 391/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6063 - acc: 0.7559\n",
            "Epoch 392/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6057 - acc: 0.7564\n",
            "Epoch 393/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6072 - acc: 0.7557\n",
            "Epoch 394/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6068 - acc: 0.7564\n",
            "Epoch 395/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6073 - acc: 0.7566\n",
            "Epoch 396/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6074 - acc: 0.7562\n",
            "Epoch 397/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6079 - acc: 0.7556\n",
            "Epoch 398/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6072 - acc: 0.7553\n",
            "Epoch 399/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6064 - acc: 0.7563\n",
            "Epoch 400/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6070 - acc: 0.7559\n",
            "Epoch 401/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6063 - acc: 0.7560\n",
            "Epoch 402/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6069 - acc: 0.7563\n",
            "Epoch 403/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6071 - acc: 0.7563\n",
            "Epoch 404/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6058 - acc: 0.7556\n",
            "Epoch 405/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6041 - acc: 0.7573\n",
            "Epoch 406/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6045 - acc: 0.7563\n",
            "Epoch 407/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6064 - acc: 0.7547\n",
            "Epoch 408/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6054 - acc: 0.7565\n",
            "Epoch 409/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6069 - acc: 0.7563\n",
            "Epoch 410/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6060 - acc: 0.7567\n",
            "Epoch 411/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6053 - acc: 0.7562\n",
            "Epoch 412/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6063 - acc: 0.7564\n",
            "Epoch 413/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6054 - acc: 0.7569\n",
            "Epoch 414/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6053 - acc: 0.7555\n",
            "Epoch 415/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6059 - acc: 0.7556\n",
            "Epoch 416/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6053 - acc: 0.7560\n",
            "Epoch 417/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6061 - acc: 0.7572\n",
            "Epoch 418/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6041 - acc: 0.7576\n",
            "Epoch 419/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6059 - acc: 0.7556\n",
            "Epoch 420/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6058 - acc: 0.7568\n",
            "Epoch 421/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6044 - acc: 0.7566\n",
            "Epoch 422/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6052 - acc: 0.7571\n",
            "Epoch 423/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6045 - acc: 0.7564\n",
            "Epoch 424/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6061 - acc: 0.7571\n",
            "Epoch 425/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6053 - acc: 0.7559\n",
            "Epoch 426/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6045 - acc: 0.7568\n",
            "Epoch 427/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6056 - acc: 0.7556\n",
            "Epoch 428/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6046 - acc: 0.7572\n",
            "Epoch 429/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6044 - acc: 0.7564\n",
            "Epoch 430/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6038 - acc: 0.7571\n",
            "Epoch 431/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6053 - acc: 0.7568\n",
            "Epoch 432/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6033 - acc: 0.7571\n",
            "Epoch 433/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6040 - acc: 0.7568\n",
            "Epoch 434/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6035 - acc: 0.7570\n",
            "Epoch 435/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6044 - acc: 0.7580\n",
            "Epoch 436/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6040 - acc: 0.7570\n",
            "Epoch 437/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.6044 - acc: 0.7567\n",
            "Epoch 438/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.6041 - acc: 0.7575\n",
            "Epoch 439/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6040 - acc: 0.7571\n",
            "Epoch 440/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6032 - acc: 0.7578\n",
            "Epoch 441/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6045 - acc: 0.7565\n",
            "Epoch 442/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6036 - acc: 0.7578\n",
            "Epoch 443/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6044 - acc: 0.7568\n",
            "Epoch 444/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6044 - acc: 0.7563\n",
            "Epoch 445/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6023 - acc: 0.7582\n",
            "Epoch 446/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6035 - acc: 0.7579\n",
            "Epoch 447/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6030 - acc: 0.7579\n",
            "Epoch 448/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6042 - acc: 0.7578\n",
            "Epoch 449/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6038 - acc: 0.7574\n",
            "Epoch 450/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6026 - acc: 0.7584\n",
            "Epoch 451/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6048 - acc: 0.7563\n",
            "Epoch 452/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6026 - acc: 0.7584\n",
            "Epoch 453/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6037 - acc: 0.7568\n",
            "Epoch 454/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6029 - acc: 0.7571\n",
            "Epoch 455/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6024 - acc: 0.7583\n",
            "Epoch 456/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6022 - acc: 0.7573\n",
            "Epoch 457/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6010 - acc: 0.7575\n",
            "Epoch 458/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6028 - acc: 0.7573\n",
            "Epoch 459/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6016 - acc: 0.7570\n",
            "Epoch 460/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6021 - acc: 0.7567\n",
            "Epoch 461/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6033 - acc: 0.7575\n",
            "Epoch 462/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6017 - acc: 0.7579\n",
            "Epoch 463/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6019 - acc: 0.7577\n",
            "Epoch 464/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6022 - acc: 0.7576\n",
            "Epoch 465/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6015 - acc: 0.7573\n",
            "Epoch 466/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6028 - acc: 0.7576\n",
            "Epoch 467/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6026 - acc: 0.7576\n",
            "Epoch 468/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6017 - acc: 0.7585\n",
            "Epoch 469/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6024 - acc: 0.7577\n",
            "Epoch 470/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6012 - acc: 0.7578\n",
            "Epoch 471/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6012 - acc: 0.7585\n",
            "Epoch 472/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6020 - acc: 0.7579\n",
            "Epoch 473/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6016 - acc: 0.7583\n",
            "Epoch 474/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6021 - acc: 0.7571\n",
            "Epoch 475/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6026 - acc: 0.7575\n",
            "Epoch 476/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6023 - acc: 0.7574\n",
            "Epoch 477/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6010 - acc: 0.7582\n",
            "Epoch 478/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6024 - acc: 0.7571\n",
            "Epoch 479/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6028 - acc: 0.7573\n",
            "Epoch 480/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6013 - acc: 0.7572\n",
            "Epoch 481/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6011 - acc: 0.7584\n",
            "Epoch 482/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6009 - acc: 0.7580\n",
            "Epoch 483/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6016 - acc: 0.7581\n",
            "Epoch 484/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6018 - acc: 0.7579\n",
            "Epoch 485/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.6018 - acc: 0.7576\n",
            "Epoch 486/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6016 - acc: 0.7579\n",
            "Epoch 487/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6012 - acc: 0.7584\n",
            "Epoch 488/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6012 - acc: 0.7582\n",
            "Epoch 489/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6006 - acc: 0.7582\n",
            "Epoch 490/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6010 - acc: 0.7582\n",
            "Epoch 491/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6010 - acc: 0.7586\n",
            "Epoch 492/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6009 - acc: 0.7587\n",
            "Epoch 493/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6008 - acc: 0.7580\n",
            "Epoch 494/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6004 - acc: 0.7574\n",
            "Epoch 495/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6011 - acc: 0.7581\n",
            "Epoch 496/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6007 - acc: 0.7589\n",
            "Epoch 497/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6014 - acc: 0.7580\n",
            "Epoch 498/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6010 - acc: 0.7579\n",
            "Epoch 499/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6020 - acc: 0.7578\n",
            "Epoch 500/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6013 - acc: 0.7574\n",
            "Epoch 501/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6007 - acc: 0.7584\n",
            "Epoch 502/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6006 - acc: 0.7591\n",
            "Epoch 503/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6001 - acc: 0.7578\n",
            "Epoch 504/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6002 - acc: 0.7583\n",
            "Epoch 505/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5998 - acc: 0.7586\n",
            "Epoch 506/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5997 - acc: 0.7579\n",
            "Epoch 507/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6008 - acc: 0.7570\n",
            "Epoch 508/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6009 - acc: 0.7575\n",
            "Epoch 509/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5998 - acc: 0.7582\n",
            "Epoch 510/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5996 - acc: 0.7592\n",
            "Epoch 511/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5988 - acc: 0.7600\n",
            "Epoch 512/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6002 - acc: 0.7583\n",
            "Epoch 513/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6004 - acc: 0.7580\n",
            "Epoch 514/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5992 - acc: 0.7594\n",
            "Epoch 515/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5988 - acc: 0.7595\n",
            "Epoch 516/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5997 - acc: 0.7592\n",
            "Epoch 517/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5984 - acc: 0.7594\n",
            "Epoch 518/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5979 - acc: 0.7604\n",
            "Epoch 519/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6009 - acc: 0.7587\n",
            "Epoch 520/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5994 - acc: 0.7591\n",
            "Epoch 521/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6003 - acc: 0.7573\n",
            "Epoch 522/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5986 - acc: 0.7593\n",
            "Epoch 523/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5984 - acc: 0.7595\n",
            "Epoch 524/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5999 - acc: 0.7574\n",
            "Epoch 525/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5984 - acc: 0.7593\n",
            "Epoch 526/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6000 - acc: 0.7587\n",
            "Epoch 527/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5997 - acc: 0.7588\n",
            "Epoch 528/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5987 - acc: 0.7593\n",
            "Epoch 529/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.6004 - acc: 0.7590\n",
            "Epoch 530/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5986 - acc: 0.7593\n",
            "Epoch 531/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5996 - acc: 0.7585\n",
            "Epoch 532/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5995 - acc: 0.7574\n",
            "Epoch 533/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5993 - acc: 0.7589\n",
            "Epoch 534/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5996 - acc: 0.7584\n",
            "Epoch 535/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5986 - acc: 0.7592\n",
            "Epoch 536/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5985 - acc: 0.7594\n",
            "Epoch 537/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5972 - acc: 0.7595\n",
            "Epoch 538/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5980 - acc: 0.7596\n",
            "Epoch 539/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5981 - acc: 0.7596\n",
            "Epoch 540/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5988 - acc: 0.7590\n",
            "Epoch 541/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5996 - acc: 0.7588\n",
            "Epoch 542/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5981 - acc: 0.7597\n",
            "Epoch 543/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5980 - acc: 0.7592\n",
            "Epoch 544/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5993 - acc: 0.7583\n",
            "Epoch 545/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5994 - acc: 0.7597\n",
            "Epoch 546/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5992 - acc: 0.7579\n",
            "Epoch 547/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5980 - acc: 0.7594\n",
            "Epoch 548/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5969 - acc: 0.7603\n",
            "Epoch 549/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5987 - acc: 0.7582\n",
            "Epoch 550/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5976 - acc: 0.7600\n",
            "Epoch 551/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5977 - acc: 0.7589\n",
            "Epoch 552/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5974 - acc: 0.7586\n",
            "Epoch 553/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5977 - acc: 0.7603\n",
            "Epoch 554/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5964 - acc: 0.7606\n",
            "Epoch 555/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5981 - acc: 0.7585\n",
            "Epoch 556/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5965 - acc: 0.7605\n",
            "Epoch 557/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5973 - acc: 0.7593\n",
            "Epoch 558/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5973 - acc: 0.7598\n",
            "Epoch 559/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5981 - acc: 0.7593\n",
            "Epoch 560/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5954 - acc: 0.7595\n",
            "Epoch 561/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5970 - acc: 0.7597\n",
            "Epoch 562/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5966 - acc: 0.7606\n",
            "Epoch 563/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5984 - acc: 0.7591\n",
            "Epoch 564/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5970 - acc: 0.7597\n",
            "Epoch 565/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5968 - acc: 0.7595\n",
            "Epoch 566/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5976 - acc: 0.7590\n",
            "Epoch 567/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5975 - acc: 0.7594\n",
            "Epoch 568/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5971 - acc: 0.7601\n",
            "Epoch 569/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5977 - acc: 0.7588\n",
            "Epoch 570/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5974 - acc: 0.7604\n",
            "Epoch 571/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5976 - acc: 0.7598\n",
            "Epoch 572/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5968 - acc: 0.7597\n",
            "Epoch 573/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5960 - acc: 0.7607\n",
            "Epoch 574/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5966 - acc: 0.7597\n",
            "Epoch 575/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5970 - acc: 0.7595\n",
            "Epoch 576/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5970 - acc: 0.7596\n",
            "Epoch 577/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5963 - acc: 0.7607\n",
            "Epoch 578/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5974 - acc: 0.7598\n",
            "Epoch 579/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5960 - acc: 0.7597\n",
            "Epoch 580/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5959 - acc: 0.7599\n",
            "Epoch 581/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5961 - acc: 0.7598\n",
            "Epoch 582/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5965 - acc: 0.7592\n",
            "Epoch 583/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5969 - acc: 0.7605\n",
            "Epoch 584/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5960 - acc: 0.7598\n",
            "Epoch 585/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5958 - acc: 0.7609\n",
            "Epoch 586/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5972 - acc: 0.7599\n",
            "Epoch 587/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5950 - acc: 0.7602\n",
            "Epoch 588/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5969 - acc: 0.7596\n",
            "Epoch 589/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5958 - acc: 0.7607\n",
            "Epoch 590/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5972 - acc: 0.7598\n",
            "Epoch 591/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5971 - acc: 0.7587\n",
            "Epoch 592/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5966 - acc: 0.7602\n",
            "Epoch 593/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5969 - acc: 0.7592\n",
            "Epoch 594/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5964 - acc: 0.7608\n",
            "Epoch 595/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5963 - acc: 0.7605\n",
            "Epoch 596/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5958 - acc: 0.7594\n",
            "Epoch 597/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5962 - acc: 0.7595\n",
            "Epoch 598/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5969 - acc: 0.7592\n",
            "Epoch 599/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5953 - acc: 0.7600\n",
            "Epoch 600/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5960 - acc: 0.7602\n",
            "Epoch 601/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5968 - acc: 0.7593\n",
            "Epoch 602/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5951 - acc: 0.7610\n",
            "Epoch 603/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5957 - acc: 0.7599\n",
            "Epoch 604/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5967 - acc: 0.7595\n",
            "Epoch 605/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5973 - acc: 0.7596\n",
            "Epoch 606/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5958 - acc: 0.7599\n",
            "Epoch 607/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5966 - acc: 0.7605\n",
            "Epoch 608/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5947 - acc: 0.7604\n",
            "Epoch 609/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5946 - acc: 0.7608\n",
            "Epoch 610/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5948 - acc: 0.7606\n",
            "Epoch 611/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5949 - acc: 0.7603\n",
            "Epoch 612/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5952 - acc: 0.7610\n",
            "Epoch 613/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5953 - acc: 0.7594\n",
            "Epoch 614/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5949 - acc: 0.7613\n",
            "Epoch 615/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5958 - acc: 0.7597\n",
            "Epoch 616/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5948 - acc: 0.7611\n",
            "Epoch 617/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5958 - acc: 0.7593\n",
            "Epoch 618/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5938 - acc: 0.7613\n",
            "Epoch 619/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5948 - acc: 0.7599\n",
            "Epoch 620/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5967 - acc: 0.7592\n",
            "Epoch 621/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5974 - acc: 0.7606\n",
            "Epoch 622/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5938 - acc: 0.7600\n",
            "Epoch 623/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5946 - acc: 0.7602\n",
            "Epoch 624/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5950 - acc: 0.7601\n",
            "Epoch 625/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5949 - acc: 0.7604\n",
            "Epoch 626/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5946 - acc: 0.7610\n",
            "Epoch 627/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5943 - acc: 0.7600\n",
            "Epoch 628/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5946 - acc: 0.7605\n",
            "Epoch 629/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5941 - acc: 0.7605\n",
            "Epoch 630/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5952 - acc: 0.7594\n",
            "Epoch 631/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5958 - acc: 0.7604\n",
            "Epoch 632/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5956 - acc: 0.7602\n",
            "Epoch 633/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5944 - acc: 0.7607\n",
            "Epoch 634/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5944 - acc: 0.7614\n",
            "Epoch 635/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5950 - acc: 0.7592\n",
            "Epoch 636/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5935 - acc: 0.7604\n",
            "Epoch 637/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5951 - acc: 0.7591\n",
            "Epoch 638/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.5947 - acc: 0.7605\n",
            "Epoch 639/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5940 - acc: 0.7611\n",
            "Epoch 640/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5937 - acc: 0.7601\n",
            "Epoch 641/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5940 - acc: 0.7607\n",
            "Epoch 642/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5939 - acc: 0.7607\n",
            "Epoch 643/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5942 - acc: 0.7609\n",
            "Epoch 644/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5949 - acc: 0.7596\n",
            "Epoch 645/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5941 - acc: 0.7602\n",
            "Epoch 646/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5944 - acc: 0.7612\n",
            "Epoch 647/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5941 - acc: 0.7613\n",
            "Epoch 648/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5935 - acc: 0.7610\n",
            "Epoch 649/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5932 - acc: 0.7615\n",
            "Epoch 650/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5953 - acc: 0.7610\n",
            "Epoch 651/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5939 - acc: 0.7602\n",
            "Epoch 652/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5935 - acc: 0.7611\n",
            "Epoch 653/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5935 - acc: 0.7614\n",
            "Epoch 654/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5928 - acc: 0.7613\n",
            "Epoch 655/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5937 - acc: 0.7607\n",
            "Epoch 656/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5935 - acc: 0.7610\n",
            "Epoch 657/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5937 - acc: 0.7607\n",
            "Epoch 658/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5940 - acc: 0.7610\n",
            "Epoch 659/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5932 - acc: 0.7613\n",
            "Epoch 660/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5939 - acc: 0.7611\n",
            "Epoch 661/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5938 - acc: 0.7613\n",
            "Epoch 662/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5947 - acc: 0.7596\n",
            "Epoch 663/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5938 - acc: 0.7610\n",
            "Epoch 664/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5939 - acc: 0.7613\n",
            "Epoch 665/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5941 - acc: 0.7606\n",
            "Epoch 666/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5928 - acc: 0.7608\n",
            "Epoch 667/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5928 - acc: 0.7613\n",
            "Epoch 668/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5922 - acc: 0.7607\n",
            "Epoch 669/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5935 - acc: 0.7611\n",
            "Epoch 670/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5934 - acc: 0.7615\n",
            "Epoch 671/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5932 - acc: 0.7611\n",
            "Epoch 672/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5928 - acc: 0.7615\n",
            "Epoch 673/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5931 - acc: 0.7606\n",
            "Epoch 674/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5938 - acc: 0.7612\n",
            "Epoch 675/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5914 - acc: 0.7620\n",
            "Epoch 676/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5937 - acc: 0.7601\n",
            "Epoch 677/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5930 - acc: 0.7607\n",
            "Epoch 678/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5923 - acc: 0.7609\n",
            "Epoch 679/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5932 - acc: 0.7614\n",
            "Epoch 680/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5920 - acc: 0.7611\n",
            "Epoch 681/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5923 - acc: 0.7616\n",
            "Epoch 682/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5923 - acc: 0.7619\n",
            "Epoch 683/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5923 - acc: 0.7617\n",
            "Epoch 684/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5916 - acc: 0.7606\n",
            "Epoch 685/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5929 - acc: 0.7614\n",
            "Epoch 686/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5934 - acc: 0.7609\n",
            "Epoch 687/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5930 - acc: 0.7612\n",
            "Epoch 688/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5927 - acc: 0.7621\n",
            "Epoch 689/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5935 - acc: 0.7615\n",
            "Epoch 690/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5927 - acc: 0.7610\n",
            "Epoch 691/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5928 - acc: 0.7614\n",
            "Epoch 692/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5934 - acc: 0.7604\n",
            "Epoch 693/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5931 - acc: 0.7611\n",
            "Epoch 694/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5920 - acc: 0.7621\n",
            "Epoch 695/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5919 - acc: 0.7617\n",
            "Epoch 696/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5932 - acc: 0.7608\n",
            "Epoch 697/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5913 - acc: 0.7607\n",
            "Epoch 698/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5919 - acc: 0.7607\n",
            "Epoch 699/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5917 - acc: 0.7615\n",
            "Epoch 700/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5913 - acc: 0.7610\n",
            "Epoch 701/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5919 - acc: 0.7614\n",
            "Epoch 702/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5924 - acc: 0.7598\n",
            "Epoch 703/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5923 - acc: 0.7608\n",
            "Epoch 704/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5921 - acc: 0.7602\n",
            "Epoch 705/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5912 - acc: 0.7624\n",
            "Epoch 706/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5921 - acc: 0.7624\n",
            "Epoch 707/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5910 - acc: 0.7619\n",
            "Epoch 708/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5916 - acc: 0.7616\n",
            "Epoch 709/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5918 - acc: 0.7614\n",
            "Epoch 710/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5914 - acc: 0.7622\n",
            "Epoch 711/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5913 - acc: 0.7617\n",
            "Epoch 712/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5906 - acc: 0.7626\n",
            "Epoch 713/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5921 - acc: 0.7613\n",
            "Epoch 714/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5905 - acc: 0.7623\n",
            "Epoch 715/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5918 - acc: 0.7624\n",
            "Epoch 716/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5929 - acc: 0.7610\n",
            "Epoch 717/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5926 - acc: 0.7616\n",
            "Epoch 718/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5921 - acc: 0.7626\n",
            "Epoch 719/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5929 - acc: 0.7613\n",
            "Epoch 720/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5917 - acc: 0.7627\n",
            "Epoch 721/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5905 - acc: 0.7618\n",
            "Epoch 722/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5906 - acc: 0.7624\n",
            "Epoch 723/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5918 - acc: 0.7617\n",
            "Epoch 724/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5903 - acc: 0.7618\n",
            "Epoch 725/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5911 - acc: 0.7621\n",
            "Epoch 726/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5916 - acc: 0.7615\n",
            "Epoch 727/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5902 - acc: 0.7615\n",
            "Epoch 728/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5903 - acc: 0.7631\n",
            "Epoch 729/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.5914 - acc: 0.7616\n",
            "Epoch 730/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5899 - acc: 0.7631\n",
            "Epoch 731/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5905 - acc: 0.7628\n",
            "Epoch 732/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5912 - acc: 0.7613\n",
            "Epoch 733/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5902 - acc: 0.7629\n",
            "Epoch 734/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5897 - acc: 0.7617\n",
            "Epoch 735/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5913 - acc: 0.7618\n",
            "Epoch 736/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5907 - acc: 0.7632\n",
            "Epoch 737/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5900 - acc: 0.7625\n",
            "Epoch 738/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5910 - acc: 0.7615\n",
            "Epoch 739/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5900 - acc: 0.7624\n",
            "Epoch 740/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5911 - acc: 0.7620\n",
            "Epoch 741/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5912 - acc: 0.7617\n",
            "Epoch 742/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5906 - acc: 0.7612\n",
            "Epoch 743/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5901 - acc: 0.7635\n",
            "Epoch 744/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5905 - acc: 0.7615\n",
            "Epoch 745/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5907 - acc: 0.7626\n",
            "Epoch 746/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5905 - acc: 0.7633\n",
            "Epoch 747/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5906 - acc: 0.7619\n",
            "Epoch 748/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5908 - acc: 0.7628\n",
            "Epoch 749/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5912 - acc: 0.7617\n",
            "Epoch 750/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5907 - acc: 0.7611\n",
            "Epoch 751/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5904 - acc: 0.7627\n",
            "Epoch 752/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5905 - acc: 0.7610\n",
            "Epoch 753/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5901 - acc: 0.7617\n",
            "Epoch 754/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5914 - acc: 0.7624\n",
            "Epoch 755/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5896 - acc: 0.7628\n",
            "Epoch 756/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5900 - acc: 0.7618\n",
            "Epoch 757/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5907 - acc: 0.7631\n",
            "Epoch 758/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5903 - acc: 0.7628\n",
            "Epoch 759/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5901 - acc: 0.7620\n",
            "Epoch 760/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5905 - acc: 0.7617\n",
            "Epoch 761/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5888 - acc: 0.7631\n",
            "Epoch 762/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5898 - acc: 0.7632\n",
            "Epoch 763/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5901 - acc: 0.7623\n",
            "Epoch 764/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5891 - acc: 0.7622\n",
            "Epoch 765/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5892 - acc: 0.7634\n",
            "Epoch 766/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5888 - acc: 0.7628\n",
            "Epoch 767/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5888 - acc: 0.7641\n",
            "Epoch 768/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5900 - acc: 0.7624\n",
            "Epoch 769/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5893 - acc: 0.7628\n",
            "Epoch 770/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5908 - acc: 0.7612\n",
            "Epoch 771/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5899 - acc: 0.7631\n",
            "Epoch 772/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5890 - acc: 0.7626\n",
            "Epoch 773/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5899 - acc: 0.7628\n",
            "Epoch 774/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5894 - acc: 0.7623\n",
            "Epoch 775/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5904 - acc: 0.7624\n",
            "Epoch 776/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5898 - acc: 0.7624\n",
            "Epoch 777/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5889 - acc: 0.7625\n",
            "Epoch 778/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5889 - acc: 0.7631\n",
            "Epoch 779/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5903 - acc: 0.7628\n",
            "Epoch 780/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5905 - acc: 0.7617\n",
            "Epoch 781/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5885 - acc: 0.7616\n",
            "Epoch 782/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5900 - acc: 0.7627\n",
            "Epoch 783/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5883 - acc: 0.7628\n",
            "Epoch 784/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5901 - acc: 0.7624\n",
            "Epoch 785/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5897 - acc: 0.7629\n",
            "Epoch 786/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5882 - acc: 0.7633\n",
            "Epoch 787/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5882 - acc: 0.7628\n",
            "Epoch 788/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5884 - acc: 0.7642\n",
            "Epoch 789/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5908 - acc: 0.7620\n",
            "Epoch 790/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5894 - acc: 0.7629\n",
            "Epoch 791/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5888 - acc: 0.7628\n",
            "Epoch 792/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5876 - acc: 0.7629\n",
            "Epoch 793/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5879 - acc: 0.7632\n",
            "Epoch 794/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5892 - acc: 0.7619\n",
            "Epoch 795/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5890 - acc: 0.7632\n",
            "Epoch 796/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5885 - acc: 0.7626\n",
            "Epoch 797/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5871 - acc: 0.7642\n",
            "Epoch 798/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5903 - acc: 0.7619\n",
            "Epoch 799/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5893 - acc: 0.7632\n",
            "Epoch 800/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5885 - acc: 0.7628\n",
            "Epoch 801/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5886 - acc: 0.7626\n",
            "Epoch 802/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5895 - acc: 0.7635\n",
            "Epoch 803/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5874 - acc: 0.7637\n",
            "Epoch 804/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5866 - acc: 0.7631\n",
            "Epoch 805/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5898 - acc: 0.7634\n",
            "Epoch 806/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5889 - acc: 0.7628\n",
            "Epoch 807/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5874 - acc: 0.7634\n",
            "Epoch 808/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5887 - acc: 0.7636\n",
            "Epoch 809/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5882 - acc: 0.7634\n",
            "Epoch 810/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5880 - acc: 0.7630\n",
            "Epoch 811/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5892 - acc: 0.7632\n",
            "Epoch 812/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5880 - acc: 0.7628\n",
            "Epoch 813/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5873 - acc: 0.7636\n",
            "Epoch 814/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5873 - acc: 0.7636\n",
            "Epoch 815/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5878 - acc: 0.7634\n",
            "Epoch 816/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5872 - acc: 0.7635\n",
            "Epoch 817/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5883 - acc: 0.7625\n",
            "Epoch 818/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5870 - acc: 0.7633\n",
            "Epoch 819/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5868 - acc: 0.7639\n",
            "Epoch 820/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5886 - acc: 0.7635\n",
            "Epoch 821/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5865 - acc: 0.7631\n",
            "Epoch 822/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5876 - acc: 0.7629\n",
            "Epoch 823/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5875 - acc: 0.7630\n",
            "Epoch 824/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5877 - acc: 0.7629\n",
            "Epoch 825/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5889 - acc: 0.7622\n",
            "Epoch 826/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5886 - acc: 0.7627\n",
            "Epoch 827/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5871 - acc: 0.7631\n",
            "Epoch 828/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5883 - acc: 0.7624\n",
            "Epoch 829/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5884 - acc: 0.7635\n",
            "Epoch 830/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5875 - acc: 0.7632\n",
            "Epoch 831/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5873 - acc: 0.7642\n",
            "Epoch 832/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5868 - acc: 0.7641\n",
            "Epoch 833/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5879 - acc: 0.7633\n",
            "Epoch 834/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5881 - acc: 0.7624\n",
            "Epoch 835/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5871 - acc: 0.7648\n",
            "Epoch 836/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5877 - acc: 0.7640\n",
            "Epoch 837/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5863 - acc: 0.7647\n",
            "Epoch 838/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5876 - acc: 0.7647\n",
            "Epoch 839/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5867 - acc: 0.7633\n",
            "Epoch 840/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5874 - acc: 0.7632\n",
            "Epoch 841/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5872 - acc: 0.7624\n",
            "Epoch 842/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5885 - acc: 0.7631\n",
            "Epoch 843/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5867 - acc: 0.7638\n",
            "Epoch 844/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5875 - acc: 0.7627\n",
            "Epoch 845/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5866 - acc: 0.7636\n",
            "Epoch 846/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5862 - acc: 0.7648\n",
            "Epoch 847/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5879 - acc: 0.7633\n",
            "Epoch 848/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5879 - acc: 0.7626\n",
            "Epoch 849/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5868 - acc: 0.7639\n",
            "Epoch 850/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5872 - acc: 0.7637\n",
            "Epoch 851/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5882 - acc: 0.7639\n",
            "Epoch 852/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5879 - acc: 0.7630\n",
            "Epoch 853/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5859 - acc: 0.7636\n",
            "Epoch 854/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5866 - acc: 0.7638\n",
            "Epoch 855/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5878 - acc: 0.7629\n",
            "Epoch 856/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7642\n",
            "Epoch 857/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5870 - acc: 0.7634\n",
            "Epoch 858/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5865 - acc: 0.7633\n",
            "Epoch 859/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5873 - acc: 0.7631\n",
            "Epoch 860/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5884 - acc: 0.7631\n",
            "Epoch 861/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5865 - acc: 0.7643\n",
            "Epoch 862/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5850 - acc: 0.7649\n",
            "Epoch 863/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7642\n",
            "Epoch 864/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5862 - acc: 0.7639\n",
            "Epoch 865/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5848 - acc: 0.7649\n",
            "Epoch 866/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5869 - acc: 0.7637\n",
            "Epoch 867/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5856 - acc: 0.7654\n",
            "Epoch 868/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5855 - acc: 0.7645\n",
            "Epoch 869/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5867 - acc: 0.7640\n",
            "Epoch 870/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5862 - acc: 0.7643\n",
            "Epoch 871/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5866 - acc: 0.7639\n",
            "Epoch 872/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5861 - acc: 0.7626\n",
            "Epoch 873/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5885 - acc: 0.7641\n",
            "Epoch 874/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5867 - acc: 0.7645\n",
            "Epoch 875/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5859 - acc: 0.7637\n",
            "Epoch 876/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5862 - acc: 0.7632\n",
            "Epoch 877/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5864 - acc: 0.7643\n",
            "Epoch 878/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5861 - acc: 0.7640\n",
            "Epoch 879/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5852 - acc: 0.7642\n",
            "Epoch 880/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5854 - acc: 0.7652\n",
            "Epoch 881/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5858 - acc: 0.7644\n",
            "Epoch 882/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5865 - acc: 0.7635\n",
            "Epoch 883/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7650\n",
            "Epoch 884/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5858 - acc: 0.7645\n",
            "Epoch 885/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5860 - acc: 0.7646\n",
            "Epoch 886/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5849 - acc: 0.7643\n",
            "Epoch 887/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5844 - acc: 0.7653\n",
            "Epoch 888/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5856 - acc: 0.7636\n",
            "Epoch 889/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5850 - acc: 0.7644\n",
            "Epoch 890/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5863 - acc: 0.7635\n",
            "Epoch 891/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5856 - acc: 0.7641\n",
            "Epoch 892/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7647\n",
            "Epoch 893/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5857 - acc: 0.7644\n",
            "Epoch 894/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5852 - acc: 0.7635\n",
            "Epoch 895/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5854 - acc: 0.7641\n",
            "Epoch 896/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5857 - acc: 0.7642\n",
            "Epoch 897/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7635\n",
            "Epoch 898/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5868 - acc: 0.7643\n",
            "Epoch 899/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5871 - acc: 0.7648\n",
            "Epoch 900/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5861 - acc: 0.7650\n",
            "Epoch 901/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5849 - acc: 0.7644\n",
            "Epoch 902/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5853 - acc: 0.7648\n",
            "Epoch 903/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5842 - acc: 0.7658\n",
            "Epoch 904/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5849 - acc: 0.7639\n",
            "Epoch 905/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7649\n",
            "Epoch 906/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7647\n",
            "Epoch 907/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7636\n",
            "Epoch 908/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5847 - acc: 0.7646\n",
            "Epoch 909/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5854 - acc: 0.7643\n",
            "Epoch 910/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5866 - acc: 0.7630\n",
            "Epoch 911/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5843 - acc: 0.7646\n",
            "Epoch 912/1300\n",
            "144000/144000 [==============================] - 4s 25us/step - loss: 0.5856 - acc: 0.7640\n",
            "Epoch 913/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5849 - acc: 0.7639\n",
            "Epoch 914/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5847 - acc: 0.7651\n",
            "Epoch 915/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5861 - acc: 0.7643\n",
            "Epoch 916/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5846 - acc: 0.7642\n",
            "Epoch 917/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5843 - acc: 0.7641\n",
            "Epoch 918/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5847 - acc: 0.7647\n",
            "Epoch 919/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5845 - acc: 0.7650\n",
            "Epoch 920/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5848 - acc: 0.7647\n",
            "Epoch 921/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5846 - acc: 0.7643\n",
            "Epoch 922/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5844 - acc: 0.7653\n",
            "Epoch 923/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5855 - acc: 0.7650\n",
            "Epoch 924/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5844 - acc: 0.7651\n",
            "Epoch 925/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5871 - acc: 0.7632\n",
            "Epoch 926/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5854 - acc: 0.7637\n",
            "Epoch 927/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5845 - acc: 0.7648\n",
            "Epoch 928/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5844 - acc: 0.7652\n",
            "Epoch 929/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5840 - acc: 0.7643\n",
            "Epoch 930/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5848 - acc: 0.7648\n",
            "Epoch 931/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5842 - acc: 0.7651\n",
            "Epoch 932/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5838 - acc: 0.7647\n",
            "Epoch 933/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5842 - acc: 0.7654\n",
            "Epoch 934/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5838 - acc: 0.7641\n",
            "Epoch 935/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5854 - acc: 0.7629\n",
            "Epoch 936/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5838 - acc: 0.7659\n",
            "Epoch 937/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5847 - acc: 0.7646\n",
            "Epoch 938/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5842 - acc: 0.7649\n",
            "Epoch 939/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5839 - acc: 0.7648\n",
            "Epoch 940/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5842 - acc: 0.7637\n",
            "Epoch 941/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5839 - acc: 0.7647\n",
            "Epoch 942/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5842 - acc: 0.7651\n",
            "Epoch 943/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5844 - acc: 0.7643\n",
            "Epoch 944/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5839 - acc: 0.7649\n",
            "Epoch 945/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5832 - acc: 0.7651\n",
            "Epoch 946/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5842 - acc: 0.7649\n",
            "Epoch 947/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5847 - acc: 0.7635\n",
            "Epoch 948/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5843 - acc: 0.7642\n",
            "Epoch 949/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5839 - acc: 0.7652\n",
            "Epoch 950/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5843 - acc: 0.7645\n",
            "Epoch 951/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5839 - acc: 0.7646\n",
            "Epoch 952/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5842 - acc: 0.7641\n",
            "Epoch 953/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5848 - acc: 0.7644\n",
            "Epoch 954/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5843 - acc: 0.7647\n",
            "Epoch 955/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5834 - acc: 0.7649\n",
            "Epoch 956/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5826 - acc: 0.7648\n",
            "Epoch 957/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5837 - acc: 0.7653\n",
            "Epoch 958/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5834 - acc: 0.7648\n",
            "Epoch 959/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5841 - acc: 0.7659\n",
            "Epoch 960/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5837 - acc: 0.7644\n",
            "Epoch 961/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5836 - acc: 0.7657\n",
            "Epoch 962/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5827 - acc: 0.7651\n",
            "Epoch 963/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5831 - acc: 0.7647\n",
            "Epoch 964/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5842 - acc: 0.7651\n",
            "Epoch 965/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5822 - acc: 0.7655\n",
            "Epoch 966/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5824 - acc: 0.7653\n",
            "Epoch 967/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5840 - acc: 0.7649\n",
            "Epoch 968/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5824 - acc: 0.7654\n",
            "Epoch 969/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5842 - acc: 0.7647\n",
            "Epoch 970/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5849 - acc: 0.7645\n",
            "Epoch 971/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5846 - acc: 0.7642\n",
            "Epoch 972/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5833 - acc: 0.7654\n",
            "Epoch 973/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5827 - acc: 0.7658\n",
            "Epoch 974/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5826 - acc: 0.7657\n",
            "Epoch 975/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5838 - acc: 0.7653\n",
            "Epoch 976/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5855 - acc: 0.7642\n",
            "Epoch 977/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5822 - acc: 0.7659\n",
            "Epoch 978/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5833 - acc: 0.7659\n",
            "Epoch 979/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5836 - acc: 0.7655\n",
            "Epoch 980/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5819 - acc: 0.7652\n",
            "Epoch 981/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5830 - acc: 0.7644\n",
            "Epoch 982/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5838 - acc: 0.7659\n",
            "Epoch 983/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5827 - acc: 0.7652\n",
            "Epoch 984/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5829 - acc: 0.7655\n",
            "Epoch 985/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5834 - acc: 0.7651\n",
            "Epoch 986/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5822 - acc: 0.7655\n",
            "Epoch 987/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5847 - acc: 0.7641\n",
            "Epoch 988/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5821 - acc: 0.7665\n",
            "Epoch 989/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5818 - acc: 0.7647\n",
            "Epoch 990/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5816 - acc: 0.7665\n",
            "Epoch 991/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5829 - acc: 0.7643\n",
            "Epoch 992/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5835 - acc: 0.7648\n",
            "Epoch 993/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5824 - acc: 0.7656\n",
            "Epoch 994/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5827 - acc: 0.7649\n",
            "Epoch 995/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5833 - acc: 0.7660\n",
            "Epoch 996/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5812 - acc: 0.7660\n",
            "Epoch 997/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5822 - acc: 0.7654\n",
            "Epoch 998/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5823 - acc: 0.7657\n",
            "Epoch 999/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5826 - acc: 0.7642\n",
            "Epoch 1000/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5831 - acc: 0.7647\n",
            "Epoch 1001/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5839 - acc: 0.7654\n",
            "Epoch 1002/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5806 - acc: 0.7658\n",
            "Epoch 1003/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5821 - acc: 0.7654\n",
            "Epoch 1004/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5820 - acc: 0.7651\n",
            "Epoch 1005/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5832 - acc: 0.7645\n",
            "Epoch 1006/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5819 - acc: 0.7656\n",
            "Epoch 1007/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5832 - acc: 0.7652\n",
            "Epoch 1008/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5822 - acc: 0.7653\n",
            "Epoch 1009/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5830 - acc: 0.7667\n",
            "Epoch 1010/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5825 - acc: 0.7643\n",
            "Epoch 1011/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5821 - acc: 0.7658\n",
            "Epoch 1012/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5826 - acc: 0.7650\n",
            "Epoch 1013/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5827 - acc: 0.7657\n",
            "Epoch 1014/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5821 - acc: 0.7649\n",
            "Epoch 1015/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5826 - acc: 0.7653\n",
            "Epoch 1016/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5821 - acc: 0.7652\n",
            "Epoch 1017/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5821 - acc: 0.7660\n",
            "Epoch 1018/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5817 - acc: 0.7659\n",
            "Epoch 1019/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5829 - acc: 0.7654\n",
            "Epoch 1020/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5820 - acc: 0.7654\n",
            "Epoch 1021/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5822 - acc: 0.7659\n",
            "Epoch 1022/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5823 - acc: 0.7656\n",
            "Epoch 1023/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5816 - acc: 0.7656\n",
            "Epoch 1024/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5822 - acc: 0.7655\n",
            "Epoch 1025/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5812 - acc: 0.7653\n",
            "Epoch 1026/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5824 - acc: 0.7656\n",
            "Epoch 1027/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5819 - acc: 0.7658\n",
            "Epoch 1028/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5813 - acc: 0.7665\n",
            "Epoch 1029/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5814 - acc: 0.7653\n",
            "Epoch 1030/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5825 - acc: 0.7651\n",
            "Epoch 1031/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5826 - acc: 0.7650\n",
            "Epoch 1032/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5821 - acc: 0.7658\n",
            "Epoch 1033/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5804 - acc: 0.7664\n",
            "Epoch 1034/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5818 - acc: 0.7663\n",
            "Epoch 1035/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5810 - acc: 0.7664\n",
            "Epoch 1036/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5823 - acc: 0.7674\n",
            "Epoch 1037/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5811 - acc: 0.7664\n",
            "Epoch 1038/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5813 - acc: 0.7666\n",
            "Epoch 1039/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5827 - acc: 0.7645\n",
            "Epoch 1040/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5821 - acc: 0.7667\n",
            "Epoch 1041/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5833 - acc: 0.7653\n",
            "Epoch 1042/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5811 - acc: 0.7655\n",
            "Epoch 1043/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5812 - acc: 0.7664\n",
            "Epoch 1044/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5804 - acc: 0.7662\n",
            "Epoch 1045/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5821 - acc: 0.7659\n",
            "Epoch 1046/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5811 - acc: 0.7659\n",
            "Epoch 1047/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5819 - acc: 0.7657\n",
            "Epoch 1048/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5803 - acc: 0.7654\n",
            "Epoch 1049/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5819 - acc: 0.7651\n",
            "Epoch 1050/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5807 - acc: 0.7657\n",
            "Epoch 1051/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5814 - acc: 0.7660\n",
            "Epoch 1052/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5805 - acc: 0.7674\n",
            "Epoch 1053/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5813 - acc: 0.7661\n",
            "Epoch 1054/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5815 - acc: 0.7654\n",
            "Epoch 1055/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5807 - acc: 0.7657\n",
            "Epoch 1056/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5815 - acc: 0.7661\n",
            "Epoch 1057/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5813 - acc: 0.7651\n",
            "Epoch 1058/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5818 - acc: 0.7651\n",
            "Epoch 1059/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5806 - acc: 0.7662\n",
            "Epoch 1060/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5803 - acc: 0.7658\n",
            "Epoch 1061/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5818 - acc: 0.7645\n",
            "Epoch 1062/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5814 - acc: 0.7666\n",
            "Epoch 1063/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5816 - acc: 0.7659\n",
            "Epoch 1064/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5823 - acc: 0.7657\n",
            "Epoch 1065/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5809 - acc: 0.7657\n",
            "Epoch 1066/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5807 - acc: 0.7664\n",
            "Epoch 1067/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5800 - acc: 0.7660\n",
            "Epoch 1068/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5800 - acc: 0.7671\n",
            "Epoch 1069/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5810 - acc: 0.7650\n",
            "Epoch 1070/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5804 - acc: 0.7667\n",
            "Epoch 1071/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5803 - acc: 0.7666\n",
            "Epoch 1072/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5788 - acc: 0.7686\n",
            "Epoch 1073/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5800 - acc: 0.7664\n",
            "Epoch 1074/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5807 - acc: 0.7662\n",
            "Epoch 1075/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5821 - acc: 0.7660\n",
            "Epoch 1076/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5804 - acc: 0.7666\n",
            "Epoch 1077/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5803 - acc: 0.7655\n",
            "Epoch 1078/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5804 - acc: 0.7662\n",
            "Epoch 1079/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5810 - acc: 0.7673\n",
            "Epoch 1080/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5809 - acc: 0.7667\n",
            "Epoch 1081/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5794 - acc: 0.7666\n",
            "Epoch 1082/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5797 - acc: 0.7666\n",
            "Epoch 1083/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5811 - acc: 0.7661\n",
            "Epoch 1084/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5793 - acc: 0.7670\n",
            "Epoch 1085/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5807 - acc: 0.7666\n",
            "Epoch 1086/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5806 - acc: 0.7667\n",
            "Epoch 1087/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5799 - acc: 0.7670\n",
            "Epoch 1088/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5811 - acc: 0.7665\n",
            "Epoch 1089/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5798 - acc: 0.7662\n",
            "Epoch 1090/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5800 - acc: 0.7669\n",
            "Epoch 1091/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5791 - acc: 0.7667\n",
            "Epoch 1092/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5793 - acc: 0.7670\n",
            "Epoch 1093/1300\n",
            "144000/144000 [==============================] - 4s 25us/step - loss: 0.5809 - acc: 0.7663\n",
            "Epoch 1094/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5807 - acc: 0.7667\n",
            "Epoch 1095/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5814 - acc: 0.7659\n",
            "Epoch 1096/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5806 - acc: 0.7666\n",
            "Epoch 1097/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5803 - acc: 0.7663\n",
            "Epoch 1098/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5795 - acc: 0.7666\n",
            "Epoch 1099/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5804 - acc: 0.7660\n",
            "Epoch 1100/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5804 - acc: 0.7660\n",
            "Epoch 1101/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5798 - acc: 0.7659\n",
            "Epoch 1102/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5792 - acc: 0.7672\n",
            "Epoch 1103/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5801 - acc: 0.7654\n",
            "Epoch 1104/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5796 - acc: 0.7667\n",
            "Epoch 1105/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5801 - acc: 0.7671\n",
            "Epoch 1106/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5801 - acc: 0.7666\n",
            "Epoch 1107/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5795 - acc: 0.7658\n",
            "Epoch 1108/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5800 - acc: 0.7660\n",
            "Epoch 1109/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5809 - acc: 0.7666\n",
            "Epoch 1110/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5806 - acc: 0.7664\n",
            "Epoch 1111/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5794 - acc: 0.7669\n",
            "Epoch 1112/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5810 - acc: 0.7666\n",
            "Epoch 1113/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5792 - acc: 0.7668\n",
            "Epoch 1114/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5788 - acc: 0.7667\n",
            "Epoch 1115/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5809 - acc: 0.7668\n",
            "Epoch 1116/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5804 - acc: 0.7665\n",
            "Epoch 1117/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5784 - acc: 0.7671\n",
            "Epoch 1118/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5795 - acc: 0.7668\n",
            "Epoch 1119/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5795 - acc: 0.7671\n",
            "Epoch 1120/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5792 - acc: 0.7677\n",
            "Epoch 1121/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5793 - acc: 0.7672\n",
            "Epoch 1122/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5795 - acc: 0.7670\n",
            "Epoch 1123/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5790 - acc: 0.7667\n",
            "Epoch 1124/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5794 - acc: 0.7659\n",
            "Epoch 1125/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5795 - acc: 0.7673\n",
            "Epoch 1126/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5787 - acc: 0.7671\n",
            "Epoch 1127/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5788 - acc: 0.7673\n",
            "Epoch 1128/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5791 - acc: 0.7662\n",
            "Epoch 1129/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5793 - acc: 0.7674\n",
            "Epoch 1130/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5803 - acc: 0.7658\n",
            "Epoch 1131/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5793 - acc: 0.7668\n",
            "Epoch 1132/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5802 - acc: 0.7662\n",
            "Epoch 1133/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5790 - acc: 0.7667\n",
            "Epoch 1134/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5785 - acc: 0.7683\n",
            "Epoch 1135/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5775 - acc: 0.7678\n",
            "Epoch 1136/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5800 - acc: 0.7663\n",
            "Epoch 1137/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5791 - acc: 0.7670\n",
            "Epoch 1138/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5798 - acc: 0.7667\n",
            "Epoch 1139/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5799 - acc: 0.7659\n",
            "Epoch 1140/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5781 - acc: 0.7677\n",
            "Epoch 1141/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5782 - acc: 0.7676\n",
            "Epoch 1142/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5785 - acc: 0.7666\n",
            "Epoch 1143/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5774 - acc: 0.7676\n",
            "Epoch 1144/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5781 - acc: 0.7668\n",
            "Epoch 1145/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5786 - acc: 0.7670\n",
            "Epoch 1146/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5792 - acc: 0.7663\n",
            "Epoch 1147/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5788 - acc: 0.7675\n",
            "Epoch 1148/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5782 - acc: 0.7679\n",
            "Epoch 1149/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5792 - acc: 0.7668\n",
            "Epoch 1150/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5780 - acc: 0.7674\n",
            "Epoch 1151/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5794 - acc: 0.7672\n",
            "Epoch 1152/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5786 - acc: 0.7668\n",
            "Epoch 1153/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5785 - acc: 0.7673\n",
            "Epoch 1154/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5794 - acc: 0.7670\n",
            "Epoch 1155/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5798 - acc: 0.7669\n",
            "Epoch 1156/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5769 - acc: 0.7686\n",
            "Epoch 1157/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5789 - acc: 0.7666\n",
            "Epoch 1158/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5775 - acc: 0.7677\n",
            "Epoch 1159/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5776 - acc: 0.7676\n",
            "Epoch 1160/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5783 - acc: 0.7678\n",
            "Epoch 1161/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5782 - acc: 0.7676\n",
            "Epoch 1162/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5780 - acc: 0.7669\n",
            "Epoch 1163/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5785 - acc: 0.7665\n",
            "Epoch 1164/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5781 - acc: 0.7669\n",
            "Epoch 1165/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5788 - acc: 0.7676\n",
            "Epoch 1166/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5782 - acc: 0.7666\n",
            "Epoch 1167/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5776 - acc: 0.7674\n",
            "Epoch 1168/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5785 - acc: 0.7670\n",
            "Epoch 1169/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5804 - acc: 0.7670\n",
            "Epoch 1170/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5773 - acc: 0.7665\n",
            "Epoch 1171/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5781 - acc: 0.7671\n",
            "Epoch 1172/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5789 - acc: 0.7665\n",
            "Epoch 1173/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5775 - acc: 0.7683\n",
            "Epoch 1174/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5782 - acc: 0.7687\n",
            "Epoch 1175/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5779 - acc: 0.7684\n",
            "Epoch 1176/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5785 - acc: 0.7661\n",
            "Epoch 1177/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5769 - acc: 0.7686\n",
            "Epoch 1178/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5778 - acc: 0.7677\n",
            "Epoch 1179/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5784 - acc: 0.7683\n",
            "Epoch 1180/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5763 - acc: 0.7676\n",
            "Epoch 1181/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5783 - acc: 0.7667\n",
            "Epoch 1182/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5783 - acc: 0.7682\n",
            "Epoch 1183/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.5775 - acc: 0.7672\n",
            "Epoch 1184/1300\n",
            "144000/144000 [==============================] - 4s 25us/step - loss: 0.5757 - acc: 0.7679\n",
            "Epoch 1185/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5785 - acc: 0.7666\n",
            "Epoch 1186/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5775 - acc: 0.7666\n",
            "Epoch 1187/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5760 - acc: 0.7675\n",
            "Epoch 1188/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5786 - acc: 0.7665\n",
            "Epoch 1189/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5771 - acc: 0.7669\n",
            "Epoch 1190/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5782 - acc: 0.7674\n",
            "Epoch 1191/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5776 - acc: 0.7677\n",
            "Epoch 1192/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5773 - acc: 0.7680\n",
            "Epoch 1193/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5765 - acc: 0.7665\n",
            "Epoch 1194/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5780 - acc: 0.7673\n",
            "Epoch 1195/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5776 - acc: 0.7679\n",
            "Epoch 1196/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5795 - acc: 0.7672\n",
            "Epoch 1197/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5767 - acc: 0.7682\n",
            "Epoch 1198/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5776 - acc: 0.7668\n",
            "Epoch 1199/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5773 - acc: 0.7689\n",
            "Epoch 1200/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5775 - acc: 0.7680\n",
            "Epoch 1201/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5773 - acc: 0.7677\n",
            "Epoch 1202/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5786 - acc: 0.7669\n",
            "Epoch 1203/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5771 - acc: 0.7680\n",
            "Epoch 1204/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5774 - acc: 0.7678\n",
            "Epoch 1205/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5765 - acc: 0.7673\n",
            "Epoch 1206/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5779 - acc: 0.7678\n",
            "Epoch 1207/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5775 - acc: 0.7671\n",
            "Epoch 1208/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5761 - acc: 0.7668\n",
            "Epoch 1209/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5772 - acc: 0.7672\n",
            "Epoch 1210/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5785 - acc: 0.7674\n",
            "Epoch 1211/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5772 - acc: 0.7681\n",
            "Epoch 1212/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5781 - acc: 0.7676\n",
            "Epoch 1213/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5783 - acc: 0.7671\n",
            "Epoch 1214/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5768 - acc: 0.7676\n",
            "Epoch 1215/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5756 - acc: 0.7689\n",
            "Epoch 1216/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5791 - acc: 0.7674\n",
            "Epoch 1217/1300\n",
            "144000/144000 [==============================] - 4s 26us/step - loss: 0.5772 - acc: 0.7684\n",
            "Epoch 1218/1300\n",
            "144000/144000 [==============================] - 4s 28us/step - loss: 0.5767 - acc: 0.7684\n",
            "Epoch 1219/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5760 - acc: 0.7681\n",
            "Epoch 1220/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5762 - acc: 0.7674\n",
            "Epoch 1221/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5773 - acc: 0.7676\n",
            "Epoch 1222/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5777 - acc: 0.7675\n",
            "Epoch 1223/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5779 - acc: 0.7672\n",
            "Epoch 1224/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5777 - acc: 0.7677\n",
            "Epoch 1225/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5768 - acc: 0.7687\n",
            "Epoch 1226/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5764 - acc: 0.7682\n",
            "Epoch 1227/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5772 - acc: 0.7674\n",
            "Epoch 1228/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5757 - acc: 0.7674\n",
            "Epoch 1229/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5767 - acc: 0.7670\n",
            "Epoch 1230/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5767 - acc: 0.7682\n",
            "Epoch 1231/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5771 - acc: 0.7678\n",
            "Epoch 1232/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5777 - acc: 0.7682\n",
            "Epoch 1233/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5773 - acc: 0.7680\n",
            "Epoch 1234/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5771 - acc: 0.7678\n",
            "Epoch 1235/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5771 - acc: 0.7686\n",
            "Epoch 1236/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5760 - acc: 0.7677\n",
            "Epoch 1237/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5764 - acc: 0.7686\n",
            "Epoch 1238/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5776 - acc: 0.7678\n",
            "Epoch 1239/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5760 - acc: 0.7685\n",
            "Epoch 1240/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5774 - acc: 0.7685\n",
            "Epoch 1241/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5757 - acc: 0.7685\n",
            "Epoch 1242/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5766 - acc: 0.7684\n",
            "Epoch 1243/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5761 - acc: 0.7684\n",
            "Epoch 1244/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5749 - acc: 0.7689\n",
            "Epoch 1245/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5761 - acc: 0.7681\n",
            "Epoch 1246/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5761 - acc: 0.7683\n",
            "Epoch 1247/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5755 - acc: 0.7680\n",
            "Epoch 1248/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5759 - acc: 0.7684\n",
            "Epoch 1249/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5770 - acc: 0.7675\n",
            "Epoch 1250/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5771 - acc: 0.7675\n",
            "Epoch 1251/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5762 - acc: 0.7687\n",
            "Epoch 1252/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5769 - acc: 0.7681\n",
            "Epoch 1253/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5765 - acc: 0.7681\n",
            "Epoch 1254/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5770 - acc: 0.7668\n",
            "Epoch 1255/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5760 - acc: 0.7672\n",
            "Epoch 1256/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5751 - acc: 0.7683\n",
            "Epoch 1257/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5759 - acc: 0.7687\n",
            "Epoch 1258/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5766 - acc: 0.7678\n",
            "Epoch 1259/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5762 - acc: 0.7672\n",
            "Epoch 1260/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5758 - acc: 0.7688\n",
            "Epoch 1261/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5765 - acc: 0.7677\n",
            "Epoch 1262/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5757 - acc: 0.7685\n",
            "Epoch 1263/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5756 - acc: 0.7681\n",
            "Epoch 1264/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5765 - acc: 0.7678\n",
            "Epoch 1265/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5754 - acc: 0.7688\n",
            "Epoch 1266/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5758 - acc: 0.7677\n",
            "Epoch 1267/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5765 - acc: 0.7683\n",
            "Epoch 1268/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5763 - acc: 0.7691\n",
            "Epoch 1269/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.5768 - acc: 0.7677\n",
            "Epoch 1270/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5745 - acc: 0.7684\n",
            "Epoch 1271/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5767 - acc: 0.7674\n",
            "Epoch 1272/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5759 - acc: 0.7681\n",
            "Epoch 1273/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5764 - acc: 0.7679\n",
            "Epoch 1274/1300\n",
            "144000/144000 [==============================] - 4s 25us/step - loss: 0.5759 - acc: 0.7686\n",
            "Epoch 1275/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5757 - acc: 0.7680\n",
            "Epoch 1276/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5765 - acc: 0.7681\n",
            "Epoch 1277/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5764 - acc: 0.7682\n",
            "Epoch 1278/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5752 - acc: 0.7674\n",
            "Epoch 1279/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5765 - acc: 0.7688\n",
            "Epoch 1280/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5758 - acc: 0.7688\n",
            "Epoch 1281/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5760 - acc: 0.7684\n",
            "Epoch 1282/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5752 - acc: 0.7693\n",
            "Epoch 1283/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5749 - acc: 0.7688\n",
            "Epoch 1284/1300\n",
            "144000/144000 [==============================] - 4s 24us/step - loss: 0.5751 - acc: 0.7682\n",
            "Epoch 1285/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5750 - acc: 0.7690\n",
            "Epoch 1286/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5753 - acc: 0.7683\n",
            "Epoch 1287/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5764 - acc: 0.7672\n",
            "Epoch 1288/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5758 - acc: 0.7680\n",
            "Epoch 1289/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5748 - acc: 0.7694\n",
            "Epoch 1290/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5754 - acc: 0.7697\n",
            "Epoch 1291/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5748 - acc: 0.7692\n",
            "Epoch 1292/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5757 - acc: 0.7687\n",
            "Epoch 1293/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5752 - acc: 0.7687\n",
            "Epoch 1294/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5760 - acc: 0.7680\n",
            "Epoch 1295/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5746 - acc: 0.7687\n",
            "Epoch 1296/1300\n",
            "144000/144000 [==============================] - 3s 24us/step - loss: 0.5758 - acc: 0.7680\n",
            "Epoch 1297/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5744 - acc: 0.7677\n",
            "Epoch 1298/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5751 - acc: 0.7687\n",
            "Epoch 1299/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5752 - acc: 0.7692\n",
            "Epoch 1300/1300\n",
            "144000/144000 [==============================] - 3s 23us/step - loss: 0.5750 - acc: 0.7695\n",
            "Tensor(\"Cast_20:0\", shape=(48000,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2N3y140SMRWZ",
        "colab_type": "code",
        "outputId": "37f9b109-43d9-4fee-f376-c68cc02b8a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1410
        }
      },
      "cell_type": "code",
      "source": [
        "print ('----------------------------TRAINING DATA-------------------------------\\n\\n')\n",
        "\n",
        "print ('Matriz de Confusão training_data :\\n ')\n",
        "predictions1 = nn.predict(X_train_sc) # Predictions of training data\n",
        "print (confusion_matrix(y_train, predictions1.argmax(axis=1))) # Confusion Matrix of training data\n",
        "\n",
        "print(\"\\n\\nReports (Precision - Recall - F1 Score)\\n\")\n",
        "print (classification_report(y_train, predictions1.argmax(axis=1))) # Reports of training data\n",
        "\n",
        "print ('----------------------------VALIDATION DATA-------------------------------\\n\\n')\n",
        "\n",
        "print ('Matriz de Confusão validation_data :\\n ')\n",
        "predictions2 = nn.predict(X_val_sc) # Predictions of validation data\n",
        "print (confusion_matrix(y_val, predictions2.argmax(axis=1))) # Confusion Matrix of validation data\n",
        "\n",
        "print(\"\\n\\nReports (Precision - Recall - F1 Score)\\n\")\n",
        "print (classification_report(y_val, predictions2.argmax(axis=1))) # Reports of validation data\n",
        "\n",
        "print ('----------------------------TESTING DATA-------------------------------\\n\\n')\n",
        "\n",
        "print ('Matriz de Confusão testing_data : \\n')\n",
        "predictions3 = nn.predict(X_test_sc) # Predictions of testing data\n",
        "print (confusion_matrix(y_test, predictions3.argmax(axis=1))) # Confusion matrix of testing data\n",
        "\n",
        "print(\"\\n\\nReports (Precision - Recall - F1 Score)\\n\")\n",
        "print (classification_report(y_test, predictions3.argmax(axis=1))) # Reports of testing data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------TRAINING DATA-------------------------------\n",
            "\n",
            "\n",
            "Matriz de Confusão training_data :\n",
            " \n",
            "[[21877  1298   195   192   504   259]\n",
            " [ 1874 19117   474   488  1355   614]\n",
            " [  167   758 16074   389  2297  4315]\n",
            " [   60   445   267 22097   797   177]\n",
            " [  328  1247  1364   849 19405   815]\n",
            " [  193   882  6172   260  2049 14346]]\n",
            "\n",
            "\n",
            "Reports (Precision - Recall - F1 Score)\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.89      0.90      0.90     24325\n",
            "          1       0.81      0.80      0.80     23922\n",
            "          2       0.65      0.67      0.66     24000\n",
            "          3       0.91      0.93      0.92     23843\n",
            "          4       0.73      0.81      0.77     24008\n",
            "          5       0.70      0.60      0.65     23902\n",
            "\n",
            "avg / total       0.78      0.78      0.78    144000\n",
            "\n",
            "----------------------------VALIDATION DATA-------------------------------\n",
            "\n",
            "\n",
            "Matriz de Confusão validation_data :\n",
            " \n",
            "[[6851  767   69   58  122   89]\n",
            " [ 486 6603  147  134  479  217]\n",
            " [ 105  364 5026  161  856 1490]\n",
            " [  34  315   97 7183  317   79]\n",
            " [ 154  646  441  267 6240  288]\n",
            " [  86  433 2280  102  784 4230]]\n",
            "\n",
            "\n",
            "Reports (Precision - Recall - F1 Score)\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.89      0.86      0.87      7956\n",
            "          1       0.72      0.82      0.77      8066\n",
            "          2       0.62      0.63      0.63      8002\n",
            "          3       0.91      0.90      0.90      8025\n",
            "          4       0.71      0.78      0.74      8036\n",
            "          5       0.66      0.53      0.59      7915\n",
            "\n",
            "avg / total       0.75      0.75      0.75     48000\n",
            "\n",
            "----------------------------TESTING DATA-------------------------------\n",
            "\n",
            "\n",
            "Matriz de Confusão testing_data : \n",
            "\n",
            "[[6754  811   74   75  125   77]\n",
            " [ 487 6508  158  133  478  209]\n",
            " [  81  381 4996  145  868 1594]\n",
            " [  37  304  101 7143  313   58]\n",
            " [ 145  670  410  283 6211  315]\n",
            " [  93  446 2307   91  753 4367]]\n",
            "\n",
            "\n",
            "Reports (Precision - Recall - F1 Score)\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.89      0.85      0.87      7916\n",
            "          1       0.71      0.82      0.76      7973\n",
            "          2       0.62      0.62      0.62      8065\n",
            "          3       0.91      0.90      0.90      7956\n",
            "          4       0.71      0.77      0.74      8034\n",
            "          5       0.66      0.54      0.60      8057\n",
            "\n",
            "avg / total       0.75      0.75      0.75     48001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PZ1HrztlcX6O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = nn.fit(training_data[features].values, np_utils.to_categorical(training_data.Class.values), verbose=1, nb_epoch=1000, batch_size=512)\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_AZuaSpECVeE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Log loss on the cross validation sample"
      ]
    },
    {
      "metadata": {
        "id": "fzVBcw0mCVeF",
        "colab_type": "code",
        "outputId": "fe89d557-5359-4c28-96a3-4c95daa15c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "# predict each track\n",
        "proba_nn = nn.predict_proba(validation_data[features].values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0aa8c38eebb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproba_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8c3dfsbOCVeK",
        "colab_type": "code",
        "outputId": "c6cf148a-fd03-4307-f4f1-80990082d796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "log_loss(validation_data.Class.values, proba_nn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.796290166154051"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "xwXWhN7lCVeP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quality metrics\n",
        "\n",
        "Plot ROC curves and signal efficiency dependece from particle mometum and transverse momentum values."
      ]
    },
    {
      "metadata": {
        "id": "EiEwNETzCVeQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "proba = proba_gb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0WdnDhbCVeb",
        "colab_type": "code",
        "outputId": "58c866ac-6227-42eb-dad8-8052adecabfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "cell_type": "code",
      "source": [
        "utils.plot_roc_curves(proba, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGMCAYAAAAx7xNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsnXl8HEl5v5/unvvWSKPTlny3vWt7\nL3tvdrkCy7FswhJYCAkJgYRAQoCQX0hCAgFCIJALkpBNAuE+FgjHAuFcFlhY2PvAa7cv2ZIt65rR\naO6+f3/0aHRYkiVZtsd2PZ/PaGa6q6uq+21Vf+ett6ok13URCAQCgUAguNCRz3UFBAKBQCAQCM4G\nQvQIBAKBQCC4KBCiRyAQCAQCwUWBED0CgUAgEAguCoToEQgEAoFAcFEgRI9AIBAIBIKLAiF6BAKB\nQLBsVFV9u6qqB5eY9uOqqt53puskEJwK37mugEAgEFxoqKqaAf4UeBGwFrCBvcCngY9ommadw+qt\nCFVV1wDP0TTtYwCapr0HeM+5rVVzMPfazLN/HdAPmIAzY1cO+Cnwdk3TtDnHvBB4A3A1EAGywD3A\n+zVN2zMnbRB4I/ByYEu9jH7gC8AHNU0zTvMULxiEp0cgEAhWkfoD7lHgEuAOIA5kgHcCfwj8n6qq\n/nNVv9Pg14BXn+tKNClLvTbP1zQtNPXCEzQ28H1VVZNTiVRV/VvgM8CXgU2apoWB64Ex4EFVVZ83\nI20Q+AHwKuCtQAvQCfw58Lv1vJVVOMcLAuHpEQgEgtXlP/B+wd+maZpd36bjiZ3HgafwfpX/g6qq\nTwd+CFwH/DOwAzgGvFnTtG8BqKoaBt6H5zXqBI4Af6dp2ifnK1xV1d8G/h24HfgXoBfYD/ympmmP\n19OowD/iPXQDwOPAmzRNe6S+/17gl8Bm4EbgQ8D/AyRVVWvATcDzgddomramfsym+jncBJSBrwBv\n1TStMk8dLwM+AFwJBIGf1MvfP0/a9wJ3aJq2Yc72fjxh8FfAu4DfwhOXE3gejj/TNM2cJ7+P4wnR\nCp5Y2alp2mFVVV8P/AGwoZ7HZ4C/1DTNUlVVWqiM+vZZ10bTtAfmljsfmqYdU1X1TcAJ4FnA/6qq\nei3wF8BLNU374oy0A8CfqKpqAx9XVXWdpmlV4C3167hF07Rj9eQm8C1VVQ/giZ8uvPtq7rWIAX8P\nvATw43md/ljTtEP1++h/AP+UZ1JV1dcA/6VpmlT/7tbLfx0wiOeR0jRN+50ZZawHDgO/omna91VV\n/fX6dVOBKvBV4E80TSvW0/8R8EdAD9599M16nQpLuaanQnh6BAKBYJVQVbUNeA5el4I9d7+maUPA\nl4BXztn1TryuiRbgfryHmlTfdydwLd5DMY73QPyoqqo3LVKVMN6v/BuBDmAfcLeqqlNt/pfwhFkv\nnpDqB/53Th4vBf4TiGua9ufAp4Cf1b0Usx7qdW/Dd+v59ABXATfgiSXmpM3gddPcj9f1txYYBb65\ngEfiU8B6VVV3z8jjOmAd8EngZcBrgGdqmhYBngG8gMU9LzcBDwMpoF9V1VcD78YTPfH68XfgXWsW\nK+NU12YJBOvv1fr7K4DDMwXPHD4EtOPdZ+DdN5+fIXgaaJp2QNO0V8+3r86dwOX1Vw/ePfGtGffJ\nUvhdPPH4K3jX4VfneDLvwBNc96iq+mw8m70H79pfB+zCE+fUBd8HgJdpmhYFrsDrrnvbMuqzKEL0\nCAQCweqxEZDwvDkLsQ/vV+5MPqRpWn899uIuPG9Cl6qqaeA3gL/SNO2wpmmWpmlfAb4OvPYUdfk7\nTdNGNU2bBP4WT1xMCYfrgd/TNK1a9xZ8AehTVbVzxvGDmqZ9WdM0h1NzC9BXr2exLu5+E697Zi6v\nAHRN095RLz8PvAnPw/L0uYk1TdsLPIInwqa4A7i/7hlK4cWwVOvp9wNbNU27c5H6unjX3NI0zcXz\nLNypadp9mqY5dY/YB5m+xispY1FUVZXqXpB/wxOL99R3bcaL/5qXuoApM30PbWbx+22h8lvxxNzf\naZo2VPfI/Sme5yy0jKy+o2naU/XreBcQZVqQgWerT9XvozcAX9E07auaptmaph0C3gG8su7RTNWP\nqdTP9Thwo6Zpf8EqIbq3BAKBYPWYWsF5sRgKZUa6KWaOgprqDorgCRUZz0sz8xgZ+Pkp6jLzwXm4\n/r4W+AWe6PlrVVUvxXvATf0AnvmwO3SK/GeyGZioCxgANE17AnhinrRbgc56V9BMHDzvzXx8Ck8Y\n/WndC/FSPO8YwOeAXweO1EeIfR+va+roIvU9MkfMbQW2q6r6lhnbJLwuq8AKy5iPb6mqOlWuUi/j\n08DNmqbp9e0ui98/4Nlr6n5wgZUEKq+vl9M/tUHTtBE84YLXA7okGveJpmlZVVW/hWefb6qqug3Y\nybRg3QpsVlX1xXPykPE8TffgdXftUVX1AbxYpc+xAlG3EEL0CAQCweqxH+/hvR1PXMzHJZz8S34h\nb8pUl8e1mqY9usy6zHxwTnWVOaqqbsHzFH0YuFXTtJyqqs8Fvj3n+OU8SG2W3nNQBZ7UNO2yZeT/\nOeCDqqpeg+dJaMHzTlH3ZD2rLuCeC9wGvENV1ds1TfvGAvnNPbcq8G5N0/5pkfTLLWM+nq9p2vcB\nVFXdCTwIfEPTtMEZafYBt6uqKtW9J7Ooe4fCTN9D+5j24C2Hqe7X5fT4zCfG5l7LTwP/XReLLwd+\nMWNkWhX4N03T/niRMu5QVXUD3nV+IfDnqqq+4XS8ajMR3VsCgUCwStQ9Hd8A/qze6M9CVdW1eF0K\nn1hilofxHk5XzMmnV1XVU/1o3Tzj88b6+wBe0GsAeK+mabn69muWWJ+F2A+kZnaPqap6haqqf7BA\n2k2qqsZnpJ3q6pmXugfie8CL8bpLvjblVVJVNaiqalzTtD2apv2jpmk343krfm+Z9Z97jdvrgb6r\nVcbcc3oCL47oTlVVu2fs+jSeR+5VCxz6VmAIz9sEnsfpDnUe14yqqmtUVd2vquqV8+RzGLDwvC9T\n6dtUVX1rvVt1SnBHZhyz6dRnxt143qdncfK9Pt91TtXLQ1VVn6qqqXpX7kc0TXsB8Hd43WKrghA9\nAoFAsLq8AS849f9UVb1KVVW5/tB8Ll6w73fxRledEk3TSsB/43kVrlBVVakHMD+K90BZjD+vP7iT\nwF/iPeQeZro74kZVVUP10TQ317f1LpJfGehRVTVdj7+YyXfwukneX3+IdeKNYts1Tz6fref1r6qq\ntqqqGsEbAfWQqqqJRcr/NF7w8G3MfpD+K/B1VVV7AeoCYgueB2Sp/DPwMlVVf11VVX/d0/BNYMrz\nc6oyFrs2i/E+vNF4/zMVuF4fQfdO4N9UVX2Dqqot9TLXqqr6frwRZK/UNG2qe/BDwH3Avaqq3l6/\n18Kqqj4f+BFe19Bjcwuue8g+C/ylqqrr6/V+N56Qm5xxbi+v33fX4137Ral3030JT5z1AZ+fsftf\n8O67N9Tr2Ikn2r5Q3/9nwH2qqm6tn3Mab0Tjcmy5KEL0CAQCwSpSDzS9Ci/49rNACRgH/gav0f/V\n+UZ2LcJb8H49fxso4o24+WtN0z5ziuM+jTcUfATvF/qtmqa5mqY9iBfY/DG8odLPw/Og3Icn1G5e\nIL9P4cX8HGN2oCr1Ic3PwBsafRzvIfsocFI3Rn3o8S143oyBevprgWefYljyV/Aeog6eyJrirXjC\n4SFVVat4sU4P4gXILglN0z6PF8T7Xrxr/CO80WVvXGIZC16bU5Rr4Xl0no4XTD21/V14cTAvAg7V\ny7wfbyTeLk3TfjgjrYnXFfRB4O14I7CG8ITTB4AXLxKM/rr6uTyCdy/0AS+oBxk/jnefvBtPBP0J\nnjhdCp8CngncrWnaxIy63o8XyP46vGH/j+H9b7y8nuQDeB69H9TPeQ9QYBU9PZLrntRlKBAIBILz\nFHWe+VUEAoGH8PQIBAKBQCC4KDiro7fqgWr/g9d/vF7TtCOLpP0VPHfwJXiutf8D3qLNM7unQCAQ\nCAQCwak4a54eVVV/Da/v8JTzGqiquhmvD/tzQDdef+duvEmcBAKBQLAAmqZ9XNM0SXRtCQQncza7\nt9LA0/ACnE7F7wP7NE37sKZpFU3T+vECqF6petO8CwQCgUAgECyLsyZ6NE37qDbPYnILcC0wd/2S\nB/C6465a1YoJBAKBQCC4KGjWGZkzeMPuZjJef28/1cGv/dYjYkia4LRQsPFh4cckgIWBDweFLmmU\nIAZBTAKSgen6aJXyhNAJSgYhdMLoKNJSliu6sHEcCduWsW0F25FxHBnHkXBdGduWcBzFS+PIRMI6\n5UqIWi2IZSs4U8fZMrYz47Ot4DgyhunDMn1Y9tRM/gJBcxIIKgSDfoqFGum2KOlMlEg0QDjiJxIN\nEI0FiSVCJJLeKxwJIMninl6A074wzSp6FuOUguYViSoTk0VcF6R6cnfGkd5nF3dqnzv1x9sn4YI0\ntWlGupNKn96H6+K60qw9832eLnDq49RnycvcBVeqH+NOHeuV00jquo1cHdfBdm0UScEFZNvBafzD\nuF7+jvfZlhVk1wYXnHpBriThumC5NrLt4Pr8GHIQv6PjujTOSXIccFxsRQFJwm1cWXAlF7lmYwUD\nuMjYskI5kCBey2PLCo6kMJrspqU0hgQ4yCBJOJJMNRChGoqRKE/gyDKOpFAJxQCQHQtHPje3qI2C\njYLeWADZ45DbN/3FnfM+A8U18bsmCiZ+THyY+CVvWwCDAAZpn4HjGMiuRZgaQckTTH4sFAmi9Qnf\nTQckqb5Qz3nUFsqyiyzb+P1Lm5ImlSwuuwzv3vVjOwFCvjKGHaZqxXBcH5bjx3Z82K4Px5WRsCmb\nSWzHh+X4cF0J3Q5hOX5Mx4/jyJSqJoZpk4wFG/9zrjv9vzfVVExtc936f6jrciJbIR7xEw76cB0X\np57Ycac+e/93rkt9f/1/2PGOlyQJ23Ya26fycFwXx/Fe9iJTjCz31pDxmoa5xy3n+1L3zfd5oWMl\nIISEXm+NpTn7JLw1GMwZ9Z+5X8ZbJr0sSSiSt81xXMKKjGK7uH7ZS296P0wkWcJ1ztzvZEO3MXTv\nfyA3XiY3Xl40vSxLhKP+aSHUEiaRDBGNB4nEAiSSIfyB8/HRffpkMvFTJzoFzXrlRoDWOdumYnmG\nT3XwM268gbGx5TeggjNHJhNfkk1c1wXbxrUsXNPENnRMXccwTCzTxLQddMPENr2XaZpYhkltfAw7\nFMaQZAoo+I0qNWTyviCRcgHLcSkFw+ihCOFKCcvnx/L5sX0+LMV7N/1BzEAAy3/S6gHLxpb82JL/\n5B0zW3pnnm2NCwG2nsN1azhuGccp47pV7yCnBG4JyS0hYyAjIQOy5DX4fskTpPKMlySBjEREkjBx\nUQAF76GgAIokNdJ627x9PsAnSfjr774Z25QZaX1T+SAh19PIZ0GhSRKemJRNAAJKlYBSPcVRi+Qn\n+1ECSWQ5iKwEQVKwzQLBWB+OWSYY60NWQii+CIo/juyPIithpFU416X8j7iui+3UX7aD5bjYtovt\nONiOi2k6dSHliSp7SizV303bmZXetl0sZ2pbfbvtUqyYlGsmiWigkWYsX8U0HVLxIFY9n6MjRfyK\nTCIawLQdLNvBtGa/DNM+9S/Vk890zvsKcN3Zh9t18W3O8cLWv0p497A847MC+JAI+mVCAYWgTybo\nU/ArEgFFxi9L+GUJx3IJ+WRwXBzLwTZt9JqFXjVZRKfOi+O4lIsG5aLByPH552oMhnzEEkESyTDp\n9ijptiitmSip1siq3IsXMs0qen6GN934TG4EdLxZMAUXKJIkgc+H5PNBKIRCnADeCoOrges4uKaJ\nY+i4NR2nVsOpVbGKReziJE6hgl2tYpkmVcOkVqtR001qLpiWRc2BmiRTC0cYa+8mWi6iB8PowRAj\n3Z4XSHIcXPn0w+UUJX3qNJJLQHaIKBCQbXyyhe2Uifl9yFgokslY5RiZcAxcC9u1MB0TyedSqeno\njoXlWOi2gemYmI6FYRlYjoXpWCd7KZeBJ8AgMEdcKdQFFOCTIC7LmK6LX5IISOCviyh/PY1f8h48\nfgn6/D4KjoMEBCWJwCo38K5jYtXGT9puVkcAqOT3zHOUhOKPISshzNoY4eRWlLoYkn1RFF8UxR9F\n8cdR/DEkObjiB5MkSfgUCZ8C+E+1EHfz4Dgulu1g2VPCy/FEkuW9G+a0SNJNG8Oy64LJmZV+apth\n2eiGTc2wqegWumGjm9530/LE13Jx8RaimnePaXuvZeBTZOJRH62JEMmgj2jQR8SvEPLJBGXv3vUB\nZs2iUjYoTtaolI2GV2gx9JqFXrPIjpbpPzB9vwZDPrrXpuham2TN+hbSbVEhguZw1mdkVlX12XjT\nTDfm6VFV9Wrgk8BzNE0bUFV1Hd7002/HW7+lF28K8ns0TfvDJRTjCk9Pc7FUT8/5gGtZWMUiTqWC\nUyljl4rYxRJ2uYRTrWJVKlSKRWrVGrWaTs00qSFh+oPooTBGMIQRCGEEggytWU/A0HEliYnWjjNa\n74AskQj4iPl9dCXChF2I+RWCskxbKEDcrxD3+1BmxBPYjo3hGBi2Rc2qYrk2hm1i2EZ9u4nhmJi2\nieVaDbFk2mZdRJnULB3dNqjZNQzbZKB4jGQgTs32tp8OEhCSICxJDY+UUhdPU6IoJUuEJAnLdQlK\nEi2KTKsik7MdQvXvZxNJ8iH7oyi+GIp/6hUnGglguq2eYKrvkyQxf+xKcFwXoy6CyjVrhriyqeo2\nNcOiqltUdIuabrP36AQd6TCG6VCqmdR0C91yKJQNdGN5Yme5hIM+UrEALfEgiUiAWNCHUTPpa416\nneuGQ6WsUykZlAo6xUINx17aczuRCtHT10JHd4LejWmiseCpD2piMpn4aSu4syZ6VFXV8Nb1kAE/\n3nL0Lt4Q9s8APwQ2a5p2sJ7+Jrx1OC4D8nhr2LxN07SltJJC9DQZF5LoWQlOrYZVKGAXC9ilEnax\ngJXPY5fL2JN573OhgDWZxzAM9FAEPRimGolRjsYZ7+ihEokxkW4nqFexfH4q0fiqdMXNJeZTSAZ8\nJAM+EgEfErA+HiYV8BOtCyPfKgZaOq6DYRtUrZonmByTilnBxcWwTXTboGyWGa/mCPmC1CydqlWl\nYlWpWTqGY1CzdIbKXs+3LMk47vJ/6fvwxFNQkghKEJIlYpKEIkkkZQnLhYgsEZIgIsnEZImo7KU/\nM0j4AimUQBxLnyCSusTrUvNF8QUS+AItKP44knz+eHzOJ6baLMt2qOoWpapJVbep1ExKVZOKblGu\nWTzVn6MlEaRYNqjoFoWySaFiYFqrM5hBliTaUiEyqTDpeJCWeJCORJBkwIdsOuTGvDihseEiteri\nUzP19KVQd3SyblMbwVCzdvQszHkles4yQvQ0GRe76FkOU54kK5f1hFA+jzU54X0u1EXT5CR2sYBu\nO5SjCaqRKNVwtP4eQw9HqAXD1CJRaqEolUgM2z9PjNEKifsV0kE/yYCPuN9Hwu81oG1hP23BAImA\nj+BZ9qDMxLANdNvAsA1qtk7N0huepql9NatG1a6h2zqmbTY8T1Wr5okqs8Kkcep7VgEikkRMlvBL\nElFJIixLhOviKCJ726ZE0mp3ySEHkP1xfIEWAsE0/mALvlAbvkAKX7BFeItWyOm0Wa7rYlgOkyWd\nbEGnWDEoVkwmyzqTJYOJks5YvkZ2soq1RK/NQsTCfnapGfo647SF/dhFg+FjkwwczmEu4qXq6Uux\n+ZIOtlzageI7P+4RIXoWRoieJkOInjODYxrYxRLm6Ah2qegJpImJhifJmpjAzGVxdL3uOYpSjcQp\nJlKMdPViBII4soweilCJxKlGoqs2RCzhV2gNBWgJ+GgLBUgFfcR8ngcp5lcIKfJ5EW/guA5Vq0bZ\nrKDbOhWzim7rjFezBJQAum1QqYukslmhateoWTUqVo2SUaJc91pNEQCidQEUk2SSskSnT8Zy69sl\niYgsEVuFuDDLhQkXUMKEZT9GuItAqB1fKE0y0kUymCCorDzG6ELmbLRZjutSqprkizr5kkG+pHN0\npIiMxHCuzMhElfHJ2rLylCTobo2yriNOV8SP33IojpYXDIoOhf1s3dnJ1p1dtLRGVuO0zhhC9CyM\nED1NhhA95w7XdbELBcyxUcxcFmtiAn+lwMi9P8afaccuTGJNToJt40gSlWicYqKFUjzFZKoV0x9g\naM16aqEIsmOjh1crrNxjfTxMJhQgE/LTGQmSCQWI+ZWzMvrrbDAlmmpWjZqtNwTUeDWLYXtB4yWz\njKNY5EoFSmaZslmhZpaI4tCieF1osRmCKCHLpGRvNN5Kr5PjusiSxH7TpuQq6HII0xdFCqSJBpPE\nAzESgThRf4RYIEoqmCTmjyJfJJ6jZmmzdMNmOFchV6wxUdQZz9fYNzDBkeHl1S0TDbA+EiBQs9CL\n80eJqDs6uf6ZGwmFV88rvJoI0bMwQvQ0Gc3SgAg85trDdRzsYhG7MIk5kcMcGcHMZr1Yo8k8ZnYc\na2LCm3dGlilH4xQTaSrRGIVEmlxbJ9m2TuKFHJVognI0jqusPNZEkaAjHKQt5Cfh97xDLUE/rSE/\nLQE/gXPYdXammO9/pGbpFI0SJdPzGE3ok+zLHSBby9ESTFG1KthmGb9TQ7IqpBSJtCyTkmVSikR8\nBd4i13UZdxzGbYei4zLpuORth7zjUEEhGogTD8RJBuKkQknSoRZaQ2lawy2kgy1E/OELQhg1e5vl\nui4TRZ3B0RLHxkocOVHk6EiR7GTtlGMuA8Aav0KrA8zpXguFfVxz8wa2XdbVdB5AIXoWRoieJqPZ\nG5CLjZXYw7Vt7GIBY3gY48SQ13U2kcMcG8PKZrHyE42JNx1JohRPUUim616jJKVYklo4Qq61AzMY\nOq36BxWZTMhPOui9gorM2miI1vootPPRS7Qa/yO2Y1OzdUpGCcMxKVTGwMxTq45hmEUwJvDbFdrl\nlbX7ruuSc1yydRE0bjucsByyjtN40MqSTDKQIBNuJRn03jsiGVrDaeKBOKlgAt85mnR0OZyvbVbN\nsDhyokj/iQL9JwocGyszlq9izzMBowSkgDU+hZA1e39be4xtl3ex7bIulCb5kSFEz8II0dNknK8N\nyIXKmbCH6zhY+QnM8XGsbNbzDuWyjdgiK5/HLk7HFZg+f10YtVBMpplMtTLRkqGQTGOEwiuuR8Sn\nsDYapD0cpCcSpDXkpy0UOKeB1UvhbP+POLaOUR1Fr41SqYxg1sax9SyyVVzxXP+P6SajtsOoZZN1\nHGrzPF5kSSYTbiMdSpEJt7Im1k1HtJ22cJpEIN40XqILqc2yHYf+E0WeOpLj6HCRPf05jDmjy1qB\nPiSUOdaPJYJcdX1fU3h+hOhZGCF6mowLqQG5EDhX9nBMA3NsHCs3jjEyQunRR7zJIms1rOw4Ts0L\n2tQDIXKt7ZRjSSqxOOVogkIy3fAYrbTrrDcWoq3eRZYJB8iEArQEfYROoytutWiW/xHH1jGro1jG\nBJZR8N71LJYxiW0UWO4syabr8qhuMm47ZG2HUdtZYBJAj0QgTlu4lXQoRWsoTUckw9p4D5lIG/6z\n6CFqFnucCWzH4dDxAj/75TC/2DvSmItIAXqQyODN4D6T3g1pnvNrl+I/h5NiCtGzMEL0NBkXcgNy\nPtKM9nBdF6dc9rrNsuNYk3nMkRFqA0cxR0awJrw1iF2gFo6ST7VSSLVybO1GZMehlEhRSLSsuOts\nTTRIRzhIRzhAR10QJQK+s9ZV1ow2mYvjmJ4g0nOY+jhGZZha4cDy8nBdxmyHMdthpC6CRmwb/RSP\nIlmS6Yy00xHJ0BFtZ02sm65oB+2RtjPiHTof7LEa6IbNU0dz7OnP8eC+UYoVEx/eqt/dSLPETyDk\n40V3XEam8/TXwFoJQvQsjBA9TcbF0oCcL5yP9nB0HXN0tNFtZuZyXnfayAjG6AhOuYwLXjdZup1c\nWwcnutcx3tGDZNsr8g75cGn1KWRiIVpCAdrDQbrCATLhAP5VGFI+k/PRJlM4toFROY5ROYFRHcGs\njmLWRpaVR8FxGbZsRmyb45bDCctmKTPR+mU/7ZE20qEW2kJpOqIZOiPttIbTpILJFQui89keK8Vx\nXQ4dn+QHDx/jwX2jyC6sRSIz0+sjS1zznM1ceXn3Wa+fED0LI0RPk3ExNiDNzIVoD0fXsXJZjLEx\nzNERzNERKk89hV0qYek1ysEwk6nWRhxRviXD8d5NyLaFoyy/2yQlQ3ckSDISoicaIhHw0VqfsHEl\n3qELzSau62KbBYzKkCeEamOY1REsPbfkPHQ5SNaRGTR1DtfKHLdslrMoRED20xJqoT3SxppYN32J\nNfTEupYkhi40eyyXiaLOjx8f4vsPDRKrWfQyfb0cXErJIDfeuJ7rt3eetVgfIXoWRoieJuNib0Ca\njYvNHo0g69FRzNFRjNERL7g6l8XIZSkaFvlEC7nWDvLpDPmWDMV4Cj28/Mna/K5DWpFoCfrpSUbp\niEbojgRJBRcXQxeLTRyrWhdBo+jlY5jVEUw9B+6p5YyLjOlPkHcVjls2h6p5BmolzGXWwS/7WRPr\npj3SRnukjZ5YF2vjPbMCqS8We5wK13V57OA43/neARIFHanu9XFxOYSLnAhy6w3redrOMx/oLETP\nwgjR02SIBqS5EPaYjeu62MUixvAJrOw4pUcfQY5EmBweYbRY8eKFkmlyrR1MpDOUY0ncZXZvyY6D\nI8tsxCQTDdHZkmRNItroKruYbeK6NmZ1DKM6jFE+Rq10FEvPLv14X4xaMEPO9XPUNDhazZOt5Sib\nlWXVI6QEWRvvYWNqPVf2biMjdRJQVn99u/MR13X5xaPHeeT7h5Dqw99dXI7iMgas70rwqltUejvO\nXLyPED0LI0RPk3ExN+jNiLDH8nBtGyuXwxgdwRg6TvHQIY4dGeTIlu1YksxBdSeJyRyVaJzaCmas\njpo6HT7IBPykk3GSiTi9sRDJgO+cDxM+Vzi2gVkb9brHKsPo5cElCyFfME0osRklvolJKchQeZhj\npSEGCscYqYxRMstLykeRFNYletmUWs/W9GbWJdZe9CIoO1riq595DEOfHoM3gMMIEPDJ3Hbjem65\npveM3LdC9CyMED1NhnjINhetjMY0AAAgAElEQVTCHquD67pYEzmsiQmMEycwxscoTBaZKJUZk3yM\nh2LkWtsZ6e5bUf5hU6fdNugMyHQmYnR1ZGhPxppiiP25wDZL6JXjmNURKhN7sK0qjlVa9BjZFyEQ\n6SEUX084vhFfqI2iWeJ46QRjlSzDlREGCsc5UR6mZuuL5uWTfaxP9LIhuY6+xFo2p9YT8Tf3elVn\ngnyuwuf+84FZ2w7hMBWt1dsR47Yb13PF5syqlitEz8II0dNkiIdscyHscXZwLctb8yybpTQ2zlg2\nx3hFZ1RSGA/HmUy1UYovv6uspVygy67RGgnTmU6xpr2VdDKOssojys4HHNtALx1FLw+il49hlI/h\nugvPBKQEUgSja4i0XEoovgFZ9taZcl2XCT1P/+QA+ycO0l86yvHC8CnLXxvrZkfbJVzRvpOuaMdF\n45nL5yp864tPMjlRBbypJPbiMNOHdvW2dl51y1bCwdWZX0mInoURoqfJEA/Z5kLY49wz1WVWGxlh\nbGSEsXKFA6ZCSZKp+QPkW9owgkufmVqxLZKVEmmrRkZyaU3E6Gproauzg1D04vFGOI6JXuynPPEU\ntcIBHLu6SGoJf7iTUKyXUHwDwdhaZMWb5ymTibN/cJAD+cMczPdzMN/PSGV00bJbQy1cntnB+mQf\nW9ObCPtWPrP4+UCpUOOLH3+YWmU6lPxxnFlTDaRiAf7o9p2s70qcdnlC9CyMED1NhnjINhfCHs3H\nlE1c18UuTGKMjDI6nmMwX2TUtMlKPvKhCJPJ1mV5hiTHIVGapKecp9sn0ZdO0L2uj1B7O9IF7hly\nXRezNoZeOkqteJjq5H5ONaO0JAeJpneQzvRi+zag+KYF40QtT39hgP7JoxzIH+ZYcQh3gfxkSWZ9\noo8NyT42ptaxKbX+ghRBI0MF/veTjzS+t3bGOKzA/uOFWelee+slXHdp52mVJUTPwgjR02SIh2xz\nIezRfCzFJq5lURrPcuT4MKMTecYrOmNKgFw8tawAatm2SeazdFQm6XRMuvwSPW1pImvWEOjuRvZf\nmMG6jmNSzj2BURnyAqNr46c8JhDpIZLaSji5FX+odda+qlVjz/heHhx5jKdyGo7rLJALSEj0Jdai\ntmziqo7L6I6evfltzjT7njjBD7+lNb5v2d6B2xnjcz84wEyJ8cLr1/FrT1u/4vMWomdhhOhpMsRD\ntrkQ9mg+TscmruNQHB1jeDzHSLHCWKVG1nLIBsIUoglYwkNGchwSk1nah4/RbVbpDgfoTMWJrO0l\n2LcOX+L0uyeaDceqoZcHKE/8kkp+L7gOi3mCAtE1hBObCUbXEIh0IyvBxj7dNtiX28/hyaM8ldUY\nKi8eD9QRaWd3x+XszFx6QQign3z3AL985Hjj+6/cdglKKsS/fOkJCuXpDq/nXdvLS27euKLzFaJn\nYYToaTLEQ7a5EPZoPs6UTXTD5MiJEQZGswxUTIYVP+Xg0mJ8FMsklRujJTdGulqiR7JZk04Q37CB\n0IaN+JKpVa/vucSxalQLB6kVD+GY41SLQywqgiLdRFouJZq+bFY3GEBen+RIYRAtd4BDk0cYKg0v\n2BXWGmrhivadXN15JT2xrtU8pbOGbTt87J/vwzKnvV2//cbrqdku//n1PWiD+cb2my7r5lW3qMsW\nPkL0LIwQPU2GeMg2F8IezcfZtEnNshnI5jkyMs5o1eC4IzPpW1qXluQ4JPPjtI2dYM34ED0hPx29\nawn39hFcswYlmTrvvRbg2WN4aJhKfg/VSY1a8SiwQPeVJBNJbiOa3kkwvq4xImwmJbPMnvF9PDz6\nOPtyB7AXmIF6Q7KPqzuv5OrOqwieZ3MC9e8f49v/u6fxvXNNgttecTmW7fKBzz/KoRlxPi+6YR2/\n+rQNy8pfiJ6FEaKnyRAP2eZC2KP5ONc20W2H4+Uah7N5BicKDJsuRXlpQ439eo22sRN0H+uns5ij\nK+QnmskQXLOW8ObNBDq7kHyrM2z5bDHXHpZZpFY4iF4+tmg8kCT5CKe2Ek5sJpzaOq8Aqlk6v8zu\n5dHRJ9ib249uz7+06rWdu7h143NJBZOrc1JngZ/94CCPP3is8f2qG/q4+mnr0Q2bv//cI/SfmL6m\nL3n6Rp5/7dLnsBKiZ2GE6GkyznWDLpiNsEfz0Yw2KZkWwxWDE+Uqx3N5BismE9KpJ0aULYuO4QHa\nR47TPjxI28QYiXQLTk0n+fRnEN6wicCaNSjh5h3NdCp72GaZ8sSTlLOPYdYWHsoea7uKePt1+IPp\nefebtskT43t4ZPQJnhh/6qRgaEVS2N1xBVd2XMbWlk0ocvNPTHnPN/ai/XIE8MLJXvxbV9LelaBU\nNXnXxx9kfLLm7QP+6PadXL65bUn5CtGzMEL0NBnN2KBfzAh7NB/ni01qls1QRefAZJn+XIEx3aJ6\nihXLAeKTOTpPDNA5dJSOEwPESgV8ra0E16wluLaX4NpeAl3dBDo6kJpgxuml2sN1XYzKEJX8Hir5\nvdjG5LzpwknVmxAxth7FP/9Iu7w+yQ8GfszDI48zaRRO2h/3x7i2axdP67mO1nDL8k7oLGJZNp/4\n8P2NpSpa2iK89NW7kGWZUtXkb/7nAbIFb/ZrCfh/r7gCtffU5yNEz8II0dNknC8N+sWCsEfzcb7a\nxHVdcrrJwUKFo8UqRwtlJqxTP1dihTxrBg/ScWKAruNHCNXqkwgqCqF164moWwn2rSO0bh2+dOtZ\njxNaiT1c18WsDlOeeJLS2EMLzgwdiK4h2rKDaMsOZF9o3nweH9/D94/eS39hYN48Lm3dyos3vYDO\naMey6ni2GBsu8qWPP9z4PtXNBXAiW+bdn3iImuHFNbUlQ7z3967FpywunoXoWRghepqM87VBv1AR\n9mg+LiSbTOgmR0tVjhZrHCvXGKnqnEoHJfJZMqPHaR8+RtfxI8QLE0w94ZR4nOCaXoJ9fUS37yC0\nYSNy4MwG+Z6uPVzXpjp5kOLYA+il/gVSyYQSG4lndhOKnzyM23Vd+gsDPDr6BA8MP3LSQqk+SeHm\ntTfwnN5nEAssf6HbM8193zvAkw9PD2N/3Z/d3DjHY2Ml/vaTD6ObnvC5cWcXr37+tkXzE6JnYYTo\naTIupAb9QkDYo/m4kG1iOQ4DpRoHChWOlmocL9cwncWfPZFSgdbxYTKjx+kcOkrb6BDy1PNKUQj1\n9RHespXwxk2ENm3CF1/deYRW0x5mdYxyfg+1wiGMyvF50yiBJIn264m1XYk0T9yU6Vg8Of4UPxj4\nMUfmeH+CSoBb+p7Fs/tuRl5CV+PZolI2+MSHf9b4/vTnqWy7bHpI/ld/cpiv//QIAIos8cHXX08y\nFpybTQMhehZGiJ4m40Ju0M9HhD2aj4vJJpbj0F+s0l+scrBQYaiicwoNhOQ4dA4doffIATKjx0nl\nRvHZ08O+felWgn19hOrxQcHeXnwt6RUvtXGm7GGZRar5vZSyj2FWT57AUFZCRFuvINqynUBk/jl7\n9k8c4tN77yJbm5i1vSvawa0bbmFH27amET9f+fSjDB/z4pwSqRCv+P1rGt4e07J547/c1/D2XLUl\nwxtevGPBvIToWRghepqMi6lBPx8Q9mg+LmabmI7DUFnnSL1L7HCxgnEKFaRYJu3Dg/QMHqZn8BCp\niXHmPhGVZIrIJZcQ3bGT6KU7UKJL7wI6G/YwKsMUx35BdXL/vAujhuIbSHTcQDC27qSuL8d1eHD4\nUb5++Nvk9dnB0z2xLl51yR1NMdHhYH+Ob3zhicb3F7x0B70bppfz+PYvBrjrhwcb39/80svYMWP/\nTIToWRghepqMi7lBb0aEPZoPYZNpbNdltGowVNE5XKhwqFClYM4fFDxFoFal88QA3cf66evfR7g6\nO/4FSSK0fgPRyy4ndvmVBLq7Fw2OPpv2sM0yxbFfUBp/eF7x4wu2Ec/sJpq+DHnOhIWWY/HN/u/x\nvaP3zprxWZZkrsjs4JZ1z6I7dnoLfZ4uX//cYxw/6s3IHI0H+c3XXzvr2r/tzvsZnfDO+9J1LfzJ\nHVfMm48QPQsjRE+TIRr05kLYo/kQNlmcXM1kf6HMoUKV4+UaeWMREeS6tOZG6Tl6kDVH95MZHTrJ\nC+TPZEje/AxiV+0ikGk/KYtzYQ/XtakWDjI5dC9mbeSk/bISJtF5E/G2q5DmTBw5Ndz9x8fvx3Km\nr42ExDPW3siLNtyCXzl5osSzQW6szBc++mDj+7VP38AV1/Y2vu89kuMDn3+s8f1tv3ElW9aevMSJ\nED0LI0RPkyEa9OZC2KP5EDZZHhO6yaFChb35Mv3FKjV74RXOY9UyPYf30TN4mI4TRwka+qz9/ky7\n5wG67HLCm7cg+Xzn3B56+Til8Qcp555k7vpfkuwnmr6cVPczZy16CjBYHOLTe+/iWGlo1vaWYIrn\nrXsW13XvPifxPl/+xMOM1mdjDgQVfvfNT5u1/28/+RCHhry5idKJIB98/Q0n5SFEz8II0dNknOsG\nRDAbYY/mQ9hk5Tj17rCDhQpP5IocK+sLJ3Zdeo8eoOvYYdqHj5HOjszyAknBEPFdu+l70fOopbvO\n+Tpi3szPT1AY+RmONbvLTpIDpLqfSaxt96x6uq7LwXw//3vwbgaKs0eL9cXX8luXvIzO6MnerTPJ\n/j0j/ODuvY3vd7x2Ny2t0zFWTx7O8k93Pd74/pG33EwwMHsUmxA9CyNET5MhGvTmQtij+RA2WT1K\npsWRYpW9+TJ7JkqLBkWHKyXWHdrLhoO/pHXsxPSweCDQ3U105+VELrmU8MZNyMGFh1OfaRxbpzT+\nCPmh7520zxdqo6XnuYQTG2dttx2bHx37KXcf/g6GY87ad03nVdy28Xkkg6s71H8xPvK+exuf129p\n45YXb298d12X333/Dxvf73jmJp5zde/Mw4XoWQQhepoM0aA3F8IezYewyZnBdByOFKscmKygTZYZ\nq5kLpg3qVboGD7P+0FP0DB6aNSQeWSa8aTOxq3YRv/qaVZ8XaKm4jkVp/GEmR36KY5Vm7Yumd9Ky\n5vknBTuXjDJfP/xtfjb0wKxg55ZgildvfwUbkuvORtX5+Y8O8+j903MM3f4qb02uKf79q7/koX3e\nOmYbuhO8/bd2zTpeiJ6FEaKnyRANenMh7NF8CJucHaa6wfblSwyWdfQFYoEUy6Jn8CDp7Ci9/Rot\nudHpbjBJInrZ5SSuvZ7wFhVf4uwLIMeukRv8NpWJJ2ZtVwJJ2tbdTjC65qRjBovH+cy+LzE4p8vr\n9k0v5Jm9N53R+oLnzbnz73/ElOwIhX38zh/f2Nj/8z3D/OfdTzW+f+xtz5x1vBA9CyNET5MhGvTm\nQtij+RA2OfvYrsvhQoXHs0X2T1YoWfaCaRP5LOsO76Vn8DCZ0ePIzrRY8nd0Erv8CuK7dhPsW7fi\nCRFXglnLkhv8JnrpyKzt4dQ2Eu3XE4z2zNruui4PjzzGp/beheVOn+8z1z6N2zffesbrOzSQ52uf\nnR6p9eu/s4u2jhgAhbLBmz58X2Pfh9/0NKKh6RFnQvQsjBA9TYZo0JsLYY/mQ9jk3OK4LsfLOo/n\nijw1UVp0SLximvQe3c/6g3tYM3holgDypVu9LrDd1xDesOFsVB2AyeH7mBz+EbizhVukZTstPc89\naWX34fIoH3r0TiaN6Xtua8tmXn/Zq1HkM7fKveu6/Mf7f9T4Ho0H+a03XNf4/ur33TP9+fnbuHHn\n9ASLqyF6lHe+852nm0cz8s5KxTjXdRDMIBoNImzSPAh7NB/CJucWSZJIBnxsSUa5viPF1X0ZbMNG\nkbzA6JnuAVdRyKfb6d90KU9t300h1YrPNIgV87jVKrXDhyj85EcUH3oQ13UJtGXOeBB0KNZLJHUp\nlp7DMqaXpzBro5Szj+ELteEPtTW2xwJRru++hn25/Q3hM17LcaQwyPbWbWdsTh9JkgiH/Qwcznn1\nM2zU7R0E6x6dnz55goruCU5Fkdm9dXqUWTQa/JvTLV+IHsFZQTTozYWwR/MhbNI8SJLEmtYYa/w+\ndmWS3NDRQnckSECWKFsO+gzPjuPzkWvr5NCWnezbvgtHVkjlx/FZFnaxSOXJJ8jfew84DoHOTuRQ\n6IzVW/FFiKZ3EkpuxtJz2IY3C7LrWlQm9mBUThBObGpMbOiXfVzTeRWHJo+Qq6/jNV7N8vPhh9iW\n3kIiED8j9cx0xXnop0cb3wcP59hxlReD1NUa4f493sSMQ+Nlbr1hegkOIXoWRoieJkM06M2FsEfz\nIWzSXMy0h0+W6AgHuaQlxg0dKbalogRkmYJpzQqEtn1+hnvWsXfn1eRb2khNjBOqVcC2qWr7mPje\nd6gNHEWSZAIdHWcs9sfnjxNN70TxRdBLR8H16mjpWcoTT+ILJPGHMgAossLVnVdSMssMFI8BYNgG\nPx16gK5oB13RjlWvnyRJKIrUWJrCH/Cxc7cnelqTIe6ur7wOsK4zQWdrBBCiZzGE6GkyRIPeXAh7\nNB/CJs3FQvaQJIlEvRvsho4UmxPeA3msajAlf1xJJp9uZ9/2XezdsRu/YZDMZ1FsG3N4mNLDD5L/\n4Q9wDIPgmrXIgcBJ5ZwukiQRjPYQaal3eeled5Lr6FTyT+E4JqFYL5IkI0kS29u2EfNH2ZPd56XD\n5ZHRJygZJba3bVv1+iVawjz+QF1k6RaXXtGNP6AgSxLffXAQqy4mh7JlnnGFF4wtRM/CCNHTZIgG\nvbkQ9mg+hE2ai6XYQ5IkUkE/l7TEuK4jSdzvI29YlGeMArN9fo71bULbvhtbVghXSoT0Kq5pUt2v\nMfnjH+HoOsHeXmT/6osfxRcmmt6BEkhRndQa243yIOXcYwQi3fgC3jpX6xJr6Yy08+jYk410R4vH\ncFwHtWXTqtYrEPChPTmMUY/fCQQUunu9epSrJgePeyvHS8At13iTFArRszBC9DQZokFvLoQ9mg9h\nk+ZiufbwyTJrYyGuySTpjYUYKNWozuz6UhSGu/vYt303wz3riBbyxEuTDfGT/9530QcHcC0Tf6Yd\nyedbpLTlE4h0EmnZTnVyH67jnZfrGJRzjyMpoca8Pt2xTq7v2s3Phh7Ecj1BcjDfT82qcUmruqp1\nqtVMTgx64mZoIM/uG9cBEAwo/OSJEwDops1tN64HhOhZDCF6mgzRoDcXwh7Nh7BJc7FSe0iSRGso\nwPUdKa5sS5DwKxwv61gzpocpxZMcUi/j+HoVv14lMZlDsm2ME0OUHn2E/D3fx8xmCW3YsKqjvhRf\nhHjmGmTZT63Y39heKx7C1HOEk1uQJJmwL8SOtm385Pj9jTT9hQEOThzmms6rVm09snAkwJ5HvYVR\nZUXi8mvWIssyiWiAu392pJHuedf0oiiyED2LIERPkyEa9OZC2KP5EDZpLlbDHmGfQl88zLXtKVqD\nfizHZUKfXgajEolxdMM29lx+HZVInLaxE/gtE9ey0I8eIf+D72GOjaEkU/hbWk73lIB6rE+sl3By\nC3plqLGUhVkbpZrfRyS1DVkJEA/EuKnnOvblDlCoD2nP1iaQJInNLRsXK2LJhKMBHrrvCACuC53d\nSVLpCLIs8bX7pkXZ9g2ttCZDQvQsghA9TYZo0JsLYY/mQ9ikuVhNe/hkie5oiCvaEuxIx6lYNiPV\n6bxdWSbb3o2282qkaIzWY0eQXQccB31wgMJPfkRl317kcIRA5+qs/K7UR3gZlRONeX0cq0I5+xjh\n5BYUX5SgEuC6rl187+i9jTW7DuQPc0lapSWUPO06AJQKNcZHPOEVjgTo3ZAGmCV6utuibFqTFKJn\nEYToaTJEg95cCHs0H8ImzcWZskfUr7A9HefKNm+9rsFyrbHPkSROZLo5csV1RGWJ+PAxpHq3mJXN\nUnrwAUoPPYivJUWgq/u06yJJCtH0TlzXQS97C4G6rkU59wT++mSGsiRzbdcu7hn8SeO4Xww/zK6O\nK4j6I6ddB1O36N8/DsBEtsyV1/UBoA1MMD7pXZtwUGH3to5VET1nb4EQgUAgEAgEALQE/bywN8M7\nr9zIi9e1E/VNL/1QkBTuufIm7v79t5F/xnNnHWecGGLo3z7MsX/8ALWBo3OzXRGp7meQ6nlO47vr\nGIz330Vp/BGvrqEUf3j5a/DVJzW0XZt/fvQ/qJiV0y67u2+6287Q7cZoru626WUzsgX9tMuZQoge\ngUAgEAjOEQFFZlcmyf+7bB3PXdOKX57uuppwJL66ZRcPv/kdSM+6ZdZxlaf2MPCudzD4gfdR6z98\n2vVItF9L2/qXzdqWG/wW1cIhALalt/Da7b/Z2JfXJ/nEU58/7XJj8dmB2sPHCwB0tU6Lnlyhxmoh\nRI9AIBAIBOcYvyxzc1eaP9mxjhs6UrPEz5MVi09t3sWet/4N3PysWcdVtX0M/O27OPFf/4GZy51W\nHSIplbZ1L5mxxWH88BfQK94Iq+1t23jJ5hc19v4yu48vH7j7tMoEaGmb7ibLjnnxPWsy06JHlldn\ntBgI0SMQCAQCQdOQCPh4QW+GP97ex6bEtBiwXJcHiwaf3Hot+970dvxXXzvruOIvfs6Rt7+NsS9/\nEUdfeXdQpOUSMhtfgSR7HhjXtRjR/rvh8XnG2hvZ3XFlI/09gz/hqaw2b15LZcul00tdDNYXIu1I\nT5/7RFF0bwkEAoFAcMGSDvp5tdrD72zpJhOanqnZAX5edfnEVc9mz5v/GmfbpY19rmEw8X/f5Mhf\n/wXlPb/Edd15cj414cQmOja/CqRpiTB2+HOUJ/YA8NItt9ERyTT2/dvjH2Will9RWQAtM7qyptbj\nSkYDKDM8PIVVCioXokcgEAgEgiZlczLKH2/v5Tc3d9E+Q/wYjsuDFZtP3/yr7Pm9tyB1djX2Wdks\nx//pgxz7wPswTgytqNxApJP2jb+BJPu9Da5D9siXqeT3EvGHed3O324ENgP886N3rlhk9fSlZn0v\nl3QkScJ2pvMbnaiuKO+5CNEjEAgEAkETI0sS21Ix3ri9l9vXtZMO+hv7HBcelMJ8/sWv4eArXoMz\nY+X26n6NI3/1Fwx/4mPY1eWLhlB8vefxmcF4/xep5PfRHslw64bpkWXj1SzfPnLPCs4OAsHZS24c\n2jvmbfdPn0upYrIanFXRo6pqRFXVf1dVtV9V1UlVVe9XVfVXFkn/SlVVH1NVtaiq6pCqqp9VVXXN\n2ayzQCAQCATNgCxJXJVJ8pYdfdy+voO20LT4qdoO98U7+Nrr/oLjz799lvgp/OTHDLznnVQPL3+U\nVyDSTWbDHbO2jfd/EaMyxLPW3kQqOD1J4Tf6v8OBiUPLPzEgPSNweWjQ6+K6bGNbY1uxepa6t+pC\n5Q9UVf26qqoDqqpW669BVVXvVlX1daqqLnWGon8FrgeeC3QAHwfuVlX1pFXMVFV9FvAJ4L1AGtgF\ndAGfWWJZAoFAIBBccMiSxFVtCd60vY9b1rTO2jdpu3xv7Vb+7/ffxuT2KxrbzZERBt/3Hsa+dNey\nA53DyS10bXsDshKub3EZO3wXjlXmXde9jbg/1kj7ocf+i6q1fK/SpVdMT7aYGysDEAtPi7qB+qzN\np8uiokdV1d8BDuMJDxP4b+At9dd/AUZ932FVVX/3FHm1AK8E3qlp2n5N02qapt0J7AVeN88hu4Bx\nTdPu0jTN1DRtCPgCsHs5JygQCAQCwYWILEnc1JXmbZet57r2JMqM5SnGHImv3PB8jvz2G2BqxXbH\nYeLb3+LoO/+Kyt6nllWWP9RK+6ZXguRNomibBUYPfhocg1/fclsjneM6fEH72rLPpbNn2mM0WY/f\nyc6Ynyce8Z90zEpYcO16VVU/AdwMvB34uKZp1gLpfMCrgL9UVfUmTdNeNV864CrADzwwZ/sDwLUn\nJ+ebwDtUVf0N4EtAEngZ8MWFT0cgEAgEgouLRMDHrX3tPL07zf0jee49MdHYd28wxYbX/znXfv+r\nBJ56EgBzbJRj//D3hDZuIvOSlxLevGVJ5QQiXbT23kr26Fe9fGqjjOz/KFeov8f1XVfzsxPe4/3B\nkUe4putKtqWXli/M7t4CMA2L9V0JnjiUBVYvpmdB0QMEgB2aphUXy6Auhj6qqupdwJ2LJJ0a3zZ3\n9qRxoH2efH+pquorgE/VXxJwL/CGxerTKCwTX0oywVlE2KS5EPZoPoRNmovzzR4ZYEN3Czdu6ODf\nHz5MrubFwRzWHY7edBu7b3gmWz77UeSy11VUO3SQwfe/F/XP3krb9dctrYzMDURCLoN1b46l5yie\nuJs33vAbjPxghEMT3tIYH3n8Y3zmJR9GllcWOhwM+EmnpiNnxlZpVuYFRY+maS9fSgaqqsqapjl1\ncfSKFdbjpHFuqqreiCd2Xgt8HU8YfQT4GvCsuennMja2qFYTnGUymbiwSRMh7NF8CJs0F+ezPSLA\nmy5dy1eOjPJo1jsH23X5uRxj72+/mWc/fh/x+37YSK+9/4OMPf+FtP7qi5GWIFKkyGUkO/NMDv8I\ngMmxPex/9Au8fMtLeM8v/qFensOXH/suT197w5Lr3d4dZ3TIq+/DPz/KSG3au5Ncpe6tpQQy/3/2\n7ju8qaoP4Pg3abo3bWlZhbIOypKpDEX2FhAVRVFQXpGhDEVfURFEURQQGTJ8QRQFRfbegjJEEBBZ\nF5BRKasFunea94+UpKEppHAtKL/P8+Tpvefee85JUu2PM7sopZYopeZdO9NKKVUB2OZiWRdyf4Zc\nkx4KnHdy/wDgZ03TvtM0LVXTtFPAW0AzpVRVJ/cLIYQQAjAZjTxePoIelUoQ4W1f3ychO4fF1Rpy\nss8QLO72QOLyqhVEjx5F1qVLLuUfWKIJ3oFVbOcpl/cTlJ1A5eCKtrQfji0lLs21/AAy0uyjaNJS\nM4nIsypztvnm1gC61o0GMj+FdfCwJ9bZVquUUh1yr/0H2Id1MLMrfgMyyD9+pxHwc/7bcct95XW1\nZUrWFxJCCCFu4J4gPwZUjaRt6VBMuQOdcyywBW8W/ecNDJHlbPdmnDrJ6ZGuD3IOjXoc68gTq7jT\ni+mlHsXb5GVLm3nA9cPni6gAACAASURBVAnXYRH27sSYU/GY3Ip+ReZBQG9N09pqmtYMeAV4Rym1\nFJgAvAM87EpBmqYlALOAkUqpyrlT4V8DygHTlFKllFJHlFJXOxYXYm3V6aqU8lBKRQDvAn8AhRt2\nLoQQQtyljAYDD5YI5sV7SjssbJhktrDpsecJbG7vxMlJTSVm4qekHjl8w3wNBgMl7x1gO7eYM0g/\nu5qn1KO2tOikM1xOv+Ls8Xzyrsxs8nDD5GYPUf4qiinrQGWsLT1XfYN1yngx4D5N0yZomlaYNqfB\nwEZgK3AJ6Aq01jTtNNaZXQrwBdA07TugHzA8914NSAE6aJpmLkSZQgghxF2vtK8XA6tFUi3Yvq7O\n6ZQMVtZuQkj/gRh9rDOoLFlZnBk7hvgtm2+Yp8kzmMASTW3n6UknudfbHw+jPbjaEP2TS/ULDbfX\n6/yZBHLybGtRMtTX2SOFZrjeXhlKqVRN03yuSUvTNM27oGfuEJZ/6gC0f6t/8qDAfyP5Pu488p3c\nWf7t38csLYbjiam28xBPd3oGm7g8eiSWLPsA4qCWrQl74kkMedYAupbFYuGvfR9g3Q7Vap9/HdZG\nb7Gdf/LgSHzcrx86ZGZkM/PTrbbzJo9XY+wP+23ny8d1KrgSLrqZsTH6jCYSQgghxG3Rs3JJaofa\nx9Bcysjif5ez8PrvcNzDw23p8evXcnbip1iynS7VB1i7uYpX6uGQ1sAtDfc8rT0b8wRABbl2D66k\nS/aVnfVq6ZEBwUIIIcRdxmgw8FhUBK1K2SdUJ2RmMzMuAwa+gWdkWVt6yh/7OTPu4+vuou7lVxaf\noHtt52nxh6gbZj/fH3fIpV3YK1ezB1zpSfbtMszmHGe3F9r1FicE8FBKfX2jNE3TntWlNkIIIYQo\nMg+XLEaAh4kFJ62rymTmWPgy+jJt/zOQyEXfkLJ3DwBpx45y8ZuvCe9R0KYLEFLuUVL32ecZNfPz\nZ0fuYjVnU85z6LJG1ZAqBTxtlXdl5lOHL9qOzTlFMGUd64DjMte8fnaSJoQQQoh/oNqhATxXqSTu\nRuuQmWyLheVnLvHno8/gX/9+230JW37kyqYNBeZjMBjxL25flSb78j4ahd9nO19/evMN61I8z7R1\nY57ZW3EJf/OKzACapj2sSylCCCGEuGOpIF/6VCnNjCNnyMxtVVkfcwn/zk8RFH2arPPWNYRj536D\nKSgY/9p1nOYTVKIZSRd/sZ039DTaVjA+Fn+CCykXCffNt/OUTUhx+wyuZJ0CnbxcGtOjrMrrXroQ\nQggh7gglfb0YWK0s/u65O6lb4IfTsZzo9TIeJUra7jv3+SSSft3pNA+D0eQwhd2YdJTyfvZxOpvO\nbHX2mI2Xt+N2E1dbZrw8rl2r+ObcaEXmkkqpPcBh4JhSapNSKliXkoUQQghxRwn2dKdPlTJ45+la\n2ng5lT1P98HoZ2+FOTdjKlc2rHOaR0C4435bbfztiw7+duF3ciyuD0r2zP2Z48IgaFfcqKVnFBAP\nNASaYA26RupSshBCCCHuOMW83Hm5aiSlfDxtabuTMjnU93WMYfZWm9jv5pK8f1++5w0GI/5h9rE9\n/ukxlHK3bk2Rlp3Gpr+c7Txl5+tvL/fqkU4xzw2DnqZYt6H4RdO0rUBvoK0+RQshhBDiThTk6c6L\n95R22Kz0l8QMNnd/CUNomC3t7MQJmFNT8z9fqiUmz2K280f87a1E+y4euG7ZGXl2V7+6GqEr091d\ncaOgJ0LTtBN5zo8BJQu6WQghhBD/Du5GIy9WKU0ZX/sGoifSs1nerQ85Rnv4cOHLmfmeNRgMhJTt\nYjsPsKRTMXes0MnE02Sas/I9c1Wle+2tSVdLydFnmZ7CLU6Yu8/WLS8DLYQQQog7n5fJjT73lOae\nIPv6OXHZFrY+0x9zbuCTvPc3kn7bne9ZT99SeAdUtp0397YHT8fi/yywTJPJHppcHchcVC09Qggh\nhLiLGQ0Gnq5YwmGj0hPeAWzo+Izt/Pz/ppMZezHfswHhDW3HgUYDvrl7eC08trzA8vKO6fHKbWfR\na/8rWZFZCCGEENdlNBh4skIEXx87y9EE6xiecxFlONigOVV3bMSSlcXl5UuJeP4/Ds95+kXajg0G\n6ObvxazENC6kxhZYll9A3qBH5/dxg+uyIrMQQgghMBoMPFeppMMYn101HuB8CWsYkLh9Gwlbf8r3\nXLEyHWzHYW5u+Oe29qRnO198MO9aPXp3R8mKzEIIIYRwicFg4KkKEXy8/5QtbUP77nRY8D+C4i9x\nYfYsvMpF4Vna3h7iG1KLy3+tsJ1X8zSxIz2Lg5c06oTXzFeGf6A9qLpRd1Rh3Whxwn5O0proXAch\nhBBC/EMEebrTs7J9Ine2m4nlXV/AbLTOzjo9agSW7GzbdYPBQFCpVrbzep4eGIDfLuRf4wfA2+fv\na+m5UX5jnaSt1rkOQgghhPgHqRzoy7OV7IGP2eTO8keftw44Npu58PWXDvf7hdYBgzUo8jYaqOph\n4ve4g07zNrnbt5ww6Txh/EZBj7PSZMq6EEIIcZerEuRLw3D7FhPxIcU5Vf4ewDq+J/2kfZk/o9Ed\nn8AqtvP7PK2tOUcuH8uXr5ubEU8ve8eWe747bt6Ngh5ns8T0mjkmhBBCiH+wdmVC8cmzrs5PzToR\nF1oCgPMzv3BYX8crwL5vebDRiAHYcma703zzTlv31rG+sk6PEEIIIW6K0WCg372R9u0i3NxY3+5J\ncoxGMs+fI37TBtu9vsXsg5Z9jAbC3YzsL6iLy8kChbrUV8e8hBBCCHGXKebpzvOqlO08w9uHLc2t\nW1DEzvuWrDjrmjwGgxFPv3K2+6p6WMMZZ6st5x3M7K3jqJobBVDuSqmROI7jMV2bpmnacN1qJIQQ\nQoh/lAoBPjQoHsiOiwkAnC5fhaNV7qPykX2cmzGNyGHvAOAdUJGM5FMA1PB055f0LH6PPcB9xas7\nZmiwhx0e6OdGLT0xwLNAjzyva9OeKfBpIYQQQtwV2kWGEelnX2Nne5P2pHr7kn7iTxK3bwPAL6we\nGKyhh4fBQCNvD47Fn8iXV1i4fcsLnfYaBW68OGE5HcsSQgghxL+Um8FAz0ol+Xj/KdLN1lBlS8tH\nabtsDpfXriagYSOMRnf8w+4n6eIOAMqa3FgQe5DHK3dyyMszz6rMRdnSI4QQQgjhEi+TG40jgm3n\nF0pEcqJiVTJjzpD253EA/EPr2a4HGw3kZCXky8fXzx7q+OtYPwl6hBBCCKGbZiWLUdLHPuX8t/pN\nyXYzcX7W/7CYzZg8gzB5FQesqzVX93AnOTPFIQ83N3t44qbjQGYJeoQQQgihqyfKR9iOU/wD2dzy\nUTIvnOfKhnUA+IXUsl1v5O3BmeSzDs/n3X8rQ8flASXoEUIIIYSuint70KJUMdv5mbKViC6nuLxi\nGdlJifgGV3O4/9SV4w7neYOeolyR2SmlVJkb3yWEEEKIu1XTEsUo4W0fm7OrQQvMaWnEb9qIm7uv\nw72nY/c6nHt4mjAard1aRgy6tdDcbD6aTuULIYQQ4l/IYDDQqVxx23lyQBDHVQ0uL18KgMXD3hJU\nmrR8z+fk2Lu19FqV+WaDHtl0VAghhBDXFennTdk8a/fsqdeUHIOB9NOn8PQItKVXcjcRn5F/FtdV\nbgVeKRwZ0yOEEEKIv033iiVsx2m+fvzUvDPnZ36Bb/A99nSLhV/P73F4zsPTHurc7pae93UqXwgh\nhBD/Yv7uJhqHB9nOo8tVJuNsDG7pAba0YDcj55MvODzn6aX/AoU3FfRomvaBTuULIYQQ4l+uaUn7\n+J0cNxMnKlUjZvRYcgz21hxL2jmHZ3LMem5AYSXdW0IIIYT4W3mb3FCBPrbzAzUegJwcjCb7Hlu+\nWZccnomsEGI79tJpKLEEPUIIIYT427UqHWo7vhIazoVixTFZ7Cs3exsMZJmznD57u6esCyGEEEK4\nrISPJ1H+3rbz3Q80x3jKPkS5hMnIocv2FXH8A+wBkb2N6NZI0COEEEKIIlG9mL0762KJSOJj0m3n\noW5uxKbG2c7NZvs6PRk6lX/LQY9SKlWPigghhBDi361uaKDD+Ta/CLIt9vE6R87tsB0HFrO3Ct1J\n3VuyUKEQQgghbshkNNCwuD3wuVCiLMY8LTr13M2246vbUOha/vUuKqWGu5CHXgslCiGEEOJfrnmp\nELZftK6+nBwQxNm/fCgdZe00KmG0T1PPG/ToFf7caJHDt4ErQOZ17pGgRwghhBAu8Ta5ofy90JKs\n43miU8MpzUnb9bTsdLxNXg5Bj17dWzcKej4ElKZpTxZ0g4zpEUIIIURhlPb3sQU9+9UDNMwT9JyM\nO8C9EXVxM9lDnaIa0zMKqKyUevY698iYHiGEEEK4rF6Y44DmTIu9DcacfAIAd3d7R5JegcZ1gx5N\n07KB1sCv17lN9uESQgghhMsCPBw7mnan3ms79kk+DoDRzR6i/O1Bj1LKF0DTtFhN044UdF/efbiu\nPiOEEEIIcT11Q+0bju73rIoldxKXuyUb+HsGMl+vpec3pVRNVzNSStUAdt96lYQQQgjxb9emTKjD\n+TnCbMc55kyHoMe3CPbeGgNsU0p9pZSqU9BNSqnaSqnZwDbgE11qJYQQQoh/NR+T4+TvozlRtuP0\npJPX3q6LAmdvaZr2pVJqD/ARsEspdRk4AFxdIzoUqAoUAzYAjTVN+/1vqaUQQggh/nXqBXixK9E6\ni+uCOcS2CI45KwF3j0jbfRlYnD1eaNedsp4bxLRVSlUFWgE1wdb+dApYBqzRNO2QLrURQgghxF2j\nakQxdiWeBeCKMciWnhz3GwFl7CNsimqdHgA0TTsIHNSpTCGEEEIIyvp5O5ybLQbcDBYs8LcsTii7\nrAshhBDitvB0cwxDoi0lATBnp+KW55pbEQxkFkIIIYT4W1UO9LEdH7JUBMCSnYLBkK57WRL0CCGE\nEOK2CcyzUOFfuS09ADmZl3Uvy6UxPXpRSvkAY4G2WGd9HQKGa5q2voD7A3Lv7wp4AvuAVzRN21M0\nNRZCCCHE3+mhiGB2xSbazi0WMBggNeEIBoOHbdFCPbgc9CilggEF+Fx7TdO0TS5mMxmojXVri2jg\nOWC5Uqqmpmmak/vnY12IsSaQBAwFRiul2mmaluPkfiGEEEL8gxTzdHc4T8ULX9JJjT+CxVJD17Jc\nCnqUUj2Bz7G2tlw7msiCbWb9dfMIBp4BntA07Whu8nSl1EvAS8Dga+6/H2gOlNM0LSY3+W1X6iuE\nEEKIfwaDwTGsSMYXX9Ixufvj7u1OVlqWbmW52tIzAms30zwg9SbLqgO4k3/z0l+BB5zc3ww4CTyq\nlBoCBALbgYGapv15k3UQQgghxB3G1+RGSrYZgHOWMMINl8jOSnSYtq4HV4OeEOBdTdNupWft6qKG\n145MigOKO7m/DFAaqAbUAvyAL4EVSqkamqZdN/QLC/O/haqKv4N8J3cW+T7uPPKd3Fnk+yg63u72\noCfFYl27x5yZgLu7Gxk6luNq0LMDuJe/b4FCZ8GUAWv9Bmqalg7EK6UGYd0K4wHg5+tlGBubpHsl\nxc0LC/OX7+QOIt/HnUe+kzuLfB9Fq4KfN3FpmQAkYg82M9PTdC3H1aBnLDBTKfUl8CfgMIjYxYHM\nF3J/hgAxedJDgfNO7j8LpOYGPFdd7dYq7UqlhRBCCHHnKx/gzc7YBABOW0rZ0r08M8hM99StHFeD\nnjW5P+s7uebSQGbgNyADayvNwjzpjYDlTu7fDwQqpSppmnYsN61i7s+/Z/tVIYQQQhS5SgGOE8Nz\nLAaMBgv+wUYSE/Qrx9WgJ+rGt1yfpmkJSqlZwEil1B/AGaAfUA6YppQqBWwEemmatgNYhXUdn+lK\nqe6AGRgP7AZ23mp9hBBCCHFn8DI5tp0k40MAKZCdAgQ5f+gmuLQis6ZppzVNO4115lYEEA4k5kl3\n1WCsgc1W4BLWRQdb5+bhjnUdIN/cMrOANkAicBQ4AVwBOtzigGohhBBC3GEivD1sx6lYBzMHh+pb\nhqvr9AQDc7CupAzWQcZmpdQCrC0zLm2QoWlaBjAw93XttVNcswaQpml/AZ1dyVsIIYQQ/1zFPN05\nnzuYOcYSToQhjmC/MxR5Sw8wASgJPA5UxTqN/JncnyN1q40QQggh7kohXvaVmZMsvgAYDfpuvuDq\nmJ62QL1rurIOKaX2Yh1784autRJCCCHEXcXDaG+Hyc6dH+XnE69rGa629HjhOM38qj+xLzoohBBC\nCHFTSvt62Y6PW8oBYLHouyKzq0HPUaCLk/THsQ4wFkIIIYS4aXm7twAyLSYMBn3nLbnavTUamK+U\n6oF1VWYDUANoBfTStUZCCCGEuOuEXLPb+glLJFUMJzAYLLq1+Lg6ZX0R1h3PM7BOI+8EZGGdPj5H\nl5oIIYQQ4q517W7r0ZYSAPj63Ow+5/m52tKDpmlbgC26lSyEEEIIkUerUiGsi7kEQE5uu4yvbxrJ\nKb665F9g0KOUekfTtFG5x+9dLxNN04brUhshhBBC3LXC8yxQeHW3dZObWbf8r9fS8zQwKvf4WZzv\nhE5uugQ9QgghhLgl4d72zUVjCcFiAbeiCHo0TauS57icbiUKIYQQQjgR5OkYlqTgjbt7tm75uzSQ\nOXcRQmfpQUqpM7rVRgghhBB3LeM1g5kvWkLw8XFppyuXXHcgs1LqPqA2cK9SqhfX7I0FVAaCdauN\nEEIIIe5qHpkxZHqUAqwtPcU9LumW941mb5UC+mHdAX2mk+upWPflEkIIIYS4ZT7evmTmDuOJtYQQ\nmnNFt7yvG/RomrYSWKmU+kvTtDK6lSqEEEII4USot4H4ZOtxJu4EByfolrerixOWUUqVV0qVupqm\nlKqulKqgW02EEEIIcdfzc7fP4MrBQFKSPmv0gOsDmZsDB4DGeZIfBP5QSrXQrTZCCCGEuKsFedg7\noS5bAgkL1W+ndVc3HB0NDNE07furCZqmfQ68BHyoW22EEEIIcVcL9LS37KTjRVqax3XuLhxXg557\ngBlO0r8FqjhJF0IIIYQotFDvANuxN+l4e2fqlrerQc9FoKaT9IaAfsOqhRBCCHFXK+ntZztOxUvX\nvF3dcPRzYLVSag5wEmuwVAXrVhXv6FojIYQQQty1vExuYMkBgxEzJrIsbrptReFS0KNp2nilVBLQ\nF6gEmIGjwGBN02brUhMhhBBC3PUMBgPuWalkeVhbfJLwLdqgB0DTtC+AL3QpVQghhBCiAFcDHoBk\niy9GQ0F7nheOq2N6UEqVU0qNVEp9mSetkS61EEIIIYTI5WlOtR1n4o7BmKNLvq6u09MW0ID2wFO5\naeWA9UqpR3WpiRBCCCEEYMQ+YyvOEqzbTuuutvSMAgZqmlYXsABomnYK60Dmt3SpiRBCCCEE4Otl\nX5snGZ8i7966B/uGo3lLXop1YLMQQgghhC5M1wxcNpmKtqXnEhDoJD0K0G/VICGEEELc9cr42tfn\nuWwJwmQq2tlbPwL/U0q9BqCUCgBqA+OAVbrURAghhBACcDe62479DCkYjUXbvTUYKIZ1bR4vrKsw\nb8S6UvNgXWoihBBCCAEU9/a2HWdYPDAY9Jm95erihJeBh5RSNQEFpAFHNU3TdKmFEEIIIUSuIE9v\nrKEGZOKhW0tPgUGPUsqgaZol9/hqi9AfuS+uSbdcvVcIIYQQ4lb4u9vH9CThg59v6nXudt31urdS\n8hxnA1nXeWUrpa4opYboUishhBBC3LW8TfYp69m4k5HhcZ27XXe97q0X8xw/j+NUdWeqAMOB8bda\nKSGEEELcvXxMbg7nhr+7e0vTtG/yHM92JTOlVG0d6iSEEEKIu5iHm2NHlMVk0CXfwuy99YxSaotS\n6kTuuYdS6s2892ia1lqXWgkhhBBC5HIL0medHlf33noNmATsAkrkJocCvZVSb+tSEyGEEEKIXD7Z\nCbZjs8XtOne6ztWWnpeADpqmvYZ9762zQBegpy41EUIIIYTI5ZFnp/Vsd1fXUr4+V4OeEsB2J+kH\ngJK61EQIIYQQIleGyd92nJVdtEHPX1g3Hb1WEyBWl5oIIYQQQuRyz0m3HVv0Gcfs8t5bc4GlSqkx\ngFEp9QjWvbcGAJP1qYoQQgghhJXBnADuoQBYjC7Pu7ouV4Oe93Pv/QjwAJYAF4BPcl9CCCGEELrx\ndM+zQKGvPt1bruZi0TRtuFLqXSAMSNM0LUmXGgghhBBCXCPbaN90NDHbV5c8XQ16EgH/3P21LupS\nshBCCCFEAdyNWba9IDxNWbrk6Won2TalVGddShRCCCGEuIHsHHuH0oWcUF3ydLWl5xgwTSn1FvAn\nkJn3oqZpz+pSGyGEEEIIwN/bi0u5E7jcyNYlT1eDnmrA4dzjcF1KFkIIIYQogG+eTUdjDUXY0qNp\nWlNdShNCCCGEcIF7nmnqwcTrkqc+E9+FEEIIIXTkkadZ5gpBuuQpQY8QQggh7jipWcm65ylBjxBC\nCCHuOKV8Q2zHJop2yroQQgghRJExudkHMufoFK4UOJBZKRXpaiaapkXrUhshhBBCCMBksAc6Obhd\n585C5Hmda6ewrYV4Q/rURgghhBACsJCje57XC3pa5jmuAAwG/gccxNotVgPoAYzSvVZCCCGEuKsF\negTonmeBQY+maRuvHiul3ga6aZq2P88tq5RS64FPge9cKUwp5QOMBdoCxYBDwHBN09a78Ox04EUg\nStO0U66UJ6Bx47q88cbbdOwou4gIIYT45zAZ3fDMSSXD6KVfni7eVxf7isx57QdqF6K8ybn3twai\ngeeA5UqpmpqmaQU9pJRqCXQrRDn/egMGvMj+/fswmZx/hcuWrcPPz0/XMi9evMCvv/5Chw6ddM33\nVnz99SxmzPic7t2fpV+/VxyurVq1nNGjR7J58y/5Pqc9e3bzyisv8d13iyldugwAmZmZLFjwHRs2\nrOWvv6IxGIyUKFGS5s1b8tRTPXB3d9et3unp6UyePIGdO7eTmJhAuXLl6d27D/XqPVDgM9u2/czX\nX8/i1KkTeHh40rp1O156aYDtvUVHn+Lzzydy4MAfZGdnERlZjueee4FGjR4EICMjndmzZ7Jp03ou\nXYqjZMlSvPTSyzRs2NhWxooVS5g/fx5nz8ZgMpmoX78B/foNJCIiQrf3LoQQrjAYjBhdHmXjGleH\nQ/8FvKyUMlyT/hIQ40oGSqlg4BlghKZpRzVNS9c0bTrWYOql6zznj7Vb7T0X63rXaNGiNZs2bXf6\n0jvgAfjppx9ZuXKZ7vneLLPZzJIlC2nduh2rVi0jMzPzxg8VIDMzk4ED+7J69Qr69x/E6tU/smzZ\nWl56qT8rVixl0KB+mM1m3eo+fvwYDhzYz7hxk1i2bB1t23bgjTeGEB19yun9Bw78wbBhr9GiRWuW\nL1/P1Kkz2bv3N774YioAOTk5DBnyMp6ensydu4Bly9bRrFkL3nprqC3PSZMmsHbtKkaN+ohdu3bx\nwgt9GD78v/z553EANm5cx2efjWfAgMGsXbuFr776jtjYC4wYMUy39y2EEK7yd/fFoPO4HleDnuHA\nGOCCUmq3UupXpdQ5YAIw0sU86gDuwK/XpP8KFPzPWxgH7AQWuViOuI5Fi37g2We70aJFY7p0acfn\nn08kO9u+kduRI4cYMOBFWrZ8kEcfbc+MGZ9jNpuZNm0yEyeO58CB/TRr1pBDhw4wc+Z0XnihB9Om\nTaZVqybs2bMbgC1bNvH888/QsuVDtG/fnFGjhhMfb11C/Ny5szRuXJedO3cwaFA/WrZ8kK5dO9xU\nMLV160+kpCQzePDrAGzadMNe0gJ9//23HD16hHHjJlGnTj1MJhNeXl40aNCYceMmUapUaS5disv3\n3Pnz52jWrGGBr/Pnz+V7JjExkXXrVvP88y8SGVkWT09POnfuStmy5ViyZKHT+v300yZKlizF448/\niYeHB6VLl6FPn/4sWbKA7Oxs4uOvcP78Odq06UBAQCAeHh506fI42dnZHDt2FIDNmzfSpctjVK5c\nBQ8PD5o0aUbjxk1YvHgBAOHhEbz33mjq138ANzc3wsMjaNq0JcePH73pz1UIIW6Wl8kLo0XfoMfV\nvbcWKKV2A48DZQBPYBmwXNO0310sKyz35+Vr0uOA4s4eUEq1AjoDVQFfF8uxFhbmX5jb/3E8PEx4\neppcep/+/l6EhfmzYMECZs2azpQpU6hduzZHjx6lb9++hIQEMmDAAOLi4nj11Zfp3bs3X389m5iY\nGJ577jmCg/155503SUlJ4PTp08ybNw+A/ft3c+HCOTw8jOzc+Qvu7u7s2rWLd975L2PHjqVly5Zc\nuHCBl19+maFDh/LFF1+QkWH9GmfPnsH7779PpUqVmDRpEuPGfUSnTu0IDg52+TNYvnwhHTp0ICqq\nBJ07d2b58kX06PGkw/sG6+/Ctd1bQUE+ABQr5ktYmD8//rie9u3bU7VqxXzlhIVVpXbtsU7rEBbm\nzx9//OFynQGOHfuD7OxsGjeu7/D91a5dC0077PQ79fHxxGg0OFwrV64kKSkpJCfHoVQl6tSpw/r1\nK2ncuD7+/v58++1CgoODadnyYUJC/HFzM+Lt7W7LIyzMnxIlirN3717Cwvxp2rSRLe+cnByOHz/O\n2rUr6NKly7/+v6c7hXzOdxb5Pm4v30wTmQYPXfN0dUwPuYOHP9G1dLt8nXZKqQCs3VoDNE2LVUoV\nKuiJjU0qVAXW7Ixm6baTZGTq14XhKk8PNzo1iqLN/S4vjURmZjYrV65k7dq1+a61bt2ON95423ae\nlJRObGwSs2d/RceOXShbVnHpUgohIaV44onuzJ07h27dnmP+/EUYDAY6depGYmIm/v5hvPfeR5jN\nZmJjk0hPzyIry2z7bFNSMkhMTOSJJ54lISEDyGDmzC954IGG1K//EAkJGXh5BfH00z15++030LRT\nZGRkANCyZTtCQkpx+XIqDRs2ZerUqezde5Dq1Wu69P5PnTrJL7/8Qu/e/YiNTaJ583bMnj2brVt3\noVQV2/sG6+/C6jNLIgAAIABJREFUtUFPfHwqAJcvp+Djk8SpU6dp0aJtoX9vbsapU9Ye4awsN4fy\nPDx8uHgx1mkd6tZtxKxZs5g8eRqdOnUlISGeiRMnAXDyZAxBQRGMGPEhr776Cg0aNMBgMBAYGMR7\n731ITo4HsbFJPPhgU779di5Vq9aiQYM6bNz4M2vWrMVkMjmUuWbNSj780Nqb3LlzV156aVCRfC53\nu7Awf/mc7yDyfdx+GeZMMo2euubpUtCjlAoFXsc6Td3n2uuapj3kQjYXcn+G4DgOKBQ47+T+ccCv\nmqbNd6WOt2rtrujbEvAAZGSaWbsrulBBD1jH9Awf7vqKAadPn+bEiT/5/vtvbWkWiwWLxUJWVhZn\nzkQTHl4CY56dbatVq3HdPAMCAh3GD505c4b69R17K8uVKw/A2bMxhISEAtgGDwN4eVlbZNLT011+\nL4sWzadixcpUqXIvAFFR5alevQaLFs3nzTeHu5zPVQYDug5UvlkGw7XD5qyqVavOu+9+wNdfz2Lm\nzBlERpalZ88X2LLlR0wmE1lZWbz66suULRvFJ59MwNvbmzVrVvHGG0OYMWM2UVHl6d9/IG5uRoYN\nG0pWVib16j1Ax46dWbdujUNZbdq0p1Wrtpw8eYKxYz/kzTdf4+OPPy2Kty+EEDZGg5FQcxxxbqG6\n5elqS89XWGdd/QTkH6Tgmt+ADKzjd/IOXGgELHdyf28gUSl1dSDF1b/Ee5RSH2ma9vFN1sOp1vUi\nb2tLT+t6hQt4bqocT0969uxHt25PO71uNLphKWT/6bWBQmZmBtc23OXkXM3T/ge9oD/urkhNTWHN\nmlVkZWXSps3DecrO5NixowwYMBh/f39MJmvd0tPT8w3sTk62bmTn6Wn9V0TZsuU4cuRgoety/vw5\nunfvWuD1uXMXEhFRwiGtWDHrfjKJiQmEhdl7dhMS4m3XnGnevCXNm9uXzzpx4k8AIiJK8Ntvuzh6\nVGPcuEkEBxcD4NFHH2fp0oWsWrWc/v0H4u3tzeDBrzN48Ou2f8VOmfKZ05lZRqORChUqMnjwUJ5/\n/hmOHz9GxYqVXPhEhBBCH24GI8mGQnXy3JCrQc+DwL2app252YI0TUtQSs0CRiql/gDOAP2AcsA0\npVQpYCPQS9O0HVjHDuVVGtgBtMO6vo+u2twfWeiWln+aMmUiOXrUcWWAK1cu4+nphY+PD2XKRLJm\nzQqysrJswcyePbuJi4ulVau2Lpdx/Phxh7STJ//EaDRSpkwZUlNTb/l9rF69Eoslhy+/nGsLWsA6\nm6t372dZtWoZ3bo9TVSUtYXpyJFD1K1b3yGPfft+o1ixEFvLU8uWbZk2bRLPPfcCkZHlHO69ePEC\nr7zSl5EjR9u6zq6KiCjBpk3bC1V/pe7Bw8ODgwf/4OGHm9vS//jjdxo1ct5oGhcXyy+/bKd9+0ds\nAeOOHVspXTqSsLDitsHKZrNj0Go2m21B5/79+8jKyqJOnXq26zt2bKNVqzYAjBo1HB8fX1599Q3b\n9cxM6yZ/bm6y6LoQomgZMBCecZbT3hV0y9PV2VtXsA44vlWDsQY2W4FLQFegtaZpp7HO7FLkDljW\nNO1M3hf2LrDzmqYl6lCXu84TTzzFpk3r2bRpA9nZ2cTEnGHo0EFMmjQegJYtrX/8Zs2aQVpaGjEx\nZ/jww1GcPWvtjfTy8iYuLpbExAQyMpx3RXXu/Bi7dv3CunVryM7OJjr6NLNn/49WrVoRGBjkUj23\nbPmR7t27FjhFfPHiH2jRog3lykVRokRJ26t06TK0adOexYsXYrFYqFSpMu3adWTs2A/Zt28P2dnZ\nJCUl8cMP37Fw4Xz69n3Z1pX3+ONPUqPGfbz8ch82b95IZmYmGRnp7NixlQEDXiQqKopKlSoX6vMu\niJ+fH+3aPcLMmdOJjj5Neno6c+fO4fz5c3TubG01io29SPfuXTlwwLoeqNlsZty4j/jhh3mYzWb2\n79/HnDmzee655wGoXr0mxYqFMHXqRBIS4snIyGDZssVER5+madMWgDWoGjHiLU6ePEFmZiZffDGV\n+PgrdOr0KAB16tRj5cql/PTTZrKzs4mNvcgXX0ylQoVKREaW1eW9CyGEqwwGA/Hurk9ucYWrLT1j\ngTeBd2+lME3TMoCBua9rr50ib/9HIa/fjTZsWMvmzRudXnv99bdo06a9Q1qLFq25cuUKM2ZM4f33\nhxMUFMxDDz1M374vAxAQEMDkyV/w8ccfMH/+XAIDg2jduh3PPNMTsA6Q/umnTXTp0o4RIz5wWm6D\nBo0YNuxd5s79mk8+GU1QUDBNmjTlv/99jeTkbKfPXCslJZno6NNOu8B++20Xp06d5N1333f6bOfO\nXVmw4Dt27dpJ/foPMHToMBYtms/48WM4d+4cXl5eVKhQkfHjJzu0eJhMJsaPn8yCBd/z1Vczef/9\ndzGZ3ClTpgzdu/fgkUcedRjrdKteeWUIn38+kX79epOamkqlSpUZN26SrSvsasCYlpYGXJ1O/iHT\np09h2rQphIaG8tJL/WnbtgMA/v7+jB8/menTJ/PMM0+QkpJMZGQ5Ro/+hGrVqgPQrdvTxMZe5OWX\nXyQjI4MqVe5l4sSptmC0XbuO5OTkMG3aJEaMGIa/fwC1atVh2LDh0tIjhLgtIiwXSaCYbvkZLJYb\nr3aolPoOaAZkASfBcbUgFwcyFyWLjLq/sxR2JsRLLz3PtGmz/sYa3d1kZsqdR76TO4t8H3eGmVuW\n8KdPVQC+aFf7lhs+XG3pSQNW3mphQrji+PFjhIeH3+5qCCGEuM0MLjTMFIarixP20rVUIa6jYsVK\njBz54e2uhhBCiNvMmHMbVmRWSj17veuapn2tT3WEEEIIIawsOo/kdbV7a3YB6ZlAAiBBjxBCCCF0\nlWTSd50eV6ejuF/z8gKqA4uBbrrWSAghhBACCDIn6Jqfq2N6rl0wxQwcVEq9DPyINQASQgghhNCN\nh86rZdzqwiOpQHk9KiKEEEIIkVeGzjtDuTqQ+XknyT5AJ+CErjUSQgghhAAysl3fiNoVrg5k/p+T\ntHTgCNBXv+oIIYQQQlh5uXne+KZCcHVMj37r7wshhBBCuMBgctc1v0IFM0qpukqpbkqpx5VSNXSt\nifjbrFq1nCZN7r/d1RBCCCEKxZCt76AeV8f0RGLdhqJqnmSLUmon0F7TtCu61kq45NKlOObO/Zpt\n27YSF3cRk8md8PAImjZtTvfuz+Lh4VFkddm27WdCQ8NQqkqhnx0z5gOWL1/Mq6/+ly5dHnO4NnPm\ndFasWMrixavyPbdq1XJGjx7J5s2/YDJZf5WTk5OZN28OW7Zs4vz5c7mbhkbStm0HunR5zOkmpjcr\nPj6eCRM+4fff95KWlkblyop+/QZSpco9BT6zatVy5s+fR0zMX/j7B/Doo4/bNnQFaNy4LiaTKd/m\npmvWbMbDw4NmzRrmy9NsNlO8eDg//LAMgBUrljB//jzOno3BZDJRv34D+vUbSEREhD5vXAghiogR\n1zaqdpWrY3omAGeB54BDWFuIqgMfAmOAF3WtlbihmJgz9O37AjVq1GT06E+IiipPRkYGe/fuZsKE\nseze/SuffTa1yHbHnjlzOl26PFbooCcpKYn161fTunU7lixZkC/oKYyEhHj69n2B4OBivPXWCJS6\nh7S0VHbs2MaECZ+wf/++AneHvxnDh/8Xo9HI9Olf4ufnz7fffsWrrw5g7tyFtp3L89q0aQNjxrzP\niBEf8OCDD3PixHHeeusN/Pz86NzZ/r7Hj59M7dp1nZa5adN2h/OcnBz69/8P9es/AMDGjev47LPx\nfPDBx9SpU4+4uFhGjBjGiBHDZANXIcQ/TqY5Q9f8XA16HgYqa5oWlydtp1KqB7Dd+SPi7zR27IeE\nh4czatQYW+uFl5cXDRo0JjKyHFu2/Eh6ehq+vn62Z/7443fGjRtDdPQpIiJKMGzYu1SrZu2lTEiI\nZ8qUz9i9+1fi4+MpUyaSnj1foGnTFgCcPRvDhAljOXhwP5mZmZQuXYZevV7koYcepkuXdsTGXmTs\n2A9ZsOB7vvpqnsvvY9WqZYSGFmfAgEF07tyW33/fS82atW7qM5k+fQopKcnMnPkN3t7eAPj6+tGi\nRWvCwsLZsGEtKSnJDp8JwL59exgyZECB+V4baACcOHGcPXt28+WX31K8uHVz1F69/sPSpQtZu3Y1\nTzzxVL5nfvxxA3Xq1LN9ppUrV+GZZ57jhx/mOQQ9hfHDD/NIS0ujRw/r9njh4RG8995oWxBkbflr\nyYwZU24qfyGEuJ283Lx0zc/VoMcAJDlJvwgE6Fed22dD9BZWnVxPhjmzyMv2dPOgXVRLWkQ2cen+\n+Ph4du/+lXfeGeW0u6ZUqdJ0797DIc1isbB8+RI+/XQyHh4eDBv2OuPHf8ysWd8A8PbbbwAwdepM\ngoOLsWLFUoYPf5OpU8OpVq06Y8d+REhICAsXrsRkMrFx4zpGjRrOwoXLWbx4FY0b1+W1196kY8fO\nLr9vi8XC4sULaN++E8HBxWjU6CEWLZp/U0FPTk4Omzatp1u3p20BT141a95HzZr3OX32vvtqOw1s\nrufgwQO4u7tTsWJlW5rJZKJy5SocPPgHkD/oMRgM5FyzeV5QUBCnTp0kNTUVHx8fABYs+J4xY94n\nISGeqKgKvPTSy07rfulSHP/73zTGj59s6967GsSC9TM5deoEK1cuo02bDoV6f0IIcSdwM+g7j8rV\n3A7ifGr6QKzT1v/xNkX/dFsCHoAMcyabon9y+f6YmDNYLBYiI8u6/ExOTg5PP/0cwcHF8PX148EH\nH+LUKesSSydOHGfv3t/o338g4eEReHh48OijjxMVVZ41a1YCkJychJubG+7u7phMJlq3bse6dVsI\nCAgs3JvNY+fOHZw7d5Z27ax/kDt27MSWLT9y6VLcDZ7MLz7+CsnJyZQrF3XT9Slsef7+AfmCzsDA\nIOLjnQ9xa9KkGXv27GbDhrVkZmYSHX2K+fOtrWKJidal1pW6B6WqMGvWN3z//RIqVKjEkCH9OXfu\nbL78vvzyC2rVqkv16jXzXVuzZiVNmzagV6+nue++WgwePPRW37IQQhQ5HYdhAq4HPcOAj5VS+5VS\n85RS3ymlDgIfACP1rdLt0SzyITzdim7gb16ebh40i3zI5fuv/hKYzY6j2p977imaNWtIs2YNadLk\nfr788guH6yVLlrKX6elFZqY1yDtz5gwAUVGOi2uXK1ees2et1/7zn75s2/YznTu3ZcSIt1i7dhVZ\nWVku19mZRYvm07BhY0JCQgG4//6GFCsWwvLlSwqd19Xgw91d3+mNN8f5f6XNm7dk4MBXmTVrBh06\ntOTjj0fzyCNdAGwtNTNnzuG5517A19ePwMAgBg16DR8fX9audRzIHRcXx/LlS3j2WWfrhkKbNu35\n8ccdzJr1LUeParz55ms6vj8hhCgaOsc8Lq/T85NS6l6gD1AR64ajG4AnNU37Q+c63RYtIpu43L10\nu0VGlsPNzY2TJ49TtWo1W3resTQDBryYryuloJlLmZnWgWIWi2O69XnrM/Xq3c/ChSvYu/c3du3a\nybRpk/n661nMmDE73xgZV8TEnOGXX7ZjMrnTps3DtvT09HSWLVtMjx69bC1LaWlpTvNITk7CZDJh\nMpkICgomMDCQw4cP0bhx4b7HmxnTExxcjKSkRCwWi8PnmpAQT0hISIF5de3aja5d7Xv0bt++FQ8P\nT4KCgp3ebzKZiIiIIDb24jV1WkdYWHGqVSt42zuj0UiFChUZPHgozz//DMePH6NixUoF3i+EEHea\nTMNtmL2llOqhadocQNrI7wB+fn40bvwQ33zzNa1bt3faumG5NoK5jjJlrN1kx48fc/gjeurUCerW\nta7vc+XKFYKDg7n//gbcf38DevXqTefObdm9+1eaNGlW6PewZMlCwsKKM3nyDIf0hIQE+vTpydat\nP9GkSVOiosqTnJxETMwZSpUq7XDv3r17qFTJOqbGYDDQokVrFi6czxNPPJVv9tTRo0d4553/MmnS\ndNvA46tuZkxP9eo1ycrKQtOO2KaoZ2VlcfjwIfr06e/0mTNn/uLw4YO0bNnGlrZ9+1Zq1rwPk8mE\nph1h9eoVvPLKENuU9aysLM6ejaFp05YOeW3atMFpcDdq1HB8fHx59dU3bGmZmdYWuaKaySeEEHrx\nNfnomp+r3VsTlVL5R4eK22bw4Ncxm7N59dWXOXToAGazmezsbDTtCB9++B6HDx+kSpV7XcpLqSrc\nc09VPv/8M+Li4sjIyOC7777hr7+iad/+EdLS0njqqS7Mm/cN6enp5OTkcOjQQTIzMylTJhKwzhz7\n66/TJCYmArBw4fcMGOB8JYOMjHRWrlxGp06PUqJESYdXlSr30KBBIxYt+gGAhg0fpG7d+owYMQxN\nO4LZbObKlcvMmPE527f/zIsv2gOM3r37EhYWRp8+z7N7969kZ2eTmprK+vVrGDJkAA880DBfwHOz\nypYtxwMPNGTKlAnExl4kJSWZqVMn4unpScuWrQE4dOgA3bt35fz584A1oBs1ajibN28kJyeHn3/e\nzKpVy20zr4KDg1m1ajlTpnxGamoKiYmJfPrpx1gs0K5dR1vZ1u/5MJUrq3z1qlOnHitXLuWnnzaT\nnZ1NbOxFvvhiKhUqVCrUGDAhhLgj6DyQ2dXZW29hDXw+xbrBqMOIX03Tcpw+Jf42oaFhzJw5h2+/\n/ZoPPhjBhQvnMRrdCA8Pp169+5kzZ36+lpHr+eijcXz22Th69+5Beno65ctXYOLE6baWlDFjPmXa\ntEnMmjUDg8FAqVKlePvtkZQvXxGAxx57kvnz57F27WqWLl1DfHw8Z8/GOC1r/fq1pKWlFjjTq3Pn\nxxg6dCDR0aeIjCzH6NGfMG/eN4wYMYzY2Iv4+flzzz33Mn36bIeFAP39/Zk+/Uvmzp3DhAmfcO7c\nWTw9vShfvgKDB79O8+atXP48XPHuux8wYcIn9OjRjezsLKpVq8Gnn06xdfelp6cTHX2a7GxrS0vV\nqtUYOnQYU6ZM5L33hlOqVCnefXeUbU2e4sXDGT9+MjNmTKFr145kZ2dRo0Ytpk6dSVCQveUqISGe\nrKwsgoPzd4m1a9eRnJwcpk2bxIgRw/D3D6BWrToMGzZcWnqEEP84xhznwxtulsGVbhClVCzgnfvK\nR9O0O+3/ppbYWGcz7EVRsVgs9OvXm6lTZwIQFuaPfCd3Dvk+7jzyndxZ5Pu4M6z7ZQmb3aybQXzR\nrvYtj2t2taVHpn6IQtm27WeqV5ft2YQQQtw8Y+G2CL0hV2dvfaVrqeJfr3Hjh2jc2PVp+EIIIcS1\nDLg+KccVrs7eut6mPTnAX8AyTdP26lIrIYQQQtz1jDqvTuhq91Zx4H7ABzgMWIB7gGTgONAceFsp\n9aSmaQt1raEQQggh7k46Bz2udpatAtYAJTVNq6tpWj2gdG7aVE3TooCXgbd1rZ0QQggh7lpuOndv\nuRr0/Bfoq2lawtUETdPisQY6I3KTZgIVdK2dEEIIIe5et6mlJwQIdZIehLXFByACSNejUkIIIYQQ\neu++5eqYno3AWqXUFOyLE5YH+gM7lFKewDpgha61E0IIIcRd7PYEPc8DY4HRWAczgzXwWQ68qmla\nhlJqPdbd2IUQQgghbpnBAHoO63E16LmkaVpPoKdSqhjWbrFLmqZZlFJBAJqmvaJftYQQQghxtzMY\n3G5L0PO9UuopTdPMmqZdvpqolHoAmAdE6Vcl4YoBA16kePFwhg8fZUtLTExg4MC+hISE8sEHn+Dp\n6Xkba+jc4MH92bVrJ5988hkNGjRyuPbBByM4c+Yv29YVec2cOZ0VK5ayePEqW1pcXBzffvsV27f/\nTFxcLF5eXkRFVaBz5660aNFa13rHxJxh4sRxHDp0EIvFwr33VmPgwFcL3N8sJyeH77+fy8qVSzl/\n/hyhoWH06NGL9u0fsd1z9OgRpk6dxJEjh3FzM1K9ek0GDBhMqVKlOX/+HN27d82Xr9lspkaN+5g0\naToA33//LUuXLuLixQsEBATSsGFj+vQZgL+/v67vXwghbgd9O7dcH8hcDliulPK6mqCUegP4Cet0\ndnGbJSYmMGhQP8LCijN69Ng7MuCJjj7Fnj27admyDYsXL7ilvGJizvD8809z/vw5PvpoPBs2bGXe\nvEU0b96KDz98j2nTJutUa+uu5kOHDsTPz585c+Yzb94igoKCeO21V8jOznb6zLx5c/jyyy8YMuQN\n1qzZzOuvv8WUKZ+xY8c2wBqwDRzYj8qVq7B48SrmzPmBjIwM3n77dQAiIkqwadN2h9eqVZuIiChh\n23F9xYolzJjxOa+99iZr127hs8+msm/fXj77bKxu710IIW4nw21anPBhYCGwXinVC5gE1Ae6aZq2\nWNcaiUJLTExk0KD+hIUV5/33P8bd3d12LTr6FJMmfcrhwwfJysqiYsXKvPLKqyhVBbD+Qf/mm9ms\nW7ea8+fPExwcTPv2j9CzZ2+MRiOrVi1n6tRJjBjxARMnjiMm5gxlykQydOgw7r23WqHquWjRAmrX\nrstTTz1D797Pcu7cWUqUKHlT73ncuI8oViyEDz74GKPRGrsHBATSpctjBAUFcfjwIcxmc76dxdes\nWcnHH3/gNM/w8AjmzVuUL33nzh22FqjAQOtu5wMGDKJjx1bs2LGVBx98ON8zmzdvpEWLVrYd1GvX\nrkunTo+ycOH3NGjQiLi4izz00MO8+GI/3Nzc8PLyonPnxxg27DUSExMJCAjIl+e0aZOJjCxL27Yd\nADhy5DDly1e0lVGmTCSNGj3I1q1bXPwUhRDiTncbpqxrmpYKdAD+BI4A/sB9EvDcfklJSQwZMoDw\n8Ag++OATh4AH4O233yAgIICFC1ewbNlaSpQoyVtvDbVd/+qrmSxduoi33x7JunVbGD58FN9//y3z\n5s2x3ZOcnMSyZYuYMOFzli9fT2BgEOPGjSlUPVNTU1mzZgXt2z9C5cpVqFixEkuW3Nzi3fHx8eza\ntZNu3brbAp68mjZtQb9+r+QLeADatGmfrwXl6stZwANw8OAflCxZ2hbwgDXAKlmyFAcPHiiglgYs\nFseO6MDAQI4cOQRAlSr38uabwx3qePbsGXx9ffH19c2X27FjR1m2bDFDhrxhS3vooaacPPknu3b9\nQnZ2NmfPxrB9+880a9aygDoJIcQ/jM79WwW29CilyjtJfg/wBCoDnlfv0TTthL7VKnqX167m0rKl\nWDKKfqkhg6cXIY90oljrtoV6Ljk5mSFD+nP8+FHee+9DTKb8X+e0abNwc3PD09PaM9m8eUvWrFnJ\npUtxhISEsmjRfJ5+uqet1aZmzVq0adOe1atX8PTTzwGQlZVFz57/ITi4GGD9Yztp0ngsFovLTY9L\nly7Fzc2Nhx5qCkCHDp2ZNWsGL7zQBw8Pj0K975iYM1gsFqKinP2K6i8+/orTlpegoCCuXLns5Al4\n+OFmzJ49k2bNWnLffbX588/jrFixjISEBKef259/HmfWrC/o3buP02Bt2rTJdOzYyaFlrH79B+jf\nfxBDhw7CbDZjsVho3rwlvXr95xbfsRBC3BkMRdjScxw45uTVDagFaHnu+ce7sm7tbQl4ACwZ6VxZ\nt7bQz+3YsZXatetRu3Y93nzzNVJSkvPd88cf+xk0qB9t2jxMs2YNefPN1wDIzMwkKSmJhISEfMFD\nuXLliYk545BWunQZ27GXlxdZWVmYzWaX6zp37lxatWpnC3BatWpLenoamzatdzmPq67GCyaT+/Vv\nLAIFBX3duj3Nk08+zccfj6Zjx5bMmjWDLl26YjKZ8j2ze/ev9O//H7p2fYInnuieL68jRw6xa9cv\n9OjRyyF948Z1zJjxOWPGfMqGDVuZM2c+Z86c4aOPRuXLQwgh/omKckxPU11LusMFt2p9W1t6glsV\nfrZR06Yt6Nv3ZVJSkunb9wXeeut1xo6daGvxiY4+zX//O4SuXbsxZsynBAQEsnPnDl599WUAMjMz\ncnNy7IbJycnJ94t2K794e/bs5ujRo0RHR7N69XJbelZWFosXL6BNm/aANYhJT09zmkdycrJtcHaZ\nMmUxGo0cOXKQihUrFaouNzOmp1ixEBITd+dLj4+Pp1atEKd5mUwmXnihDy+80MeWtnDhfMLDIxzu\nW7FiCZ99No6BA1+jQ4dOTvNau3Y1NWrcR2homEP699/PpXnzVtx/fwMAoqLK8+yzvXj77TcYNOg1\nfHzyd5MJIcQ/ilHfvbcKDHo0TXMYDamU8gdMmqZdyT0vC8Tn3Y/rn6xY67aF7l663a4GN76+fnz8\n8QRefLEnH374Hu+88x5gnRKdlZXFs8/2IiAgEIBDh+xjUIKDi+Hn58fx48dp0KCxLf3kyT8pU6as\nbvVctOgHatWqxbBhIx3ST5z4kzfeGMzRo0eoXLkKUVHlWb9+NSkpyfj6+tnus1gs/P77XipVUgD4\n+/vzwAONmDNnNq1bt883jmnbtp+ZMWMK06Z9ibe3t8O1Nm3a24IsV1WrVoOvv57FlSuXbV18ly9f\nIibmDDVr1nL6zLFjR7lw4RyNGzexpe3YsZVaterazteuXcXkyRMYO3ZigfkA/PjjBp566pl86Tk5\nOeTkOLa2ZWdbz68dTySEEP9ERdm9ZaOUqo11+4lWeZK7AseUUgX/31oUmYiIEnz00Tg2b97I9OlT\nAGxryOzfv4+MjAw2bdrAvn17ALhw4TxGo5FHHnmUH36Yx5EjhzGbzeze/Str166iU6dHXS572rTJ\njBz5ttNrsbEX+fnnzTz99NOUKFHS4dWo0YNUqFCJRYt+AKBjx86ULFmKd98dRnT0KXJycrhw4Txj\nxrzPX39F06tXb1u+gwcPJTMzk379XuDw4YPk5OSQmJjIokU/MGLEMFq3bp8v4LlZ9erdT1RUeSZM\nGEtCQjzx8fFMmDCW8uUrUrdufQC2bPmR7t272rr8/t/efUdHVbQBHP6lQyC0JHRCE4beRXoJXUCQ\nKih8oDTrZyY6AAAgAElEQVSlCtI7AkpRitIFBUEBqYZeVRAsSFPKoPQWTICEhISQ9v1xN2vKAruw\nJCF5n3P2xL135t65OyT7OvXKlcuMHz+KEyeOEx0dzaZN6zh27A86dXoTMD7/mTM/Zvz4KY8NePz9\n/QkMDDAHfPHVrevLvn27OXr0CFFRUVy/fo3Vq7+mWrUaCYJGIYR4YTlYu7KOdaydsj4TWAJsjnfs\nM4wtKWZhTGkXKaxUqTKMHTuJsWNHkDt3Hlq1akPXrm/z0UeTiI6OoU6dekyZMoNhwwbxwQcDmDFj\nDr16vQfA+PEjuXPnNnny5KV//8G89trrVt/39u1A/v33lsVzmzdvwMMjC02aNCE4OCLJ+ddfb8vn\nn8+mb99BeHh4MGfOApYvX8aQIQO5cyeQbNmyU758RZYtW0mBAj7mfHny5GXZspWsWPEl48ePIjAw\nkEyZMlGsmGLKlBlUrVrNxk/v0ZycnJg+fTazZk2nXbvXcHBwoEqVqsyYMds86Pj+/VCuXLlsbmFp\n0KARV69eZty4EYSEhFC0aFE++eQzfHwKAbB9+xbCw8MSzKSLM2zYaHNrVGBgAIC5hSm+uNafTz75\nGH//m2TIkIE6dXzp06ev3Z5dCCFSkqOdZ285WNMMrpQKAjy11tGJjjtjbEeR1b7FemaxAQEhKV2G\ndOPu3TtMnz6Fjz765JFpvL09kDpJPaQ+Uh+pk9RF6iN1OPTnbrY8KATAklcrPXMIZG27UQjGqsyJ\nlQQsjzwV6cbevbt4+WX7tawIIYQQABmdMzw5kQ2s7d5aAWxVSs0FLmEESyWA/sBiu5ZIvHDatXsj\npYsghBAiDXJIoTE9400/JwFxgwsCgfnARIs5hBBCCCGegaOTtWGKday6mtY6ChgNjFZKeQLRWusg\nAKVUbeCAXUslhBBCiHQvpTYcBUAplRPIYPrvLIAPxi7rHnYtlRBCCCGEnadvWRX0mNbiWQ9YWrHu\nZ7uWSAghhBCCFFqcEJgN/AS0BKKAZhhjefYDti1vK4QQQghhBUdH+w5ktvZq5YDeWuttGON5dmmt\nJwELMRYnFEIIIYSwq5Rq6Ynkv10pI5RS2Uz/7QdYv3SvEEIIIYSVHE2r3tvtelam+w1YrJTKAJwC\nRpoCn8ZA9GNzCiGEEEI8BXvP3rI26BkCVAKcgA+BgcBtYBNGF5cQQgghhF2lyOKEWmuNMa4HYKdS\nqixGEHRea33E2psppdwxNi9thrHI4WlgnNZ69yPS+2IEWWUwtrvYBQzRWgdYe8+0ql+/Xhw/fpSP\nP/6UWrXqPPL83LkLqVSpSgqU8PFu3fKnQ4dW5MjhyXfffY+zc8J/irVqVWH48DG0bNk6Sd527VrS\nuHEz82apAH/88Ttr1nzDqVMnCQ9/QLZs2ahc+WW6dOlm3uTTXnbv3sG3337N1atX8fT0pH79hvTo\n0ce8+ailZ120aB5Hjx4hNDSEMmXKMXjwcHx8jMmQUVFRLFu2mD17dnLnzm1y5PDE17cR77zTGxcX\nFwB+/vkAK1Ys49KlC7i6utGkyav06dPP/LndvXuHBQs+49dfDxMeHk6hQoXp1es98y7wQgjxIkqp\ngcyJxQJnbQl4TD4HagBNgFzAV4CfUkolTqiUKoexBtBqwAt4BSiLbHth5unpydat3yc5fv36Na5e\nvZwCJbLepk3rqVz5ZaKiojh48Mdnuta6dasZOnQQVapU5Ztv1rNnzwFmzZpHZGQk77zTlbNnz9ip\n1HDs2B9MmTKBt97qztate5gyZQa7dm1n+fKlFtNHR0czbNgg7ty5zRdfrOD773dRqlQZhgzpT0SE\nsev8l18uYcuWzUyZMp2dO39kypTpbNvmx4oVywD4668/GTXqAxo2bIKf324WLFjKsWN/sGTJAvN9\nRowYQmBgAMuWrcTPbxeVKlVh5Mgh5l3ahRDiReTsmMxjepRSA5RSc5RSr5jerwXOAUeVUoeUUjke\nfwXzdbIDbwETtNbntNYPtNaLgDNAHwtZ8gDztNafaa0jtdaXgeWAr3WPlvZVq1aTX375mbt37yQ4\nvmPHVmrUqJ3g2NKli3j99VcTHFu8eD7t2rU0v/f3v8moUUNp1aoJDRrUpHfv7hw9+l9c269fL+bN\nm8OiRfNo2bIxTZvWY/z4UUREPLCp3A8fPsTPbxNNm7agQYPGbNy4zqb88fn7+/P557Pp2fNdOnTo\nRNas2XB0dKRgwUJMmDCFFi1aERj4r8W877/fF1/fGhZfX331hcU869evoXr1mvj6NsTV1ZWiRV+i\nY8c3Wb9+DTExMUnSX7lymfPn/6FHjz54eXnj7u5Ojx59TMHeTwCcPXuGChUqUayYwsnJiWLFFBUr\nVuL06VMA/PTTPvLmzUf79m/g6upK/vwF6N27L5s2rSMqKorQ0FAKFSrMgAFD8PT0ws3NjTff/B/h\n4eGcOvXXU3+2QgiR8pJxcUKl1EhgLEaQ010pNQkoANQxlWSC6TXAintVBlwwBkXH9xuQZIturfVO\nYGeiw0WAq1bcy2bHf73KkZ8vEfkw+cdlu7g6UaVmISq8UsCmfDlz5qJcuYrs2LGNTp3eAiA2NpYd\nO7YycuQ4/Pw2WX2tqKgoBg3qi1KKFSvWkCFDBr76ailDhw5k1ap15M6dB4Dt2/3o0eNdNmzYyuXL\nl+jV639s2VKetm07Wn2vfft2ExUVRd269SlSpCjdunXi8uVLFCxYyKbnB/jhhz04OjrRtm0Hi+cH\nDhzyyLyzZs2z+X6nTv3F66+3S3CsVKnSBAcHc+3alSRdaXGD8OIHRI6OjmTJkoWzZ0/ToEEj6tf3\nZeHCeZw5c4rixUtw8eIFjh8/Ss+ecd13DsTGxia4btas2bh//z5XrlymSJGijBw5LsH5GzeuA5Ar\nVy6bn1EIIVILOw/peeKYnjeB17XWO5VS7TFaWl7RWv8JoJTqCezDuqDH2/TzTqLjgUDOJ2VWSjXA\naBGy6tvV29u2nTH+/ONaigQ8AJEPo/nzj2s0alHK6jyurs5kyuRG584dWbBgAQMGvAvAL7/8grOz\nE40b1wMgWzZ3vL09yJTJDUdHhwSfi7u7K05Ojnh7e7B//36uX7/K2rWr8fT0BGD48CH4+W3kl19+\npGfPnri6OlOgQAF69uwGQN68OVBKcf36Zas+77g0fn4baNXqNfLn9yJ/fi/Kli3Ljh2bGTNmTIL0\nHh4ZLF7XyckRd3dXvL09CAz0p2BBH/Ll87T6s3sWQUF3yZs3Z4JyFS6cD4DY2Igk5c2RozTFixdn\n+fIlTJs2jezZs7Nu3Tpu3LhORMR9vL096N69C0FBgfTq1c2cr3v37nTvbgSyrVo1Z/XqlWzdup6O\nHTsSFBTEmjUrAHBweJjknqGhoUyf/iENGjSgdu1XHvkstv6OiOdP6iR1kfpIefciMwOhdrvek4Ke\n/EDcIGM/wA1jyjoAWusLSilvSxltFPu4k0qpzsASYKDWeqM1FwwICLGpAGUr50/Rlp6ylfPbVOaH\nD6O4fz+CChWqcevWRPbvP0SZMmX59tu1NGnSnMBA4x9JUFAYAQEh3L8fQUxMbIJ7hIU9JDo6hoCA\nEE6fPke2bNmJiXFNkCZPnnycO3eegIAQHj6MIleuvAnOOzm5EBQU8sSye3t7EBAQwtmzZzhx4gSD\nBg0z52nW7DXmzZtN1669yJgxozlPSMgDi9eNjo4hLOwhAQEhPHgQhYODo831/SxCQxOW686d+wAE\nBYVbLMfkyTOYM2cmr73WigwZMtC0aXOqVq1GZKRRH9988zUbN25iwYJlFC+uOH/+b8aNG4WDgwvd\nu/ckX76ijB8/hRUrljFnzlx8fArSrds77Nq1i9DQhwnu6e9/k2HDBpEjhycjRkx45OcSVx8i9ZA6\nSV2kPlKHe8G2DZ94kicFPa5a6xgArfUDpVRE3Pt4rO1wu2X66Qlcj3fcC/B/VCal1HhgENDetCL0\nc1HhlQI2dy+lBm5ubjRp0oytW7+nSJGiHDjwAytWrLEqb/wul4iIh0m6UMDoLou/TsKzjqRfv94o\nW//+veOVI5awsPvs3LmN1q3bAuDs7Ex4eLjFa4SGhuLm5gZAwYKF2L7dj7CwMNzd3W0qy/vv9+XE\niWMWz3Xt+jbduvVIcjx79hwEBwcnOBYcHARgbiFLLG/efEyblnDh8h49ulK8eAkAVq9eSceOnSlT\npiwAJUuWpm3b9qxc+RXdu/cEoEGDRjRo0Mic/8KF8wDmbkeAM2dOMWzY+9St68ugQR8kmREnhBDp\nXXL+VfwDiMAYv7M+3vGaGK1ISSilRgO9gJpa69PPvYQvqBYtWtOvX09Kly5D6dJlyZUrd5I0bm5u\nPHiQMGK+du2/4VE+Pj4EBwcRGBiIl5cXYAw4vnbtKo0aNbFLOYODg9i7dzf9+79PnTr1E5xbtmwx\nGzeuMwc9hQsXwVKV//33OUJDQyhe3JjwV79+AxYsmMuqVcvp2fPdJOnHjx+Jj08h3nmnd5JzTzOm\np2zZckkGB588eRxPTy/y5ctvMc/+/XsoUuQl85ilwMBA/v5bm8cbxcREJxkEHR0dTUxMrCl9AL/8\ncojmzV8zB6CHDx8kf34fvL2NnuELF/5hyJABdOv2Dh06dLb5uYQQIjVySOYp665KqRVxr8TvTcdc\nrLmR1joYWAZMVEoVV0q5K6U+AAoBC5VS+ZRSZ5VS1QGUUpWBMUAzCXge76WXilGggA/Lly+lefPX\nLKYpWLAQISH3OHz4Z6Kjo/n55wP8+ecJ8/lq1WqSM2cuZs+eTkhICGFhYSxc+BmxsTE0aGB90NO5\nc1v2799j8Zyf3yZcXV1p1aotefLkTfBq3/4Nzp//mxMnjgPQr9/77N27mzVrVhESEkJUVBTHjx9l\n4sTRVK78MtWq1QTAy8ubgQM/YOXKr5g3bw63bwcSExPDlSuXGD9+FMeOHcXXt5HF8jyN9u0789tv\nh9m7dxcPHz7k7NnTrF69io4d3zQHJB9+OI758+eY82zd+j0zZkwlODiI4OAgPvpoEhUqVKJs2fIA\n1K3ry6ZN69H6LNHR0fzzz99s3ryBBg0aA0YA9MknH/Pdd98SHR3NyZPH+frrr/jf/942n588eQIt\nW7aWgEcIkaY42TnoeVJLz0GM2VpxDiR6H5fGWu8D0015PIDjQBOt9WWlVCFAAZlMad/FGEP0m4Vl\nfBprrX+y4b5pXosWrVm0aB61a9ezeL5mzTq0aNGKSZPGEhsbQ/36DXnjjbfM3U1ubm7MmvU5n302\ni06d2hAbG4NSpViwYKm55ccaV65c5v79+0mOx8TEsHnzBpo1a0GGDBmSnC9evASlSpVh48bvKF++\nApUrv8zs2fNZsWIZK1cu58GDB+TOnZtmzVrQrl3HBF1urVq1wcenIN9+u5KuXTvy4MEDPD29qF69\nJkuXfm1uDbGHMmXKMnHiVL74YiGTJ48ne/YctGvX0Tx7DozFCON3FY4YMY7p0yfTvn0rHB0dqVmz\nNgMHfmA+36/f+2TKlJlx40YQEBCAh0dmmjRpzttv9wIgV67cTJr0EYsWzWPhwnl4eXnRp09fmjVr\nARjr+Jw7d5aLF8/z3XffJihvkyavMnx4wgHiQgjxorB30ONgaRxHGhArA9BSxqpVyylQoCB16tRL\ncFwGBaYuUh+pj9RJ6iL1kToE3LvOLB0GwJJXKz3zoj12ngEv0ruDB3+iQoWKKV0MIYQQaYC9NxyV\n6R3CrhYssLwdgxBCCJHSpKVHCCGEEKmUfVt6JOgRQgghRKrk4ChBjxBCCCHSAQdp6RFCCCGEsJ0E\nPUIIIYRIpaSlRwghhBDpgH1DHgl6hBBCCJFa2XmdHgl60jhf3xps22ZxP1chhBAiXZHFCV9Q/fr1\n4uTJ4zg7/1eFOXJ4UqlSFXr2fNe839S+fYdSqohMmzYFP7+NDBkygl69uic4t3TpIrZs2czGjduS\n5Nu2zY+pUyfyww+/mJ8vNDSUb7/9mh9/3Ie//02cnV0oUMCHZs1a8Prr7ey6amdQUBCzZ8/gxIlj\nhIeHU7y44r33BlKiRMlH5tm2zY+1a7/l+vWreHhkoU2b9rz1Vjfz+Vq1quDs7Ixjon1kduz4AVdX\n1wTH7t0LpkuXDhQoUJDPP18MwNGjRxgwoE+StKVKlTGnEUKItMbRzh1cEvS8wBo2bMK4cR8CEBsb\ny/Xr15g2bTLDhg1i6dKVSb5gk1NISAi7d2+nSZNX2bRpXZKgxxbBwUG8++47ZM+eg9GjJ6BUScLD\nwzh8+Gdmz57ByZPHmTBhit3KPm7cCBwdHVm06EsyZ/Zg1arlDBnSj2++WU/WrNmSpN+3bw/Tpk1m\nwoQp1K5djwsX/mH06OFkzpyZ1q3bmdN9+unnVKpU5Yn3nz17JhERERbPpWQQK4QQLzrp3kojHBwc\nyJ+/AL179+Xvv89x5cplwGhh8PPbZE63adN6unbtSMOGtWjVqkmCL9ijR49Qq1YV/vrrT3r16kbD\nhrXo1KkNhw8ftLk827Z9j5dXTvr1G8SlSxc5cuTIUz/bokXzuH8/lJkz51KyZGkcHR3JlCkzDRs2\nYcqUmXh4ZOH+/dAk+Y4fP4qvb41Hviy5cOEfjh49Qt++A8mZMxfu7u50794TBwcHdu7cbjHP/v17\nqFz5ZerXb4izszPFi5fgrbf+x7p1a2x+1gMHfuDYsT9o3ryVzXmFECLtkZYe8RjR0TEACbq94mzb\n5se8eXOYOnU6FStW4dKliwwf/j5RUVF88MEIc7plyxYzYcIUvL1zMn36FKZMmYif3y6ru5BiY2PZ\nuHEdzZu3Inv2HNSsWYdVq1YxatQkm58nJiaGfft207Hjm2TMmDHJ+fLlK1C+fAWLeStUqGRzy8ip\nU3/h4uLCSy8VNx+LC2ROnfoT6JQkj4ODAzExMQmOZcuWjUuXLhIWFoa7uzsA69atYdq0yQQHB1G4\ncFH69OmfoOz37gUzc+ZHjBgxltOnT1ks3+TJ4zly5Deio6MpX74C/fsPJleu3DY9oxBCvCgcHOzb\nNiNBj8m9W4cJ9v+R2JiHyX5vB0dXsuauS5Zc1Z/6GjExMVy7dpVFiz6nQoVK5MuXP0ma9evX0qxZ\nc15+uRoAL71UjHbt3mDZssUMHjzMnK59+47kzZsPAF/fhmzfvoXbtwPx8vK2qiy//nqYmzdv8Oqr\nLQBo2bIVo0YNpXfvAXh6etn0XEFBdwkNDaVQocI25XtaQUF38fDIkiTAy5o1G3fu3LaYp25dXyZO\nHM2ePTupU6c+/v43WLv2W8AIZNzd3VGqJEqVYPTo8URFRbFkyUIGD+7LypXfkSdPXgBmzZpB1arV\nqV69VpKgx909EyVLlqZWrToMHz6GW7f8mTJlgrkr01KQK4QQLzwJep6PkH8Pp0jAAxAb85CQfw/b\nHPTs2bOTH37Ya3rngJeXF6+8UoMePXpbbJW5fv0qLVok7DYpVKgw4eFh3Llzx3wsX74C5v92c8sA\nwIMHD6wu14YNa6lRo5Y5wHnllRp4eXnh57eJbt16WH0dwPwcLi4uNuV7Piy3dDVo0IigoDssW7aY\n6dOnUry44rXXXufEiWPmYGTp0q8T5Bk06AN+/HEfO3duo1u3Hvz0k9Gt9fXXay3eo0SJkixZstz8\nPn/+AgwZMoJu3Tpx6tSflC9f0U7PKIQQaZcEPSYeOaunaEuPR07bW3niD2S2xsOHD4mNjU1wLO59\n/BjpWQZAX79+jV9+OYSzswtNm9YzH4+IiOD77zfSpUt3nJyccHFxITw83OI1QkNDcHZ2xtnZmWzZ\nspM1a1bOnDlNrVp1bSrL8eNHGTy43yPPW+r6yp49ByEh94iNjU0QOAYHB+Hp6fnIa7Vt25G2bTua\n3x86dBBXVzeyZctuMb2zszO5c+cmIOBf7t0L5pNPPmLYsDF4eHhY82iAEfgABAT8a3UeIYR4kdh7\n7y0Jekyy5Kr+TN1LL4ICBXw4f/7vBMcuXPiHzJk9yJHDk8uXLz3zPTZtWo+3d84k06gdHSPp0KED\nBw/+RN269SlcuAihoSFcv34tSVfcsWNHKVbMGFPj4OBAw4ZNWL9+LR06dEoye+rcubOMHTuCzz5b\nRM6cuRKce5oxPWXLlicyMhKtz5qnqEdGRnLmzGl69+5rMc+1a1c5c+YUjRo1NR87dOgg5ctXwNnZ\nGa3Psn37FgYMGGwOKCMjI7lx4zr16zfi558PcOfOHaZOnWDO/+DBA6KiomjevAHLlq3ir7/+JDDw\nXzp2fNOc5tKli8B/wY8QQqQ1jrI4oXharVu3Y8eOrfz++69ER0dz9uwZ1q1bw2uvtbZ6kPL69Wvo\n16+XxXMREQ/YuvV7WrVqQ548eRO8ypQpQ/XqNdmw4TsAatSoTZUqVZkwYRRanyU6Opq7d++wePF8\nDh06QK9e/wUYPXq8i7e3N717v82RI78RFRVFWFgYu3fvYPDgflSrViNJwPO0ChYsRLVqNZg3bzYB\nAf9y/34oCxbMxc3NjUaNmgBw+vRfdO7cFn9/fwCCg4P58MNx/PDDXmJiYjhw4Ae2bfOjSxdjmn72\n7NnNg8jDwu5z7949Zs2aTmwsvPpqS+rXb8j69Vv48stvzK/WrdtSokQpvvzyG7y8vHF1dWH+/Lns\n2bOTqKgorl+/xqxZ06lQoRIlSpSyy7MLIUSq4+AAxD4xmbWkpScdad26LeHhYcyZM5Nbt/zx8vKm\nbdsOdOrUxeprBAUFcePGdYvndu/eSXh4GC1btn7E/dsxdOhArly5hI9PIaZOncG3365kwoRRBAT8\nS+bMHpQsWYpFi75KsBCgh4cHixZ9yTfffM3s2TO4efMGbm4ZKFKkKO+/P4wGDRrb9kE8wfjxU5g9\newZdunQkKiqSMmXKMWvWPDJlygwYrTBXrlwmKioSgNKlyzB06CjmzZvLpEnjyJcvH+PHf2hekydn\nzlx8+unnLF48j7ZtWxIVFUm5chVZsGAp2bIZLVcZMmRIUAZ390y4uLiYg7natesxYsRYvv76Kz7+\n+EPc3NyoV68Bffr0t+uzCyFEWuaQeIxHGhEbEBCS0mVIk2JjY3nvvR4sWLDUpnze3h5InaQeUh+p\nj9RJ6iL1kTqERYYy+fgNwIElr1Z65r4u6d4SNvn55wOULVsupYshhBAiXZAp6yIF1apVh1q16qR0\nMYQQQgibSUuPEEIIIVIle09Zl6BHCCGEEKmSs6OTXa8nQY8QQggh0gUJeoQQQgiRLkjQI4QQQohU\nScb0CCGEECLdcLDjiswS9AghhBAilZKWHiGEEEIIm0nQI4QQQoh0QVZkfkH169eLkyeP4+z8XxXm\nyOFJpUpV6NnzXby9cz71tcPCwvj++w288cZb9iiqzXbt2sGkSWPw9W3EpEkfJTh39OgRBgzow+rV\nG8mfv0CCczdv3qB9+9eYNWseL7/8CgAxMTFs2bKZbdv8uHDhPLGxMXh756ROnfp06dLNvImoPURH\nR7N06SL27dvD7duB5M+fn06dutK4cdNH5vnzzxN88cVCzp3TxMbGUqdOPQYNGoq7uztg1MUXXyzg\nxx/3c+9eMHnz5qdr17dp0KCR+RqBgQHMnfspv/56iNhYKFu2PIMHDyNfvvx2ezYhhEgLpKXnBdaw\nYRP27TvEvn2H2Lv3Z2bPns/NmzcYNmwQMTExT33do0ePsGbNN3YsqW02bFhLkyav8tNP+7l9O/Cp\nrxMbG8v48aP46qsvePPNrvj57WLr1r0MHz6G33//lR49unL/fqjdyr1ixTJ27NjKxIlT2bZtL2+/\n3YupUydw9OgRi+lv3LjO4MH9UKoEGzZsZeXK77h9+zbTpn1oTjNt2mSOHz/K3LkL2b59P61atWHi\nxNGcO3cWgKioKAYP7oerqytr1mxm7drN5MyZk+XLbdsQVgghUiMHBxnTIyxwcHAgf/4C9O7dl7//\nPseVK5cBqFWrCmvWrKJTpzYMHPgeAMHBQUydOpE2bZrj61uT//2vE/v37wFg06Z1jB49lICAf/H1\nrcG+fcbx48eP8u67b9O0aT2aNq3HyJEf4O9/03z/WrWqsGvXDsaMGU6TJnVp1aoJK1Yss/k5zp07\ny+nTf9Gr13sULFgYP79NT/2Z7Nmzkx9+2MvUqTOoXbsebm5uuLq6Ur58RWbN+pxSpcpw65a/xby+\nvjUe+Tp+/GiS9LGxsaxfv5Y33ngTpUrg4uJC7dr1qF69Ft99t9riPX755RAxMTH07t2PjBkz4uXl\nxcCBQ9i/fy+3bwcSGxtLlixZGTBgCPny5cfZ2Zk2bdrj7p6JY8f+AODHH/cRGBjI0KEjyZYtG9my\nZWP48DGMGjX+qT83IYRIq6R7y+SA/132Xr/Nwxj7TY2zlqujAw3yeVI7d/ZnvlZ0tNHCE7/ba8uW\nzUydOpNChQoDMGbMcAAWLFhK9uw52LJlM+PGjWTBgly0bt2O27dvs2XLZjZu3AbAtWtXGTjwXfr0\n6c/s2fMJCwtj0qSxDB06kBUr1pgj8WXLFjNy5FgmTpzK1q3fM336FGrVqkORIi9ZXf7169dSpcor\n5MqVmxYtWvHNNyvo0qU7Tk62L0W+Z89OKlasTIkSpZKcy5IlK2PHTnpk3n37Dtl0r+vXrxEUdJeS\nJUsnOF6qVGnWrbMc9MR9brGx//2by5YtGzExMWh9lho1ajFkyPAEee7evUN4eBg5c+YC4I8/fqdY\nMcWKFV+ydev3REVFUaVKVQYOHEL27DlsegYhhEjrpKXH5KD/3RQJeAAexsRy0P/uM10jJiaGK1cu\ns2jR51SoUCnBeI6qVatTuHARHBwcuHDhH44d+4O+fQeSK1duXF1dadOmPYULF2HHjq0Wr71p03p8\nfArSqdNbuLllIHv2HPTu3Y+LFy9w5swpc7o6depSvnxFnJycaNy4GQD//POP1c9w79499uzZScuW\nrQBo0qQZwcFBHDz449N8JFy7dtUc6D1vQUFG/WXJkjXB8axZsxEUFGQxT7VqNXBwcGDBgs+4fz+U\noFGB018AABQHSURBVKAg5s2bg6urK8HBSfNERkby4YfjeOml4tSpUx+Af/+9xV9/ncDJyYnVqzcy\nf/4SLl26yIQJo+38hEIIkfyke+s5qZU7O66O9v1wreXq6ECtp2jl2bNnp7nLpWHD2nzwwQCKFi3G\nlCnTE/xDiR8AXbt2DYDChYskuFahQkW4ceOaxftcv36VwoWLJjhWuHBh07n/8uTL99/A4gwZMgAQ\nEfHA6ufZsmUzGTO6U7t2PcAIIOrW9WXDhu+svkZ8Dg4OuLi4PFXe5JAnT16mT5/NyZPHadOmOf37\n96JKlaq4u2fCySlhI+y9e8G8/35f7t69w8yZc8wtX7GxRmD19tu9yJAhAz4+hejV6z3++OP3R3bd\nCSFEeiXdWya1c2e3S/dScmrYsAnjxn34xHTxv/gfPowAjC/L+IyBz5aDvoiIhzg7uyRKb1wgfnDl\n6Pj0MXRMTAybNq0jJOQeLVo0NB+PjIwkIiKCK1cu4eNTyPws4eHhSa4RGhoCgJubGwA+PoU4c+b0\nU5XH17fGI899+qnRmhZfXFdS4haa4OAgcuTwfOS1KlWqwpIly83v47oOc+fObT52/fo1hgzpT5Ei\nLzF9+mzzzC4ALy+vJIO944LcgIB/yZUrN0II8aKy9zYUEvSkMwUKFATgn3/+pkyZsubjly5doEqV\nVyzm8fHx4ffff01w7MKF86ZzBe1Srl9+OcTNmzeYN29Jkun2Q4b0Z8OGdQwa9AE+PgVxcnJC69MU\nK1Y8Qbpjx47i4uJibpVq3LgpY8YM58iR36hSpWqCtGFh93n33R706dOX6tVrJSmPrWN68ubNh6en\nJ6dO/UW5chXMx0+ePJ7gfXwhISH89NN+6tdvaA5kDh/+mYwZ3VGqJGBMRx848F3q1vWlX79BSZp6\nixYtxt69uwgNDSVzZmP6/bVrVwGjJUkIIcR/pHsrnVGqBCVLlmb+/DkEBgYSERHB6tUruXr1Cs2b\nvwZAxowZCQm5R2BgAOHh4bRo0Zpr166yatVyIiMjCQj4l4ULP6NkydIUL17CqvuePHmSzp3b4u9v\nucvFGMBclXLlKpAnT94Er1at2rBjxxbCw8PJmjUb3br1YOHCeRw8+BMRERGEhYWxa9d2lixZQJcu\n3fHw8ACgXr0GNG7cjFGjhuLnt4nw8HAiIyM5ceIY/fr1xs3NjYoVq9jlc3VwcKBDh86sXr2Ss2fP\n8PDhQ3bv3sHvv/9Kx46dzek6d25rninn4uLC/PlzWLp0EZGRkVy8eIEFC+aaxk4ZrVUzZ35E6dJl\n6N//fYt9202bNidjRndmzvyIe/fucfPmDZYsWUDduvXx9PSyy7MJIURaIS096dDHH3/CnDmf0KNH\nFx48eECRIkWZO3eRueWkbl1fNm/eQPv2r9Gv3yDatu3Ixx9/wpdffsGKFcvIlCkzL7/8Cu+9N8Dq\ne4aHh3PlymWio6OSnLt27Sq//XaYKVNmWMzbrFlLFi+ez65d22nVqg3duvUgZ85cfPnlEiZPHoej\noxMFCxZk1Khx1K/fMEHesWMnsXXrZvz8NjN37qc4ODiQJ08eGjVqSvv2nczBhT107tyVhw8fMnLk\nEIKC7uLjU5DJk6dRqlQZc5orVy4TGmqsDZQhQwY++sioi6ZN65ElS1Zee+11unXrARiDlA8e/Aln\nZ+ck3W3GtPt5ZMmShTlz5jN79kzatHkVZ2cXGjRoRN++A+32XEIIkVLsPZDZITbx4I60ITYgICSl\nyyDi8fb2oFu3txk3brK5JUakHG9vD+R3JHWROkldpD5Sj9G/a2JxZMmrlZ45ApLuLZEsbt++TXh4\nuAQ8QgghUowEPSJZeHp68vnni1O6GEIIIdIxCXqEEEIIkS5I0COEEEKIdEGCHiGEEEKkCxL0CCGE\nECLVsuekdQl6hBBCCJEuSNAjhBBCiHRBgh4hhBBCpFr2XEJZgh4hhBBCpAsS9AghhBAiXUjWDUeV\nUu7ATKAZkAM4DYzTWu9+RPrKwDSgIhAB/Aj011oHJk+JhRBCCJFWJHdLz+dADaAJkAv4CvBTSqnE\nCZVSOYAdwBGgCEbgkw34LrkKK4QQQoi0I9mCHqVUduAtYILW+pzW+oHWehFwBuhjIUtnjOn5Y7TW\nwVrrW8AIoJ5SqnxylVsIIYQQaUNytvRUBlyA3xId/w2oZiF9NeCo1joq3rGTwINHpBdCCCFEGuNg\nx/lbyTmmx9v0806i44FAzkekT5BWax2rlLrziPTxOXh7ezxVIcXzI3WSukh9pD5SJ6mL1EfqsOjV\nl+12rdQye8vWMM6e0/aFEEIIkQ4kZ9Bzy/TTM9FxL8D/EekTpFVKOWDM+rKUXgghhBDikZIz6PkD\nY9p54vE4NYEDFtIfAioppVziHasCZAAOPpcSCiGEECLNcoiNTb6eIqXUfKAO0Aa4BrwHTABKA1HA\nXqC71vqwUiorcBZYBUwCspj+O0Rr3SLZCi2EEEKINCG5x/S8jxHYHARuA22BJlrryxgzuxSQCUBr\nHQw0AiphdGedBC5gTGUXQgghhLBJsrb0CCGEEEKklNQye0sIIYQQ4rlK1r237EH270p9nqJOfIEP\ngTJAOLALGKK1DkieEqdtttZHoryLgF5AYa31pedZzvTkKX5HspjStwXcgOPAAK310eQpcdr2FPXx\nFvABUBQIAX4AhmmtryVLgdMBpVRh4EugLk/4+6OUagRMBEoBwcB2YLDWOuxJ93kRW3pk/67Ux5Y6\nKQdsA1ZjLFfwClAWWJxchU0HrK6P+Ex/SDo+99KlT7bWyVqgIFAeyIfxJTtVKfUi/s1OjWz5m9UA\nWA5MxQiQqgB5MCbWCDtQSr0O/AJctiJtMcAP+BbIC9QDXgbmWXOvF6qlJ97+XR201udMhxcppfpg\n7N/1fqIs8ffvigKClVIjgONKqfJa6xPJVfa06inqJA8wT2v9men9ZaXUcoyoXTyjp6iPuHwewBcY\nMyU/SY6yphe21olS6hWgAVBIa33ddHhMcpU3rXuK35EqQKDWeq3p/Q2l1Brg02QpcPqQA6gN+ABd\nn5C2N3A23nfIRaXUJGCdUmrok3pxXqigB/vv3yVBz7OzqU601juBnYkOFwGuPpfSpT+2/o7E+QT4\nFdiABD32Zmud+AIXgTZKqcFAVox1ywZqrc8/z4KmE7bWx1ZgvFLqTWAdRn10RHoM7EZrvRRAKeVj\nRfJqWK47Z4y6Tfz9ksCL1lRql/27TMeetH+XsI6tdZKAqem4DzDWzuVKr2yuD6VUY6A10Pc5lis9\ns7VOCgD5Mca8VQTKYYzr2ZJosVbxdGyqD631Xxi9BgsxxiDG7S4gvy8pI8n3OkbdgRXfOS9a0PM4\nsn9X6vPYz1gp1Rn4HuP/YDcmT5HStST1YRow+wXQTwaSpwhLvyMOGP/XOlBrHWQaLDsIKMHjW+vE\ns7P0O1IL+BroCWQGCmP0FmxO3qIJKzzxe/1FC3pk/67Ux9Y6AUApNR5j4Fl7rfWC51S29MjW+vgE\n+C3eeAVhf7bWyQ0gTGv9IN6xuG6t/HYuW3pka330Aw5orVdrrcNMs4pGA75KqdLPr5jiEZJ8r2PU\nHVjxvf6iBT2yf1fqY2udoJQajTEtuqbWetvzLV66Y2t99AAaKaUClVKBQNyU6KNKqWHPr5jpiq11\nchLIapqlEucl08+L9i9eumNrfTiZXvHFjYd90b5D04JDJK27Whh1+vuTMr9wKzLL/l2pj411Uhkj\n4HxFa30yZUqcttlYH4lbDvIDh4HqwGmt9b3kKndaZmOduGCsy3MLYyxJNMbfrexAVdO4RPEMbKyP\nNzC6t97AmCqdA1iKMfaqotY6OtkfII1SSjUEdhNvnR6lVFVgBdBYa31FKVUIOIUxo3EhxoyvjcA+\nrXW/J93jRYxSZf+u1MfqOgHexRiU+ZtS6kGiV50UKHtaZMvvyLX4L/5rHvaXgMeubKmTSKApcA84\nh/E36y7QQgIeu7GlPlZjBEXjTGk1cB+jPiTgsQOllFZKPcBYww1Am74TlgDuGPXhCmAKhpphBKF3\nMRYc3gEMtuZeL1xLjxBCCCHE03gRW3qEEEIIIWwmQY8QQggh0gUJeoQQQgiRLkjQI4QQQoh0QYIe\nIYQQQqQLEvQIIYQQIl140XZZF0KYmNa16KO1/iqZ7vcV8JLWutZT5s+AsYt7XeBDrfXHSqmPMNZu\nOgR8DOwCSmmtLzzhWl2AJUCm1LpWilIqM8bO9Z9prRemUBmmAVWBhqn1cxIiOUnQI0Qqo5RyAoZi\nLL5VGGPblOvAOmC81jocQGudIcUK+XQaYywqVg74SymVDRgODAQ+Ny28Z9Uzaa2/xlglNzVbAmit\n9UKl1C6MFYDBaGF3AR7y3waJP2mtG5sCy66mc2BsPhqAsUr2WK31WTAHoPHTgbGS8AXTfeM+z9EY\nAeUEYKz9H1GIF4sEPUKkPjOADhgrh/+KsQ3By8A3GEuuv5FyRXsm2U0/z2itY03bxDjEvU/Bctmd\nUqoa0B5jWwO01o3jnasH7AdKa63/sZD9UPzWNKVUPuBTYLdSqnS8lbITp3PFWIF+NcbqtZ9oraNM\ne935KaUWa62v2vM5hXjRSNAjROrTDNiotf4p3rHDSqm2QN64A0qpWKCn1voLpVRGYBHwOvAAY08a\nT4yuonrxvmirA7OBshh7Dr0ft+mrUiq36Vw9jCX4zwHDtdZ7rCm0aU+cT4EagAfGxo5Dtda/KqVG\nAB+akoYqpaZitEIAbFNK/QBMNZWxmNb6H1P30HSgHUbLyM/AQK31eaVUN+BLwMX0xe5purev6bnP\nAmPiPdtXQEbTNT7ACMAOAN201v+a0lTB2HW+MnAHY7+f8RjbD3QHCmmtY+I971/ANq21pY1ZhwC7\ntNbams/ucbTW15VSgzB2X68JbH9EuofAVqXUKuB/pmdBa71bKXUeGIDRgihEuiUDmYVIff4C2iml\nmpm6ugDQWh/VWm95RJ7hwKsY42V8MP5Pv4OFdBOAThhf+oeBr5RSDqZzSwBvoDjGpoo7gA1KqSxP\nKrCplWEPxt5EynSdg8AOpVQWrfXHQE9T8sxa60mmdACvxm8JiWcRUMH0yocRiGxTSln6u7XRVOYq\npmf7AtislCoSL42vqVwlMFpgKgHDTOXPhTGeaBvghdFi0h0YibG5ZD7TsbjnLWe6xjILn4UT0NB0\nPXuJ+3cQaUVaNyA80bGdGMG0EOmaBD1CpD59MVpJtgGBSqmtSqkRSqmXHpOnA7DKFBiFY7SihFlI\nN1drfdHUKrAWIwjIE+8arbTW90ybXq7CaLEpZUWZmwEFgUFa62CtdZipDFEY3Tw2MbXcdAQ+0lrf\nMF1vKMa4lAyJ0pYHagNDtNa3tNYRWuv5GBsMd4+XNApjTFSY1voK8BPG+CIwugyjgRla6wemFpp2\nwI+mtDuBd+JdqxNG99JZC8X3AbKZ7v9MlFIOSqkCwByMlrefH5PWXSnVzvQsSxOdPgGUNu3gLkS6\nJd1bQqQypu6WFqYvuzoYXRo9galKqSlaa0sDUgsA5+NdI0op9TtGV0988ceQxAVF7qafZYApSqnK\nQOZ46awZXFwC4+/JbaVU/ONOQCEr8idW2JT3YtwBrfUtjECNRPcoYfp5MtFxR+BUvPcX43dPYTx/\nXHdhMeBy/PNa68Px0i4G1iilPLXWtzECiw+xzNv0M/BRD/cENUwz8+LcwuiKaxQ3iP0R6dwwuvX6\naa0TBz0Bpp9ewM2nLJcQLzwJeoRIpUyDTleZXiilxgMTlFJfaa3PJ0ruSMKZPPDfzKD4YiwcwzSo\nOK57p7TW2l8ZEYSllgxLwoF7WuusVqZ/krjp1da0RscFAnm01ncfk87is8e73+PutQWj6+5NpdRv\nGMHDWivK9jQSDFC2Np1SajVG1+SK51QuIV540r0lRCqilCqolJqvlMpj4XTceB4vC+duAubxK0op\nZ4wZX9YqidEl84nW2t907BUb8p8DsiilisY/mGhMjS0uYHRHxbXioJTyUkp9oJTKYeHeABUT3btw\nvPFKT3IOKGIamxSXv55S6k0wWs4wBk53At4E1mqtQx9xrfitKsmpL0bL1SQL55619UmINEGCHiFS\nF3+MQbBrlFJVlFKuSiknpVRpjNlNpzHG+yS2CeiilCptWgRwMkZ3h7UuY7R21FRKuSilGgJtTed8\nrMi/21S2BUqpvKZy9wFOP03go7UOxpiiP9oUvGTE6E7qBQQnSnsWY8zNJ0qpl0yf1+um8li7kOI3\npp8TlFKZTMHbMuIFkhiDo6tizIxK3H0U3xVTGcs9Jo3dmbrd3gWGKaUSP3d54LRprJYQ6ZYEPUKk\nIlrrCIwv6mPAtxgzlu4D3wMaqGtqdUhsCvAbcARj3E4gsJfHd+nEv+9NjCnNo0z37Af0wOjCWaSU\neusJ+aOBlhhdTWcxWju6YszMeuzqyo/RB/gFOIrRklUQaP6IlYW7YIzf+Q0j4BgHdNVaH7DmRqZu\nsToYM7wCgB8w1rv5KF6aixif6XWt9aHHXCsaIwhsaM297UlrvRFYA3ydaNZdY4yuSyHSNYfY2DS1\nJpgQ6ZZSKoPW+kG89z9gDM79X8qVKu0wdZWdABZprec9IW0NjNlhJbXWfydH+R5TlgbAVqC4aSaa\nEOmWtPQIkQYopYYAV5RSZUzdOy0xpnFvSuGipQmmqd6TMRZtTLI2T2KmlqD1xGspSgmmsV1TgE8l\n4BFCgh4h0orPMGZ57QbuYWxlMdDU3SGegWl8TCjQFGidaNr44/QASiqlej+3wj3ZZIwVuselYBmE\nSDWke0sIIYQQ6YK09AghhBAiXZCgRwghhBDpggQ9QgghhEgXJOgRQgghRLogQY8QQggh0gUJeoQQ\nQgiRLvwfqFf7w8yDi1EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3faf123940>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Cfe5FkVfb_4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_val."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XKbrenvvCVeh",
        "colab_type": "code",
        "outputId": "209c6888-6752-4ad1-d3f5-16b8c52f8329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "cell_type": "code",
      "source": [
        "utils.plot_signal_efficiency_on_p(proba, y_val, X_val.TrackP.values, 60, 50)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-316686467c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_signal_efficiency_on_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'TrackP'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "D-L1zQZ4CVe0",
        "colab_type": "code",
        "outputId": "b4f7658f-55af-4dea-d19a-381484b34f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "cell_type": "code",
      "source": [
        "utils.plot_signal_efficiency_on_pt(proba, validation_data.Class.values, validation_data.TrackPt, 60, 50)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-4581e3215af6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_signal_efficiency_on_pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackPt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'validation_data' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "R1WO8rVSCVe7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare submission\n",
        "\n",
        "Select your best classifier and prepare submission file."
      ]
    },
    {
      "metadata": {
        "id": "c9pLWuh8CVe8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test = pandas.read_csv('test.csv.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5CK1GS8CVe_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_model = gb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivx8ayyeCVfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predict test sample\n",
        "submit_proba = best_model.predict_proba(test[features])\n",
        "submit_ids = test.ID"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fmbTSL2qCVfH",
        "colab_type": "code",
        "outputId": "caff3766-a7ea-4166-a3c9-c8e20a3cccde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "utils.create_solution(submit_ids, submit_proba, filename='submission_file.csv.gz')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<a href='submission_file.csv.gz' target='_blank'>submission_file.csv.gz</a><br>"
            ],
            "text/plain": [
              "/content/drive/My Drive/Colab Notebooks/hadron-collider-machine-learning-master/week2/submission_file.csv.gz"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}